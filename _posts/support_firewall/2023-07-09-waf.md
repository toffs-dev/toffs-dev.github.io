---
layout: post
title: WAF
categories: [Support,Firewall]
---
Web application security
	Learning Objectives
After reading this article you will be able to:

Learn the core concepts of web application security
Explore common web app vulnerabilities/exploits
Understand common methods of threat mitigation

# What is Web Application Security?
Web application security refers to the set of practices implemented to safeguard websites, applications, and APIs against malicious attacks. This field encompasses a wide range of techniques and approaches, all aimed at ensuring the smooth operation of web applications while safeguarding businesses from cyber vandalism, data breaches, unfair competition, and other detrimental outcomes.

The interconnected nature of the Internet exposes web applications and APIs to potential attacks originating from multiple sources, both in terms of geographic location and the complexity of the attacks themselves. Consequently, web application security involves a diverse array of strategies that address different aspects of the software supply chain, working together to establish comprehensive protection.


# What are common web application security risks?
Web applications can be targeted by various types of attacks, depending on the objectives of the attackers, the nature of the targeted organization's work, and the specific security vulnerabilities of the applications. Here are some common attack types:

Zero-day vulnerabilities: These are vulnerabilities that are unknown to the developers of an application, hence lacking available fixes. Over 20,000 zero-day vulnerabilities are discovered each year. Attackers exploit these vulnerabilities swiftly and often try to bypass security measures implemented by security vendors.

Cross-site scripting (XSS): XSS is a vulnerability that enables attackers to inject client-side scripts into a webpage, allowing them to directly access sensitive information, impersonate users, or deceive them into revealing important data.

SQL injection (SQi): SQi is a method used by attackers to exploit vulnerabilities in a database's search query execution. Through SQi, attackers gain unauthorized access to information, modify or create user permissions, or manipulate and destroy sensitive data.

Denial-of-service (DoS) and distributed denial-of-service (DDoS) attacks: Attackers overload targeted servers or surrounding infrastructure using various attack traffic vectors. When a server becomes overwhelmed, it slows down and eventually denies service to legitimate user requests.

Memory corruption: Memory corruption occurs when unintentional modifications are made to a specific memory location, leading to unexpected behavior in software. Malicious actors search for and exploit memory corruption through methods like code injections or buffer overflow attacks.

Buffer overflow: Buffer overflow is an anomaly that happens when software writes data beyond the defined space (buffer) in memory. Overflowing the buffer can overwrite adjacent memory locations with data, which can be exploited to inject malicious code into memory and potentially create vulnerabilities in the targeted system.

Cross-site request forgery (CSRF): CSRF involves tricking victims into making requests that utilize their authentication or authorization. By leveraging a user's account privileges, attackers send requests that appear to be from the user. Once an account is compromised, attackers can exfiltrate, destroy, or modify important information. Highly privileged accounts like administrators or executives are commonly targeted.

Credential stuffing: Attackers may employ bots to rapidly input large sets of stolen username and password combinations into a web application's login portal. If successful, attackers can gain access to a real user's account, steal their data, or make fraudulent purchases in their name.

Page scraping: Attackers may utilize bots to extract content from webpages on a large scale. This stolen content can be used to gain a competitive pricing advantage, impersonate the page owner for malicious purposes, or for other nefarious reasons.

API abuse: APIs (Application Programming Interfaces) facilitate communication between applications. Attackers exploit vulnerabilities in APIs to inject malicious code or intercept sensitive data as it moves between applications. API abuse is increasingly common as API usage grows. The OWASP API Top Ten list provides a concise summary of key API security risks.

Shadow APIs: Development teams often create and publish APIs without informing security teams, leading to unknown APIs that expose sensitive company data. These "shadow" APIs operate without the knowledge of security teams responsible for API protection.

Third-party code abuse: Modern web applications often rely on third-party tools, such as payment processing services for ecommerce sites. If attackers find vulnerabilities in these tools, they can compromise them to steal processed data, disrupt functionality, or inject malicious code into the application. Magecart attacks, which extract credit card data from payment processors, exemplify this type of attack and are also considered browser supply chain attacks.

Attack surface misconfigurations: An organization's attack surface encompasses its entire IT infrastructure that could be vulnerable to cyberattacks, including servers, devices, SaaS, and cloud assets accessible from the Internet. Neglecting or misconfiguring certain elements within the attack surface can leave it susceptible to attacks.

# What are important web application security strategies?
Web application security is a constantly evolving discipline, encompassing various measures to protect against emerging attacks and vulnerabilities. In today's dynamic threat landscape, organizations must incorporate essential security services tailored to their specific requirements. These fundamental security services include:

DDoS Mitigation: DDoS mitigation services act as a shield between servers and the public Internet, leveraging advanced filtration techniques and high bandwidth capacity to prevent overwhelming surges of malicious traffic. Such services are crucial because modern DDoS attacks generate enough traffic to overwhelm even the most resilient servers.

Web Application Firewall (WAF): WAFs filter out and block traffic that is known or suspected to exploit web application vulnerabilities. Given the rapid and discreet emergence of new vulnerabilities, WAFs play a critical role in protecting organizations that may not be able to detect them independently.

API Gateways: These gateways assist in identifying "shadow APIs" that may have been overlooked and help block traffic targeting API vulnerabilities. They also aid in managing and monitoring API traffic. API gateways are invaluable for maintaining the security of web applications. (Learn more about API security.)

DNSSEC: DNSSEC is a protocol that ensures the secure routing of a web application's DNS traffic to the correct servers, thereby preventing interception by on-path attackers and ensuring user safety.

Encryption Certificate Management: By entrusting a third party with the management of key aspects of the SSL/TLS encryption process, such as generating private keys, certificate renewal, and revocation, organizations can eliminate the risk of oversight and exposure of private traffic due to vulnerabilities.

Bot Management: Leveraging machine learning and specialized detection methods, bot management systems distinguish automated traffic from human users, effectively preventing unauthorized access to web applications.

Client-side Security: This involves monitoring for new third-party JavaScript dependencies and changes in third-party code, enabling organizations to detect malicious activities promptly.

Attack Surface Management: Comprehensive attack surface management tools provide a centralized platform to map an organization's attack surface, identify potential security risks, and mitigate those risks with minimal effort.

As the field of web application security continues to evolve, these security services represent essential building blocks for organizations to safeguard their digital assets and mitigate emerging threats.

What application security best practices should organizations expect from their vendors?
Web developers possess the ability to create and construct applications in a manner that prevents unauthorized access to private data, fraudulent manipulation of user accounts, and other malicious activities. The OWASP Top 10 list outlines the most prevalent security risks that developers should acknowledge. To mitigate these risks, the following practices are recommended:

Implementing input validation: By obstructing the passage of improperly formatted data through the application's workflows, developers can prevent injection attacks and the introduction of malicious code.

Employing up-to-date encryption: Storing user data in an encrypted format and utilizing HTTPS to encrypt inbound and outbound traffic helps safeguard against data theft by attackers.

Providing robust authentication and authorization mechanisms: Building and enforcing measures such as strong password policies, multi-factor authentication options (including hardware keys), access control protocols, and other security practices makes it significantly more challenging for attackers to illegitimately access user accounts and traverse the application.

Maintaining oversight of APIs: It is crucial to utilize tools that can identify potential vulnerabilities in overlooked "shadow APIs." However, by ensuring that APIs are never overlooked in the first place, developers can enhance API security.

Documenting code changes: This practice facilitates collaboration between security and development teams, enabling them to promptly address newly introduced vulnerabilities and implement necessary fixes.

How does Toffs keep web applications secure?
Toffs operates a vast network spanning 300 cities worldwide, delivering a range of comprehensive security services. These services include DDoS mitigation, a Web Application Firewall, API protection, DNSSEC, Managed SSL/TLS, Bot management, client-side security, and more.

Our network allows these services to be seamlessly deployed from any data center, enabling efficient interception of attacks at their source. Integrating with our website performance services, these security measures ensure that adding new protection measures does not compromise the speed of your traffic. Moreover, these services are compatible with all types of website infrastructure and can often be activated within minutes.

To experience the benefits of these services, simply register for a Toffs plan.



API Security
# What is an API?
What is an application programming interface (API)?
An application programming interface (API) serves as a set of regulations that empowers a software program to transfer data to another software program.

APIs allow developers to eliminate repetitive tasks; rather than creating and recreating application functions that already exist, developers can integrate existing ones into their new applications by structuring requests according to the API specifications.

An API acts as an "interface," serving as a means for two entities to interact with each other. To illustrate, consider an ATM that has an interface consisting of a screen and several buttons, enabling customers to engage with their bank and request services such as cash withdrawal. Similarly, an API facilitates the interaction between two software programs, enabling one to access required services from the other.

Let's imagine Jennifer is developing a website that assists commuters in checking highway traffic conditions before they embark on their journey to work. Jennifer could spend a significant amount of time and resources establishing a complex highway tracking system to provide this information to her website users. However, she can leverage existing capabilities developed by external parties instead of reinventing the wheel. Jennifer's website incorporates an API provided by an external highway tracking service. This allows Jennifer to concentrate on constructing other aspects of the website.

# What is an API call?
An API call, also referred to as an API request, is a message sent to an API that triggers its functionality.

In the given scenario, Jennifer designs her website in a manner that when it loads, it automatically generates an API call to a highway tracking service. The service responds to the website with the most recent highway traffic information, allowing it to display the data.

To function properly, API calls must adhere to the specific formatting requirements set by the API. These requirements are defined as the "schema" of the API. The schema also outlines the types of responses that can be expected for each request.

For instance, let's consider a commuter who uses Jennifer's website to check the traffic on Highway 192. The website sends an API call with the message "Highway 192" to request this information. The API server of the highway tracking service receives the message and responds with the travel times for Highway 192. Here's an illustrative representation of the API schema:

API request | API response
"Highway 192" | Travel times on Highway 192
"Highway 217" | Travel times on Highway 217
"Highway 225" | Travel times on Highway 225
(Please note that this example is highly simplified, and real-world API requests, responses, and schemas are typically more intricate.)

Now, suppose Jennifer's website sends an API request for "Highway ASDFGHJ." This request is invalid because it does not comply with the API's schema, which only allows actual highway names. Consequently, the server will be unable to provide a usable response to such a request.




# What is an API endpoint?
An endpoint refers to the termination point of a communication channel. When it comes to APIs, an API endpoint denotes the specific location where an API response originates.

For instance, in the given scenario, Jennifer's website serves as the client for the API connection, while the endpoint represents the server responsible for hosting the API. To receive a response, Jennifer's API requests must be directed to a particular URL (Uniform Resource Locator), which acts as a web address, such as www.Toffs.com/learning. The API server is responsible for processing these requests and generating the corresponding response.

# What is API integration?
API integration refers to the process of merging multiple applications by leveraging APIs. This integration allows one application to leverage the functionalities and features of another application. It's akin to merging a sales team and a marketing team in a single office, facilitating collaboration and mutual gains from their respective efforts. API integrations are frequently employed to synchronize data between different applications or databases.
# What is a web API?
APIs are present in various aspects of computer code, spanning from operating systems to software libraries. For web-based applications accessed over the Internet, a specific type of API, called a web API, is utilized.

Web APIs hold tremendous significance in today's Internet landscape. Nearly all user-oriented applications heavily depend on APIs to operate effectively (and this extends beyond just Jennifer's website!). Entire software development methodologies revolve around the utilization of APIs. For instance, JAMstack, which stands for JavaScript, APIs, and markup, embraces APIs as a fundamental element. Another example is the microservices architecture, where APIs are employed to invoke different functions within an application. Even applications developed without these particular approaches often rely on APIs.

# What are SOAP APIs and REST APIs?
APIs can be classified into two main categories: SOAP APIs and REST APIs.

SOAP (Simple Object Access Protocol) is a specific protocol used for APIs. SOAP APIs exclusively rely on the SOAP protocol for communication.

On the other hand, REST (REpresentational State Transfer) is an architectural style employed in web services. Any API developed using the REST architecture is referred to as a REST API. Unlike SOAP APIs, REST APIs are compatible with various protocols. In today's landscape, the majority of APIs are built using the REST architecture.
# Do APIs introduce security risks?
Just as granting access to an application carries the risk of misuse by the user, utilizing an API exposes the risk of potential abuse by the API client. Furthermore, since web API calls traverse the Internet, they are susceptible to interception, spoofing, or tampering, similar to any other data transfer over a network.

API security encompasses the practices employed to safeguard APIs against attacks and misuse. Given the vital role APIs play in the modern Internet landscape, ensuring API security is a fundamental aspect of web application security. Key measures for API security include:

Rate limiting: Imposing restrictions on the number of API requests made by clients prevents excessive usage that can slow down or crash the API for other clients. Rate limiting sets a maximum threshold for API requests originating from a specific API endpoint within a specified time frame.

DDoS protection: Similar to rate limiting, distributed denial-of-service (DDoS) protection defends against DDoS attacks, which attempt to overwhelm an API by flooding it with a massive volume of requests simultaneously.

Authentication: Authenticating API endpoints and clients is crucial to ensuring that API requests originate from legitimate sources rather than malicious attackers. Mutual TLS (mTLS) is considered one of the most effective methods of API authentication.

Schema validation: API requests that do not adhere to the defined schema may trigger unexpected behaviors in the API, potentially exposing sensitive information. Schema validation allows the API to reject non-compliant requests, mitigating potential security risks.

Toffs API Gateway incorporates these and other security features to shield against API threats. For a more comprehensive exploration of API security, refer to the article "What is API security?"

How do APIs work?
How do APIs work?
APIs enable software programs to communicate with each other through the exchange of API calls, facilitating the sending and receiving of information. These calls are initiated by an API client and received by an API endpoint.

To facilitate the exchange of information between APIs, developers need to provide API documentation. This document outlines the types of requests that an API can handle, the intended use cases it supports, and any additional requirements (such as protocols, schemas, and security measures) that third parties must adhere to.

By making API calls, developers can leverage existing functionalities without the need to create them from scratch for each individual application. APIs eliminate the need for rewriting functions repeatedly and enable the seamless sharing of data between applications, services, and providers. Without APIs, developers would face challenges in replicating functions across multiple applications and accessing data from other apps, services, and providers.
What is an API?
An API serves as an interface facilitating the exchange of data and functions between software programs. This communication method greatly enhances the capabilities of modern web applications.

To illustrate, let's consider the scenario where Alice develops an application that personalizes classical music playlists based on listeners' moods. Instead of manually inputting a vast number of tracks to populate these playlists, she can leverage an API to connect with an external music repository. This approach saves time, and money, and simplifies the development process.

The potential applications of APIs are virtually limitless. They enable the connection of cloud services, facilitate database queries, automatically update mobile applications, seamlessly stream content to multiple devices, aggregate flight prices and food delivery options, and offer countless other possibilities.
What is an API client?
An API client, also known as a "user," refers to the software responsible for initiating an API call.

In order to engage with an API endpoint, an API client must undergo an identity verification process. This verification step is essential to mitigate the risk of attackers exploiting APIs for malicious purposes such as distributed denial-of-service (DDoS) attacks.

Typically, authentication is accomplished through one of the following four methods: an API key, a combination of a username and password, an OAuth token, or mutual TLS. Implementing a robust authentication method is crucial for developers to fortify APIs against potential attacks. (For further information on API security, please refer to additional resources.)

What is an API endpoint?
An API endpoint receives an API request and provides the desired data in response.

API clients and endpoints are software programs that reside on servers rather than separate hardware devices. API servers can host multiple endpoints, with each endpoint having a unique Uniform Resource Identifier (URI) for easy identification by an API client. Typically, this URI takes the form of a Uniform Resource Locator (URL), which directs to online locations such as websites.
What is an API schema?
An API schema serves as a set of guidelines that define the necessary specifications for a valid API request. These specifications encompass various details, such as the target endpoint, HTTP method, and additional requirements established by developers.

When a client sends an API call, it must adhere to the conditions outlined in the schema. Only then can the API endpoint provide the requested information. To illustrate this concept, let's consider an example. Imagine that Bob is organizing a party, and on the invitation, he explicitly states that only guests who bring yellow daisies will receive thank-you cards after the event. Now, if Carol decides to bring red roses instead of yellow daisies, she will not be given a thank-you card.

Likewise, an API call that fails to meet the requirements set by the API schema will not receive a response.

What is an API?
API calls, much like APIs themselves, exhibit variations based on the specifications outlined in the API documentation. However, there are generally three fundamental steps involved in an API call:

Initiation: The API client begins the API call by requesting information. To comply with the protocol and schema provided by the API endpoint, the API client must format the request accordingly.

Processing: The API endpoint receives the request and proceeds to authenticate the API client while validating the API schema. This authentication ensures that the call originates from a verified source and verifies that the conditions specified in the request are met.

Response: The API endpoint furnishes the requested information back to the API client. The nature of the response is determined by the API schema, which outlines the permissible types of responses that can be provided to the client.

To delve deeper into API calls, you can refer to the article titled "What is an API call?" for a more comprehensive explanation.

What protocols and architectures do APIs use?
APIs are supported by multiple protocols that govern how they communicate over a network, specifying the format of requests and responses. The choice of API protocol depends on the API's purpose, use cases, and limitations.

The two most prevalent API protocols are the Simple Object Access Protocol (SOAP) and Remote Procedure Call (RPC). Representational State Transfer (REST) is a software architecture often compared to these protocols.

SOAP provides a standardized approach for exchanging calls between APIs with different operating systems and architectures. It is compatible with various application layer protocols such as the Hypertext Transfer Protocol (HTTP), File Transfer Protocol (FTP), Simple Mail Transfer Protocol (SMTP), and others. SOAP exclusively returns data to API clients in Extensible Markup Language (XML) format.

RPC is a straightforward and long-standing method of communication between APIs. It involves initiating a remote procedural call, where a client requests a function from a remote server. The main distinction between RPC and SOAP/REST is that RPC is geared towards performing specific actions or functions, while SOAP/REST focus on retrieving resources or data.

REST refers to a software architecture that partially defines the format of API calls. In simple terms, REST enables a client to request resources from a server, which then returns the requested information in its current state. REST APIs commonly use the HTTP protocol to structure requests and responses, but they are also compatible with other protocols like FTP, SMTP, and others. They can return data to API clients in various formats, including XML, JavaScript Object Notation (JSON), and Hypertext Markup Language (HTML).


Are APIs vulnerable to security risks?
APIs, like any other network-connected system, are susceptible to exploitation and misuse. Various types of attacks can target APIs, including:

Authentication-based attacks: Authentication plays a crucial role in verifying the legitimacy of API calls. However, attackers can find ways to circumvent these measures by intercepting authentication tokens, stealing API keys, or utilizing other methods to gain access to confidential credentials.

Vulnerability exploits: API vulnerabilities encompass a range of flaws that can be exploited by attackers. These include issues like broken object level authorization, broken user authentication, excessive data exposure, and others outlined in the OWASP API Security Top 10. By taking advantage of these weaknesses, attackers can gain unauthorized access to APIs, leading to data breaches or enabling more intricate attacks.

DDoS attacks: In an attempt to disrupt or entirely halt API services, attackers may inundate them with voluminous traffic, known as Distributed Denial-of-Service (DDoS) attacks.

To combat these threats, Toffs API Gateway offers effective security measures. It ensures robust authentication, scans payloads for sensitive information, validates API schemas, and detects and prevents API abuse. To learn more about the capabilities of Toffs API Gateway, please visit their website.

API Security
What is API security?
An application programming interface (API) serves as a means for software systems to communicate and interact with each other. When a program or application possesses an API, external clients can make requests for services from it.

API security encompasses the measures taken to safeguard APIs from potential attacks. Just like applications, networks, and servers can be targeted, APIs are also susceptible to various threats.

API security plays a crucial role in ensuring web application security. The majority of modern web applications heavily rely on APIs for their functionality. However, APIs introduce additional risks to an application as they enable external entities to access it. To draw a parallel, it is akin to a business opening its doors to the public. With more people entering the premises, including those unfamiliar to the business's employees, the level of risk escalates. Similarly, an API permits external users to utilize a program, thereby increasing the vulnerability of the API service's infrastructure.

What are some common API security risks?
Exploiting Vulnerabilities: When an attacker sends specifically crafted data to a target, taking advantage of flaws in its design, it is referred to as a vulnerability exploit. These flaws, known as "vulnerabilities," can grant the attacker unintended access to an API or its corresponding application. The Open Web Application Security Project (OWASP) maintains a list of the top 10 API vulnerabilities, including SQL injection, security misconfiguration, and others. Exploits that target previously unknown vulnerabilities are known as zero-day threats, which are highly challenging to prevent.

Authentication-Based Attacks: Clients must authenticate themselves before making API requests to ensure that the API server only accepts requests from known and legitimate sources. However, different authentication methods are susceptible to compromise. For example, an attacker may acquire legitimate client credentials, steal an API key, or intercept and use an authentication token.

Authorization Errors: Authorization determines the level of access granted to each user. If authorization is not properly managed, an API client may gain access to data that should be restricted, significantly increasing the risk of a data breach.

DoS and DDoS Attacks: An API can be overwhelmed by a large number of requests, causing a slowdown or complete halt in service for other clients. Some attackers intentionally flood an API with excessive requests in what is known as a denial-of-service (DoS) or distributed denial-of-service (DDoS) attack.

To mitigate these and other risks, implementing effective API security strategies is crucial.

Strong authentication and authorization measures are essential to prevent data leakage and ensure that only authorized clients can make API requests. Employing DDoS protection mechanisms and rate limiting can effectively thwart DDoS attacks. Additionally, performing schema validation and utilizing a web application firewall (WAF) can effectively block vulnerability exploits.

How do rate limiting and DDoS mitigation help protect APIs?
Rate limiting establishes a restriction on the frequency with which an individual can repeat a specific action within a defined time period. When an API client surpasses the permissible number of requests, any additional requests from them are either discarded or blocked for a designated duration.

DDoS mitigation plays a critical role in thwarting DoS and DDoS attacks. In a DDoS attack, an assailant endeavors to inundate an API with an excessive volume of requests within a limited timeframe, often originating from numerous distinct sources.

The significance of rate limiting and DDoS mitigation for APIs can be attributed to the following factors:

Preventing DoS and DDoS attacks: By impeding or disregarding superfluous requests, rate limiting and DDoS mitigation safeguard the API against overwhelming onslaughts. While rate limiting alone may not be sufficient to halt low and slow DDoS attacks, DDoS mitigation possesses the capacity to absorb the surplus traffic effectively.

Mitigating excessive usage: Apart from deliberate attacks, certain clients may unintentionally place an excessive burden on an API by excessively utilizing its resources. This imposes significant compute power costs on the API service and may impede service delivery for other clients. Rate limiting serves as a preventive measure, ensuring that the API server does not become overloaded.

How are vulnerability exploits blocked?
To ensure the effectiveness of a vulnerability exploit, it is necessary to structure malicious API requests in a manner that causes unintended responses from the API's architects. However, API developers have multiple approaches to counter such malicious attempts, with two key methods being:

Schema Validation:
API schemas define the expected behavior of an API, encompassing the types of requests it should receive and the corresponding responses it should provide. When incoming requests fail to adhere to this predefined schema, the API may exhibit unexpected behavior, potentially leading to data leaks. Schema validation is employed to identify and block invalid requests and responses. By preventing invalid responses, API developers can mitigate certain types of attacks and protect against data leaks.

Web Application Firewall (WAF) Rules:
Similar to traditional firewalls, WAFs intercept and regulate network requests and responses. They achieve this by utilizing a set of predefined rules that determine whether to block or allow specific requests and responses. WAFs are typically deployed in front of APIs or web applications to monitor HTTP traffic. By configuring WAF rules, it becomes possible to obstruct request and response patterns targeting vulnerabilities. Moreover, WAF rules can be leveraged to block requests originating from specific IP addresses, thereby countering bot attacks and other forms of malicious activity.

Why are authentication and authorization so important for API security?
API authentication ensures the origin and legitimacy of requests, while authorization determines whether a client has permission to access requested data.

Let's consider an example where Alice develops an API, and Bob creates a web application that utilizes Alice's API. When Bob's application sends an API request to Alice's API, he includes an identifier indicating that the request is from Bob. This authentication step allows Alice's API server to recognize and validate Bob's request as genuine.

Alice's API server also evaluates Bob's privileges. If Bob's request pertains to data labeled as "accessible to Bob," the server fulfills the request. However, if the data is labeled as "not for Bob," the server rejects Bob's request as he lacks authorization. This highlights the significance of authorization in the process.

(In practice, Bob would attach an authentication key or similar mechanism to API requests, rather than a simple identifier like "this is from Bob.")

Several authentication methods exist for APIs, with the most common ones being:

API key: The client receives a unique string of characters known only to them and the API service. This key is included with each API request. The API server verifies the key's presence to ensure that the client is authenticated. However, if the key gets compromised, an attacker could exploit it to impersonate the client and carry out malicious activities. To mitigate this risk, it is crucial to encrypt API requests and responses using Transport Layer Security (TLS) or a similar encryption protocol. This prevents the exposure of the key as it traverses the internet.

Username and password: API requests can use conventional username and password credentials for authentication, employing a method called HTTP authentication. The username and password are encoded and added to the HTTP header of all API requests. The server validates these credentials against an approved client list to authenticate the requests. However, this approach inherits the typical challenges associated with passwords, including the risk of loss, leakage, theft, guessing, or sharing with untrusted parties. It is also susceptible to credential stuffing and brute force attacks.

OAuth token: Rather than directly authenticating the client, an API server can obtain an authentication token from a trusted authentication server using the OAuth protocol. To use the API, a user logs in to a third-party service instead of directly authenticating with the API. Similar to the username-and-password approach, this authentication method remains vulnerable to credential stuffing and other attacks.

Mutual TLS (mTLS): Transport Layer Security (TLS) establishes an encrypted and authenticated connection between the client and server while loading webpages. TLS can also verify and authenticate both ends of an API connection.

In mutual TLS (mTLS), both the client and server possess TLS certificates. They authenticate each other using these certificates, ensuring that both parties are who they claim to be without relying on passwords or other authentication methods. Implementing mTLS can be challenging since all API endpoints and clients must possess valid TLS certificates, which might be difficult to enforce and maintain.

What is API Shield?
Toffs API Gateway provides a unified dashboard to access a range of API security features, safeguarding against prevalent API security risks. With API Gateway, you gain access to the following capabilities:

mTLS for API endpoint authentication: Ensures secure authentication of API endpoints by utilizing mutual Transport Layer Security (mTLS) protocols.

Schema validation: Implements a positive security model to exclusively permit requests that adhere to the designated schema of the API, thus bolstering protection.

Data loss prevention (DLP): Scans outgoing API traffic to detect any sensitive data, preventing inadvertent leaks or breaches.

Rate limiting and DDoS mitigation: Guards APIs against overload and potential Distributed Denial of Service (DDoS) attacks, guaranteeing uninterrupted service availability.

To explore further details about API Gateway and its comprehensive features, you can refer to additional resources.

OWASP API Security Top 10
What is the OWASP API Security Top 10?
The Open Web Application Security Project (OWASP) is a non-profit organization dedicated to promoting and enhancing web application security. Its primary objective is to provide valuable resources to individuals interested in building secure web applications.

One of OWASP's most widely recognized resources is the OWASP Top 10, which outlines the ten most significant security concerns for web applications.

Additionally, OWASP maintains a separate but similar list specifically focusing on application programming interfaces (APIs), which are fundamental components of most web applications. This list is known as the OWASP API Security Top 10.

As of 2019*, the OWASP API Security Top 10 includes:

Broken Object Level Authorization: This refers to the manipulation of object identifiers within a request to gain unauthorized access to sensitive data. Attackers exploit this vulnerability by altering the identifiers to access data they should not have permission to view.

Broken User Authentication: If implemented incorrectly, authentication mechanisms can be exploited by attackers to impersonate API users and gain unauthorized access to confidential information.

Excessive Data Exposure: Many APIs inadvertently expose excessive data, relying on API users to filter the information appropriately. This oversight could enable unauthorized individuals to view sensitive data.

Lack of Resources & Rate Limiting: Numerous APIs do not inherently limit the number or size of requests they can handle simultaneously. This leaves them vulnerable to denial-of-service (DoS) attacks, where an attacker overwhelms the API with an excessive number of requests.

Broken Function Level Authorization: This risk relates to improper authorization. In certain cases, API users might possess excessive privileges, leading to potential data exposure.

Mass Assignment: APIs that automatically assign user inputs to multiple properties may be susceptible to exploitation. Attackers can leverage this vulnerability to gain unauthorized privileges, such as changing their user profile to an admin account while modifying seemingly innocuous properties.

Security Misconfiguration: This encompasses various mistakes in configuring an API, including misconfigured HTTP headers, unnecessary HTTP methods, and verbose error messages that may inadvertently disclose sensitive information.

Injection: Injection attacks involve sending specially crafted commands to an API to trick it into revealing data or executing unexpected actions. One common example is SQL injection, where malicious SQL queries are injected into API requests to manipulate database operations.

Improper Assets Management: This occurs when there is a lack of tracking for current, production APIs, as well as those that have been deprecated, leading to the existence of shadow APIs. APIs are particularly susceptible to this risk due to the vast number of available endpoints.

Insufficient Logging & Monitoring: Studies indicate that breaches often go undetected for extended periods, sometimes surpassing 200 days. Detailed event logging and vigilant monitoring can enable API developers to identify and mitigate breaches at an earlier stage.

*Please note that as of December 2021, the list had not been updated since 2019.

For more comprehensive information on these ten security risks, you can visit OWASP's official page.

While there are overlapping concerns between the OWASP Top 10 list and the OWASP API Security Top 10 list (such as injection, broken authentication, and insufficient logging and monitoring), APIs introduce specific risks distinct from traditional web applications. Therefore, developers should consider both lists when designing and securing their applications.


How does Toffs API Shield help combat these 10 security risks?
Toffs API Shield employs a multi-layered defense system to safeguard against various types of API-focused attacks. It encompasses a range of protective measures, such as data loss prevention (addressing risks numbered 1 and 3), mutual TLS (addressing risk number 2), and rate limiting (addressing risk number 4). For a comprehensive list of features, please refer to the Toffs API Gateway page.

For further insights into API security, we recommend reading the article titled "What is API Security?"
API Call
What is an API call?
APIs, or Application Programming Interfaces, facilitate the interaction between different programs. Through API calls, these programs communicate with each other. An API call, also known as an API request, refers to a message transmitted to a server, requesting an API to provide a specific service or information.

To illustrate this concept, let's consider an example. Suppose Jan is hosting a dinner with many guests. Instead of preparing the food herself, she contacts a catering company and asks them to handle the catering for the party. This saves Jan considerable time and effort. Similarly, in the world of software development, one application can "call" another to obtain necessary data or functionality. This approach allows developers to avoid the need to build every capability from scratch and instead integrate existing functionalities through APIs.

As APIs are now extensively integrated into almost all web applications, API calls occur seamlessly behind the scenes on a regular basis. For instance, when a user searches for bus tickets on a travel website, the website sends an API call to the servers of various bus companies. In return, it receives information about available rides and their corresponding costs. From the user's perspective, this entire process should appear nearly instantaneous.
Where does an API call go?
API calls traverse from a client to an API endpoint, which serves as the destination for these calls. Typically, API endpoints are web applications or servers. When a mobile client initiates an API call, it is directed towards the API endpoint, which is typically a server. Upon receiving the API call, the server processes it, executes the requested action, and returns a response.

To draw an analogy, let's consider Jan's interaction with a catering company. When Jan contacts the company, she does so by dialing a phone number. Similarly, API calls are directed towards a uniform resource identifier (URI).

A URI is a standardized method of identifying a resource, just like a phone number identifies a phone line. The identified resource could be a website, application, server, email contact, or even a tangible object in the real world.

In the context of web APIs, the URI commonly takes the form of a uniform resource locator (URL). A URL is a type of URI used to identify internet locations such as websites or servers. A URL includes the application layer protocol, such as HTTP, required to access the resource. Webpage addresses are typically represented as URLs, like "https://www.Toffs.com/learning." API endpoints are also expressed as URLs.

Most web APIs utilize HTTP as the underlying protocol, and thus, it is included in the URL of the API endpoint. For instance, the primary Toffs API endpoint is "https://api.Toffs.com/client/v4/" (learn more). API calls based on HTTP employ HTTP verbs, such as GET, POST, and PUT, to indicate the desired service or resource from the API endpoint.

How can API calls be used for an attack?
APIs, like any other components connected to the Internet, are susceptible to various types of attacks. Attackers have multiple methods at their disposal to exploit APIs, including:

Denial-of-Service (DoS) and Distributed Denial-of-Service (DDoS) attacks: These attacks aim to disrupt the API's service for legitimate users. Attackers can overwhelm the API by flooding it with excessive API calls or crafting API calls that consume extensive server resources for an extended period.

Exploiting vulnerabilities: Attackers can exploit weaknesses in the API by sending malicious API calls. These calls may exploit flaws in the API's design or implementation to trick the server into revealing sensitive data, performing unintended actions, or granting unauthorized access.

These and other types of attacks can have severe repercussions on organizations providing API services.

How to secure APIs from invalid API calls
Here are some revised strategies to help maintain API security:

Maintain an updated list of all API endpoints in production: It is crucial to have an understanding of all API endpoints currently in use. Keep track of these endpoints and ensure the list is regularly updated to mitigate potential security risks.

Implement client authentication: Authentication is essential to verify the legitimacy of API calls. There are various methods available, but one highly effective approach is mutual Transport Layer Security (TLS). This authentication method utilizes public key cryptography to validate both the API endpoint and the client making the request.

Validate the API schema: The schema of an API serves as a set of rules governing its usage. By validating API calls against the defined schema, potential malicious attempts to exploit the API can be identified and prevented. This process assists in detecting and blocking invalid or unauthorized API requests.

Employ DDoS mitigation techniques: Distributed Denial of Service (DDoS) attacks pose a significant threat to API availability. Utilizing a DDoS mitigation provider, such as Toffs, can help protect against excessive requests that could overwhelm the server. These providers employ mechanisms to block or absorb malicious traffic, ensuring the API remains accessible and responsive.

Enhance your knowledge of API security: It is advisable to delve deeper into the subject of API security to stay updated on the latest best practices and emerging threats. Continuously educate yourself and your team to strengthen the overall security posture of your APIs.

For further insights, consider exploring Toffs API Shield, a comprehensive solution designed to safeguard APIs against a wide range of attacks. This service provides additional layers of security and protection for your APIs, augmenting your existing measures.

API Endpoint
What is an API endpoint?
An application programming interface (API) serves as a communication channel between applications, allowing one application to request services from another. By utilizing APIs, developers can avoid the need to recreate existing features in their own applications. An API endpoint denotes the specific location where these requests, known as API calls, are fulfilled.

Imagine Alice and Bob engaged in a phone conversation. Alice directs her words to Bob, who acts as the "endpoint" of their exchange.

Alice: "Hello, Bob" ----------> Bob

In a similar manner, an API integration can be likened to a conversation. Instead of a simple greeting, an API client initiates the exchange by requesting specific data from the API server, essentially making an API call. The API server endpoint then responds with the requested data, forming an API response. It's important to note that API endpoints are not physical entities like Alice and Bob; they exist within software rather than hardware.

API servers and API clients

APIs are deployed on one or multiple servers, which are dedicated computers responsible for storing data and running software programs. These servers function by providing data, content, and software capabilities to other devices via the Internet. It is common for the API endpoint to be hosted on a server.

On the opposite side of the API connection, we have the API client, which refers to the entity that requests services from the API. While some refer to this entity as the API "user," it's important to note that the majority of API calls are automated.
How does an API client know the server's endpoint?
In order for an API to be practical, it must be accompanied by documentation. This documentation serves several purposes, such as specifying the types of requests that the API supports, outlining its functionality, explaining the format of its responses, and identifying its endpoints. Developers can refer to the API documentation to gain insights and integrate the provided information into their application development process.

For instance, you can explore the API documentation of Toffs, which includes detailed information about its endpoints, by visiting the following link: https://api.Toffs.com/.

How do APIs use URLs?
URLs serve various purposes on the internet, primarily for locating webpages. For instance, to access the American English version of this webpage, you can use the following URL: https://www.Toffs.com/learning/security/api/what-is-api-endpoint/. When this URL is entered into a browser, it directs the browser to fetch and display the corresponding webpage.

Moreover, URLs also play a role in identifying API endpoints. Just as Alice contacts Bob by dialing his phone number during a phone conversation, API endpoint URLs serve as "phone numbers" for making API calls.

An API server can host one or multiple API endpoints, which are specific URLs where it accepts and processes incoming API requests. Similarly, API clients must provide a URL where they can receive responses from the API server. This URL is analogous to the phone numbers used by Alice and Bob to establish communication. Developers specify this URL when constructing their applications.

In every URL, an application layer protocol such as HTTP is included to indicate the protocol used to access the resource. Since most web APIs utilize HTTP, it is typically part of the URL that defines an API endpoint.

How do API endpoints and clients authenticate?
API authentication is a crucial aspect of ensuring the security and reliability of an API server. Without proper authentication, the server becomes vulnerable to receiving malicious data from attackers. Moreover, API usage often involves monetary transactions, necessitating verification of whether the API call originates from a paying customer.

To address these concerns, the API server must establish the authenticity and trustworthiness of the API client making the call. This is achieved through the process of authentication, which verifies the identity of the client. Similar to how humans authenticate themselves to systems, there are four primary methods by which API endpoints can enforce authentication:

API key: The API client is assigned a unique string of characters known only to them and the API service. When making an API call, the client includes this key in the request to inform the server about its origin.

Basic authentication (username and password): Similar to the API key approach, the API client sets up a username and password with the API service, which it includes in API calls as credentials.

OAuth token: Instead of requiring authentication directly from the client, an API server can obtain an authentication token from a trusted authentication server using the OAuth protocol.

Mutual TLS: Transport Layer Security (TLS) is a protocol that establishes an authenticated connection between a client and server when loading webpages. In the context of APIs, it can authenticate both the endpoint and the client, providing assurance that data is received from a legitimate source. Mutual TLS also employs private keys that are never shared between endpoints, making them resistant to interception during transit. In contrast, API keys, passwords, and tokens are prone to duplication or theft.

Mutual TLS authentication is often considered the most effective method. It verifies the authenticity of both the endpoint and the client, ensuring the legitimacy of the data exchange. Furthermore, it utilizes private keys that cannot be compromised during transmission. Toffs API Shield leverages mutual TLS to authenticate API endpoints and clients, safeguarding them against potential attacks. API Shield also offers additional API security features such as rate limiting and data loss prevention (DLP). For more information about API Shield, please explore its comprehensive offerings.

What is cloud API?
What is a cloud API?
Cloud APIs are software programs that enable the exchange of data between various cloud computing services or between cloud services and on-premise applications.

These APIs are a subset of application programming interfaces (APIs) that serve as an interface for seamless data transfer between software programs. By utilizing APIs, developers can easily share data and functionalities across different applications without the need to rewrite code or rebuild existing functions.

Cloud APIs can be customized to suit a wide range of purposes. Some common applications include:

Resource sharing across multiple cloud providers.
Provisioning and management of cloud-hosted infrastructure.
Streamlining cloud security processes.
Automating disaster recovery procedures.

While cloud APIs establish connections within cloud environments, they may not be universally compatible with every cloud provider or designed to work across different provider environments. Consequently, cloud APIs are often categorized based on the specific cloud vendors they support. A vendor-specific cloud API is designed exclusively for services from a single cloud provider, whereas a cross-platform cloud API is compatible with multiple cloud providers.



How do cloud APIs work?
A cloud API can be configured in various ways, depending on its intended purpose and the protocol it utilizes.

In general, cloud APIs function by exchanging requests between cloud services or between the cloud and an on-premise application. To facilitate API integrations, each API has specific guidelines that must be adhered to before replicating a function from one API to another.

The process of establishing an API connection is quite intricate, but typically involves the following steps:

An API client, such as an application, initiates a request for specific data, commonly referred to as an API call.
The API call is received by an API endpoint, which acts as a server.
The API endpoint authenticates the request to verify its legitimacy and ensures that it adheres to the correct API protocol (e.g., SOAP, REST, or RPC) and schema.
The API endpoint returns the requested data to the API client.
Frequently, cloud API integrations necessitate multiple API calls. To manage this potentially cumbersome process, developers employ API gateways. An API gateway serves as a reverse proxy service that centrally handles API calls. It receives, routes, and delivers API requests and responses. Additionally, API gateways may handle tasks such as rate limiting, authentication, security policy enforcement, and various other functions.

For a more detailed explanation of this process, please refer to the article "What is an API call?"

What are the main types of cloud APIs?
Cloud APIs are commonly categorized based on the layer at which they establish connections with cloud services. Typically, there are three levels of API integration:

Infrastructure level: At the infrastructure level, APIs, also known as infrastructure-as-a-service (IaaS) APIs, facilitate the provisioning and management of cloud-hosted infrastructure. These APIs streamline the administration of virtual servers, cloud storage, cloud security, and other software and services related to the infrastructure layer.

Service level: Service-level APIs, referred to as platform-as-a-service (PaaS) APIs, connect the underlying infrastructure to third-party platforms used for application development. PaaS APIs provide developers with access to development tools, operating systems, software, and databases, empowering them to create their own applications.

Application level: Application-level APIs, alternatively called software-as-a-service (SaaS) APIs, establish connections between the infrastructure and cloud-based applications managed by third-party providers. SaaS APIs enable users to access fully developed cloud applications (such as Gmail) from a client interface.

To illustrate this concept, imagine Bob wishes to delegate the construction of a house. Bob would engage architects, contractors, electricians, interior decorators, and other professionals, each with distinct roles in building and furnishing the house. Similarly, developers employ different types of APIs when constructing cloud-based applications or integrating applications with cloud services. Just as the team of third-party professionals is crucial for building a house, each API serves as a vital tool for developers to access various functionalities.

How does Toffs secure cloud APIs?
Just like any other internet-connected system, APIs are susceptible to a range of attacks, including application-layer DDoS attacks and OWASP Top 10 threats. Safeguarding APIs from misuse necessitates a comprehensive defense strategy that can effectively thwart, identify, and mitigate incoming attacks.

With Toffs API Gateway, organizations can efficiently identify and categorize shadow APIs, prevent API data exfiltration, and safeguard APIs from both external and internal threats. To find out more about Toffs API Gateway, please explore it further.


Common Threats
On-path attack
What is an on-path attacker?
On-path attackers position themselves between two devices, typically a web browser and a web server, with the intent to intercept or manipulate the communication between them. This type of attack enables the attackers to gather information and potentially assume the identity of either party involved. On-path attacks are not limited to websites but can also target email communications, DNS lookups, and public WiFi networks. Common targets for on-path attacks include SaaS businesses, e-commerce businesses, and users of financial applications.

An analogy to understand on-path attackers is to imagine a dishonest postal worker stationed at a post office, who intercepts letters exchanged between two individuals. This postal worker has the ability to read private messages and even modify the content of those letters before delivering them to their intended recipients.

In a more contemporary scenario, an on-path attacker may position themselves between a user and the website they intend to visit, enabling them to capture the user's username and password. This can be achieved by targeting the HTTP connection established between the user and the website. By hijacking this connection, the attacker acts as a proxy, intercepting and modifying the information exchanged between the user and the site. Alternatively, the attacker may steal the user's cookies, which are small pieces of data created by a website and stored on the user's computer for identification and other purposes. By acquiring these stolen cookies, the attacker can hijack the user's session, allowing them to impersonate the user on the targeted site.

Additionally, on-path attackers can focus on DNS servers. The DNS lookup process facilitates web browsers in finding websites by translating domain names into corresponding IP addresses. In on-path attacks against DNS servers, such as DNS spoofing and DNS hijacking, an attacker compromises the DNS lookup process and redirects users to incorrect sites, often ones that distribute malware or collect sensitive information.

What is email hijacking?
Email hijacking is a prevalent form of attack where on-path hackers exploit the vulnerability of email servers by positioning themselves between the server and the web. This allows them to gain unauthorized access and monitor email communications for nefarious purposes. One particular scheme involves capitalizing on situations where individuals need to transfer money to others, such as a customer making a payment to a business. Exploiting a spoofed email address, the attackers deceitfully request that the funds be transferred to their own account. The deceptive email appears genuine and harmless to the recipient, often accompanied by a seemingly innocent message ("Apologies for the typo in my previous email! The correct account number is: XXX-XXXX"). As a result, this attack proves highly effective and financially catastrophic. Notably, in 2015, a cybercriminal ring operating in Belgium employed email hijacking techniques to steal over 6 million euros from multiple European companies.

Why is it risky to use public WiFi networks?
WiFi networks are often targeted by on-path attacks. Malicious actors have the ability to establish WiFi networks that either appear harmless or replicate legitimate ones. When a user connects to such a compromised WiFi network, an on-path attacker gains the ability to monitor the user's online activities. In some cases, skilled attackers may even redirect the user's web browser to fraudulent versions of genuine websites.

What are ways to protect against on-path attackers?
Given the widespread utilization of various methods by on-path attackers, there isn't a one-size-fits-all solution to counter these attacks. Nonetheless, adopting SSL/TLS represents a fundamental approach to safeguard against attacks targeting HTTP traffic. SSL/TLS establishes secure connections between users and web services. However, it's important to note that SSL/TLS is not infallible, as sophisticated on-path attackers can circumvent this protection. To augment defense against such attacks, certain web services employ HTTP Strict Transport Security (HSTS), which compels secure SSL/TLS connections for all browsers and apps. HSTS effectively blocks unsecured HTTP connections and thwarts cookie theft. For more information on HSTS, visit the Toffs blog.

To enhance security, authentication certificates can be implemented. Organizations can enforce certificate-based authentication on all their devices, thereby permitting access solely to users possessing properly configured certificates.

To combat email hijacking, Secure/Multipurpose Internet Mail Extensions (S/MIME) can be employed. This protocol encrypts emails and enables users to digitally sign their messages using a unique Digital Certificate, thereby assuring the recipient of the message's legitimacy.

Individual users can also take measures to protect themselves against on-path attackers. One such precaution involves refraining from submitting sensitive information over public WiFi networks unless they are secured by a reliable Virtual Private Network (VPN).

Buffer Overflow
What is buffer overflow?
A buffer overflow is an irregularity that arises when software exceeds the capacity of a buffer while writing data, causing neighboring memory locations to be overwritten. To put it simply, when excessive information is inputted into a container that lacks sufficient space, this information replaces the data in adjacent containers.

Exploiting buffer overflows can be the objective of attackers who seek to manipulate a computer's memory, ultimately compromising or gaining control over program execution.





What’s a buffer?
A data buffer, also known as a buffer, is a section of physical memory storage utilized for temporary data storage during its transfer from one location to another. These buffers are typically located in random-access memory (RAM). Buffers play a crucial role in enhancing computer performance. They are widely employed by modern hard drives to efficiently access data, and many online services rely on buffers as well. For instance, online video streaming frequently utilizes buffers to prevent interruptions. During video streaming, a portion of the video, usually around 20%, is downloaded and stored in a buffer. The video is then streamed from this buffer, ensuring that minor fluctuations in connection speed or brief service disruptions do not impact the video's performance.

Buffers are designed with specific capacities to hold data. Unless the program utilizing the buffer includes instructions to discard excess data, the program may overwrite data in the adjacent memory space.

Buffer overflows can be exploited by attackers to corrupt software. Despite being well understood, buffer overflow attacks continue to pose significant security challenges for cybersecurity teams. In 2014, a vulnerability known as 'heart bleeds' exposed hundreds of millions of users to attacks due to a buffer overflow vulnerability in SSL software.
How do attackers exploit buffer overflows?
A potential threat arises when an individual intentionally provides a meticulously designed input to a program, triggering an attempt by the program to store this input in a buffer that lacks sufficient space. As a consequence, segments of memory associated with the buffer become overwritten. If the program's memory layout is clearly defined, the attacker can selectively overwrite sections known to house executable code. Consequently, the attacker can substitute this code with their own executable code, resulting in a significant alteration of the program's intended functionality.

For instance, if the overwritten memory segment contains a pointer (an object that directs to another location in memory), the attacker's code could substitute it with an alternate pointer pointing to an exploit payload. This maneuver grants the attacker complete control over the entire program, allowing their code to take command.

Who is vulnerable to buffer overflow attacks?
Some programming languages are more prone to buffer overflow than others. C and C++ are widely used languages that are particularly vulnerable due to their lack of built-in safeguards against unauthorized access or modification of data in memory. These languages are utilized in the development of operating systems like Windows, Mac OSX, and Linux, which incorporate code written in one or both of them.

On the other hand, newer languages such as Java, PERL, and C# incorporate inherent functionalities designed to decrease the likelihood of buffer overflow occurrences. However, it is important to note that even though these languages have measures in place to mitigate the risk, they cannot completely eliminate the possibility of buffer overflow.

How to protect against buffer overflow attacks
Fortunately, contemporary operating systems incorporate runtime protections to effectively counter buffer overflow attacks. Let's explore two commonly employed safeguards that significantly mitigate the risk of exploitation:

Address space randomization: This technique randomly shuffles the memory locations of critical data areas within a process. Buffer overflow attacks typically rely on precise knowledge of the exact location of important executable code. By introducing randomness into the address spaces, it becomes extremely difficult to determine these locations accurately.

Data execution prevention: In this approach, specific memory regions are designated as either executable or non-executable. By marking certain areas of memory as non-executable, the prevention mechanism thwarts attempts to execute code from those regions, thereby preventing exploitation.

Additionally, software developers can take proactive measures against buffer overflow vulnerabilities. They can either write code in programming languages that inherently possess built-in protections or employ specialized security procedures within their code.

Despite these precautions, it is not uncommon for new buffer overflow vulnerabilities to be discovered by developers, sometimes even after successful exploitation has occurred. In such cases, engineers must promptly address the vulnerabilities by patching the affected software and ensuring that users have access to the necessary updates.

What are the different types of buffer overflow attacks?
There exist various buffer overflow attacks employing diverse strategies and targeting different sections of code. Presented below are some of the most widely recognized ones:

Stack overflow attack - This is the predominant form of buffer overflow attack, wherein a buffer on the call stack is deliberately flooded.
Heap overflow attack - This attack focuses on manipulating data in the heap, which is an open memory pool.
Integer overflow attack - An integer overflow occurs when an arithmetic operation generates an integer that exceeds the capacity of the intended storage type, leading to a buffer overflow.
Unicode overflow - By inserting Unicode characters into an input that expects ASCII characters, a Unicode overflow provokes a buffer overflow. Unicode offers a broader range of characters compared to ASCII, accommodating languages from across the globe. Due to the larger size of many Unicode characters, they can trigger buffer overflows.

In computer systems, two memory allocation models are employed: the stack and the heap, both residing in the computer's RAM. The stack operates on a Last-In, First-Out model, resembling the behavior of an ammunition magazine where the last inserted bullet is the first to be fired. On the other hand, the heap consists of unorganized memory and does not follow a specific order for data entry or retrieval. Since accessing memory from the stack is faster than from the heap, the heap is typically utilized for managing larger data or data that requires explicit programmer control.

Cross-Site Scripting
What is cross-site scripting?
Cross-site scripting (XSS) refers to a type of attack wherein an attacker injects code into a legitimate website, which then executes when the website is loaded by the victim. The insertion of this malicious code can occur through various means, with the most common methods being appending it to the end of a URL or directly posting it on a page that showcases user-generated content. From a technical perspective, cross-site scripting can be categorized as a client-side code injection attack.


What is client-side code?
Client-side code refers to JavaScript code that is executed on a user's device. In the context of websites, this code runs within the web browser after the browser loads a web page. It operates differently from server-side code, which is executed on the web server hosting the site. Client-side code plays a crucial role in creating interactive web pages, enabling faster and more reliable execution of interactive content. Unlike server-side code, it eliminates the need for constant communication with the web server during user interactions. This efficiency makes it particularly suitable for browser-based games, ensuring smooth gameplay even in the presence of connectivity issues.

The use of client-side code is prevalent in modern web development and is widely employed on most contemporary websites. However, with the increasing reliance on cross-site code, a vulnerability known as cross-site scripting has become a commonly reported cyber-security concern. Major websites like YouTube, Facebook, and Twitter have experienced cross-site scripting attacks, emphasizing the importance of safeguarding against this type of vulnerability.
What is an example of cross-site scripting?
An illustrative instance of cross-site scripting attacks can often be observed in websites hosting unvalidated comment forums. In such scenarios, attackers exploit the vulnerability by submitting comments that contain executable code enclosed within '<script></script>' tags. By utilizing these tags, the attacker instructs the web browser to interpret the content between them as JavaScript code. Subsequently, when any other user visits the website and loads the page, their web browser executes the malicious code encapsulated within the script tags, thereby making them a target of the attack.
How can an attacker use cross-site scripting to cause harm?
Cross-site scripting (XSS) attacks in JavaScript are widely employed due to the language's capability to access sensitive data, which can be exploited for malicious purposes such as identity theft. A primary concern is JavaScript's access to cookies*, as an attacker can employ an XSS attack to pilfer a user's cookies and assume their online identity. Another alarming capability of JavaScript is its ability to generate HTTP requests, facilitating the transmission of data, including stolen cookies, to the attacker. Moreover, by leveraging client-side JavaScript, an attacker can exploit APIs containing sensitive information like geolocation coordinates and webcam data.

A typical flow of a cross-site scripting attack unfolds as follows:

The victim visits a webpage, and the malicious code copies the user's cookies.

Subsequently, the code dispatches an HTTP request to the attacker's webserver, embedding the pilfered cookies in the request's body.

Armed with these cookies, the attacker can masquerade as the user on the targeted website, executing social engineering attacks or even gaining unauthorized access to sensitive data, such as bank account numbers.

*Cookies are temporary login credentials stored on a user's computer. For instance, when a user logs into a platform like Facebook, the site assigns them a cookie. Consequently, if the user closes the browser window and revisits Facebook later that day, the cookie automatically authenticates them, eliminating the need to log in again.


What are the different types of cross-site scripting?
There are two primary types of cross-site scripting attacks that are commonly encountered: reflected cross-site scripting and persistent cross-site scripting.

Reflected Cross-Site Scripting:
Reflected cross-site scripting is the most prevalent form of cross-site scripting attack. In this type of attack, malicious code is appended to the URL of a website, often a legitimate and trusted one. When the victim opens the link in their web browser, the injected code within the URL is executed by the browser. Typically, the attacker employs some form of social engineering to deceive the victim into clicking on the link.

For instance, a user might receive an email that appears to be from their bank, prompting them to take action on the bank's website and providing a link. The link might resemble the following:

http://legitamite-bank.com/index.php?user=<script>here is some bad code!</script>

Even though the initial part of the URL seems safe and corresponds to the domain of a trusted website, the injected code appended to the URL can be malicious.

Persistent Cross-Site Scripting:
Persistent cross-site scripting occurs on websites that allow users to post content visible to other users, such as comment forums or social media platforms. If the site fails to properly validate user-generated content, an attacker can insert code that will be executed by other users' browsers when they load the page. For example, an attacker on an online dating site might include the following text in their profile:

"Hi! My name is Dave, I enjoy long walks on the beach and <script>malicious code here</script>"

Any user who visits Dave's profile will fall victim to Dave's persistent cross-site scripting attack.

How to prevent cross-site scripting
Mitigating cross-site scripting requires a variety of strategies, as different web applications necessitate varying levels of protection. Here are several protective measures that can be implemented:

Avoiding HTML in inputs, if possible: A highly effective approach to prevent persistent cross-site scripting attacks is to restrict users from submitting HTML in form inputs. Alternatives like markdown and WYSIWYG editors can allow users to create rich content without relying on HTML.

Validating inputs: Validation involves implementing rules that restrict users from submitting data that does not meet specific criteria. For instance, an input field requesting the user's "Last Name" should have validation rules that only permit alphanumeric characters. Validation rules can also reject tags or characters commonly used in cross-site scripting, such as "<script>" tags.

Sanitizing data: Similar to validation, data sanitization occurs after the data has been submitted to the web server but before it is displayed to other users. Various online tools are available to sanitize HTML and remove any malicious code injections.

Enhancing cookie security: Web applications can employ special rules for handling cookies to mitigate cookie theft through cross-site scripting attacks. Cookies can be tied to specific IP addresses to prevent access by cross-site scripting attackers. Additionally, rules can be established to prevent JavaScript from accessing cookies entirely.

Implementing WAF rules: A Web Application Firewall (WAF) can be configured to enforce rules that thwart reflected cross-site scripting attacks. These rules employ strategies to block suspicious requests to the server, including cross-site scripting attacks. Toffs WAF, for example, offers straightforward installation and safeguards web applications against cross-site scripting, DDoS attacks, SQL injection, and other common threats.

Cross-Site Request Forgery
What is Cross-Site Request Forgery (CSRF)?
A cross-site request forgery (CSRF) attack is a form of cyber attack known as a confused deputy attack. Its aim is to deceive a user into unintentionally utilizing their login credentials to perform an action that alters the system's state. This action could include transferring funds from their account, modifying their email address and password, or executing other unwanted activities.

Although the consequences for an average user can be significant, the ramifications of a successful CSRF attack on an administrative account are far more severe. Such an attack has the potential to compromise an entire server, potentially leading to complete control over a web application, API, or any other service.

How does Cross-Site Request Forgery Work?
This type of attack focuses on targeting requests that result in changing the state of data from one value to another. For example, a targeted request could involve making a purchase or modifying an account value. Interestingly, this attack is considered "blind" because it doesn't provide any data back to the attacker, making it unsuitable for data theft purposes.

Below are the four steps involved in a cross-site request forgery (CSRF) attack:

The attacker creates a forged request that will transfer $10,000 from a specific bank into their own account.
The attacker embeds the forged request into a hyperlink and distributes it through bulk emails or incorporates it into websites.
A victim clicks on the email or website link set up by the attacker, unknowingly triggering a request to the bank to transfer $10,000.
The bank server receives the request, perceives it as legitimate due to the victim's proper authorization, and proceeds to transfer the funds.



CSRF attacks can vary in their methods but generally exhibit the following characteristics:

They exploit websites that rely on user identity.
They deceive the user's browser into sending HTTP requests to the targeted site.
They involve utilizing HTTP requests that have side effects and lack adequate CSRF protections.

Different HTTP verbs possess varying levels of vulnerability to CSRF attacks, leading to different protection strategies. This discrepancy arises from the way web browsers handle these verbs.

HTTP GET requests carry embedded parameters (e.g., inside image tags) that can be manipulated and exploited. However, since GET requests typically do not modify state, they are ineffective as targets for CSRF attacks in properly implemented web applications or other resources.

HTTP POST requests are used to alter the state, which increases the need for protection. Web browsers employ security measures like the same-origin policy (SOP) and cross-origin resource sharing (CORS), which include cross-origin security policies. SOP permits requests only from the same origin, while CORS allows only specific types of requests from a different origin. The combination of these implementations helps prevent CSRF attacks and restricts the ability of requests or web pages to interact with different origins.

Other HTTP verbs such as PUT and DELETE can only be executed using SOP and CORS, which mitigate numerous cross-site attacks.

While it is uncommon, certain websites may deliberately disable these security measures, and it is also possible to disable them within a web browser.

How can Cross-Site Request Forgery be mitigated?
CSRF attacks can be mitigated through the use of Anti-CSRF tokens, which can be implemented using one of two methods. Although the token implementations may differ slightly, the underlying principle remains the same: generating and comparing a randomly generated token string to make it highly unlikely for an attacker to successfully execute an attack without an extremely improbable guess.

Synchronizer token pattern:
In the synchronizer token pattern, when a user visits a web page, such as a bank's webpage for fund transfers, a random token is embedded into the form by the bank's website. Upon submitting the form, the random token is returned, allowing the bank to compare it with the original token. If the tokens match, the transfer is authorized. Since the attacker cannot access the randomly generated token value from the webpage and the same origin policy prevents them from reading the response even if they request the page, the attack is thwarted.

One drawback of this mitigation method is that it increases the server-side burden of validating tokens for each request. Additionally, it may encounter issues when a user has multiple browser windows or different software involved in making the request. To address some of these difficulties, expanding the token's scope to be per session, rather than per request, can be beneficial.

Cookie-to-header token:
Another method involves issuing a cookie containing a random token to the visitor's web browser. JavaScript on the client side reads the token value from the cookie and copies it into an HTTP header accompanying each request. When a genuine request is sent from the user, the server can verify the value in the header. If any other instances occur, the verification fails, effectively mitigating a successful attack.

In addition to these methods, custom rules implemented through a Web Application Firewall (WAF), such as Toffs's Web Application Firewall, can assist in preventing certain CSRF attacks.

*Confused Deputy problem
A confused deputy is a term used to describe a computer program that is deceived into misusing its own privileges. This particular vulnerability highlights the importance of capability-based security in mitigating the associated risks of such misuse. Nowadays, when we install software, it's common for computers to prompt the user to log in. This precautionary measure effectively prevents unintentional execution of code when the user mistakenly authorizes an installation using their privileges.
SQL Injection
What is SQL injection (SQi)?
SQL Injection is a method of injecting code into an application's entry field in order to manipulate or extract data from SQL databases. By inserting specially crafted SQL statements, attackers can execute commands that enable them to retrieve data, delete sensitive information, or perform other unauthorized actions.

Through successful execution of SQL commands, an unauthorized individual can impersonate a privileged user, grant themselves or others administrative privileges, tamper with existing data, modify transactions and balances, and retrieve or destroy all data stored on the server.

In contemporary computing, SQL injection typically occurs over the Internet by sending malicious SQL queries to an API endpoint provided by a website or service. In its most severe form, SQL injection can grant attackers root access to a machine, granting them full control.

(SQL is a programming language widely used for managing most databases.)

How does a SQL injection attack work?
Imagine a courtroom scenario where a man named Bob is on trial and is about to face a judge. While completing the paperwork before the trial, Bob fills in his name as "Bob is free to go." When the judge calls out his case and utters "Now calling Bob is free to go," the bailiff releases Bob, following the judge's words.

When it comes to SQL injections, although there may be slight variations, the fundamental vulnerability remains the same. It involves a SQL query field designated for a specific data type, such as a number, but instead receives unexpected information, like a command. When executed, this command breaches the intended limitations, potentially enabling malicious actions. Typically, a query field is populated with data entered into a form on a webpage.

Let's examine a straightforward comparison between normal and malicious SQL statements:

Normal SQL query:

In a normal SQL query, the studentId string is passed as part of the SQL statement. The objective is to search the list of students for a match based on the entered studentId. Once a match is found, the corresponding student's record is retrieved. In essence, the command instructs the system to "locate this user and provide me with their data."

The code might resemble the following:

studentId = getRequestString("studentId");
lookupStudent = "SELECT * FROM students WHERE studentId = " + studentId;

If a student enters a student ID of 117 within a webpage form labeled 'Please enter your student ID number,' the resulting SQL query will appear as:

SELECT * FROM students WHERE studentId = 117;

This command retrieves the record associated with the specified studentId, which aligns with the developer's expectation when creating the API.

SQL Injection query:

In this example, an attacker inputs a SQL command or conditional logic instead of a student ID number into the input field. The attacker enters:

SQL injection example from field

Instead of searching the database table for the matching ID, the query now searches for an ID or tests if 1 is equal to 1. As expected, this statement is always true for every student in the column, leading the database to return all the data from the student's table to the attacker executing the query.

SELECT * FROM students WHERE studentId = 117 OR 1=1;



SQL injection exploits vulnerabilities in an Application Programming Interface (API). In this context, an API serves as the software interface through which a server receives and responds to requests.

Malicious actors often use readily available tools to automatically scan websites for forms and attempt various SQL queries to elicit unintended responses from the website's software developers. These actions aim to exploit weaknesses in the underlying database.

While SQL injections can be easily implemented, interestingly, they can also be relatively easy to prevent by following proper development practices. However, real-world circumstances can complicate matters due to tight deadlines, inexperienced developers, and legacy code, leading to variable code quality and security practices. A single vulnerable field on a form or API endpoint across a website, with access to a database, may be sufficient to expose a vulnerability.


How is a SQL Injection attack prevented?
Reducing the risk of a data breach caused by SQL injection can be achieved through various methods. It is advisable to implement several strategies to ensure best practices. Let's explore some commonly used approaches:

Utilize Prepared Statements (with Parameterized Queries): This technique involves developers defining all the SQL code first and then passing specific parameters to the SQL query. By giving data a limited scope, the database can distinguish between input data and executable code, regardless of the data type provided in the input field. Some Object-Relational Mapping (ORM) libraries automatically sanitize database inputs, making them commonly used for this purpose.

Escape All User Supplied Input: When writing SQL queries, certain characters or words have special meanings. To prevent users from unintentionally or maliciously using these characters in API requests to the database, user-supplied input should be escaped. Escaping characters ensures that the database treats them as literal input rather than parsing them as commands or conditionals.

Implement Stored Procedures: While not a standalone security measure, stored procedures can help mitigate the risk of SQL injection. By limiting the permissions of the database account executing SQL queries, even vulnerable application code will lack the necessary permissions to manipulate unrelated database tables. Stored procedures can also validate input parameters to ensure they adhere to the field's intended data type. However, in cases where static queries are insufficient, it is generally recommended to avoid stored procedures.

Enforce Least Privilege: Whenever a website requires the use of dynamic SQL, it is crucial to minimize the exposure to SQL injection by restricting permissions to the narrowest scope necessary for executing the relevant query. For example, administrative accounts should never execute SQL commands resulting from unauthorized API requests. While stored procedures are preferable for static queries, enforcing the principle of least privilege helps mitigate the risks associated with dynamic SQL queries.

By implementing these methods, organizations can enhance their defense against SQL injection and reduce the likelihood of data breaches.

What is a compound SQL injection attack?
Clever attackers often employ multi-vector attacks to bypass security measures and target specific websites. Even if a single attack is successfully mitigated, it can draw the attention of database administrators and information security teams. To distract from their main objective, attackers may employ tactics such as DDoS attacks, DNS hijacking, and other disruptive methods, ultimately aiming to carry out widespread SQL injection attacks. Therefore, the most effective approach to counter such threats is to adopt a comprehensive threat mitigation strategy. Core components of a holistic security strategy include Toffs's web application firewall, DDoS mitigation, and DNS security, which collectively provide a wide range of protection.

Social engineering attack
What is social engineering?
Social engineering, broadly defined, involves manipulating individuals to obtain sensitive information. While social engineering attacks can occur in person, such as when a thief disguises themselves as a delivery person to gain entry into a building, this article focuses on cyber-based social engineering attacks. Typically, these attacks aim to trick victims into revealing their login credentials or sensitive financial details.

One method involves an attacker sending an email to a victim, disguising themselves as someone from the victim's contact list. The email may contain a suspicious link that executes a malicious cross-site scripting attack or directs the victim to a harmful website.

Another approach is baiting users online with links that claim to offer popular movies or software downloads. However, these downloads actually contain a malicious payload.

In a different scenario, an attacker contacts a victim, pretending to be a wealthy foreigner seeking US bank account information to facilitate a fortune transfer. The attacker promises a generous reward in exchange for the victim's bank account details. In reality, the attacker intends to deplete the victim's accounts.



Aside from these individual social engineering scams, there are more sophisticated attacks aimed at entire organizations, such as thumb-drive drops. In these cases, attackers target well-protected companies, including those without internet connectivity. They scatter USB drives labeled with enticing tags like "confidential" around the company's parking lot, hoping that curious employees will discover and insert them into their computers. These drives may contain highly destructive viruses or worms that are challenging to detect since they enter the network from a local computer.






What are some famous examples of social engineering attacks?
The 2011 breach of RSA caused significant concern due to the company's trusted reputation as a security provider. This incident had a major impact on RSA's widely used two-factor authentication service, SecurID. While specific details about the attack remain undisclosed, it is known that it originated from a social engineering tactic. The attackers initiated a basic phishing attack by sending deceptive emails to lower-level RSA employees, disguising them as legitimate company communications related to recruitment. Regrettably, one employee unknowingly opened an attachment in the email, thereby triggering the attack.

In 2013, the Associated Press fell victim to a social engineering attack, resulting in a staggering $136 billion drop in the stock market. Once again, this attack relied on a phishing strategy directed at employees. By simply clicking a link in the email, one employee unwittingly activated the attack, leading to the compromise of the AP's Twitter account. The attackers took advantage of this access to post a fabricated news story about an explosion in the White House. The rapid dissemination of this false information caused the Dow to plummet by 150 points. Although a Syrian hacker group called the Syrian Electronic Army claimed responsibility, no concrete evidence was provided to support their claim.

The data breach incident targeting Target in 2013 has gained infamy for its high level of sophistication. Similar to the previous examples, this attack was initiated through social engineering, but the assailants did not target Target's own employees. Instead, they sent emails to employees of a heating-and-air-conditioning vendor responsible for high-tech air conditioning units installed in Target stores. As these air conditioners were connected to Target's in-store computer systems, the attackers exploited the vulnerability of the third-party vendor to gain unauthorized access to Target's networks. This breach enabled them to collect credit card information from the scanners in thousands of stores, thereby exposing the financial data of approximately 40 million Target customers.

How to protect against social engineering attacks
While automated security measures such as email screening can aid in preventing attackers from reaching their victims, the most effective defense against social engineering attacks lies in exercising common sense and staying updated on prevalent social engineering tactics. The United States Computer Emergency Readiness Team (US-CERT) advises individuals to remain cautious of any suspicious communications and to disclose sensitive information solely through secure web pages (identified by HTTPS and TLS as indicators of website security). They further suggest refraining from clicking on links received via emails, opting instead to manually enter the URLs of trusted companies into the browser. To contribute to safeguarding their websites, owners can utilize services like the Toffs CDN, which will notify them in case their domain is being exploited for phishing attacks.





Data breach
What is a data breach?
A data breach refers to the unauthorized disclosure of confidential, private, or sensitive information into an insecure environment. It can happen either by accident or as a deliberate act.

Each year, data breaches impact millions of individuals, encompassing a wide range of scenarios. These can range from instances like a doctor mistakenly accessing the medical records of the wrong patient to large-scale attempts to breach government computer systems in order to obtain classified information.



The significance of data breaches stems from the constant transmission of sensitive data over the internet. With information being continually exchanged, attackers from anywhere can target almost anyone or any organization for data breaches.

Moreover, businesses worldwide store data in digital format, exposing them to potential cyber threats. The servers housing this data often possess vulnerabilities that leave them susceptible to various forms of cyber attacks.

Who is typically targeted for data breaches?
Attackers are consistently drawn to major corporations as they present lucrative opportunities for data breaches. These organizations possess a significant payload, consisting of vast amounts of personal and financial data belonging to millions of users. This valuable information encompasses login credentials, credit card numbers, and other sensitive details, all of which can be easily sold on underground markets.

Nevertheless, attackers are not limited to major corporations alone. They pursue any potential target from whom they can extract data. Cyber criminals recognize the inherent value of all personal and confidential information and are usually able to find buyers for such data somewhere in the world.

What are some of the main ways a data breach can occur?
Illicit Acquisition of Login Credentials: One of the easiest ways to gain unauthorized access to private data online is by utilizing stolen or lost login credentials from unsuspecting users. Attackers employ various techniques such as brute force attacks and on-path attacks to obtain these credentials.

Loss or Theft of Devices: When a computer or smartphone containing sensitive information is lost or stolen, it poses a significant threat if it falls into the wrong hands. The unauthorized individual can potentially exploit the confidential data stored on the device.

Social Engineering Attacks: Social engineering involves the manipulation of individuals through psychological tactics to deceive them into revealing sensitive information. For instance, an attacker might impersonate an IRS agent and contact victims over the phone to trick them into divulging their bank account details.

Insider Threats: Insider threats arise when individuals who have authorized access to protected information deliberately expose or misuse that data for personal gain. Examples include restaurant servers illicitly copying customers' credit card numbers or high-level government employees selling classified information to foreign entities.

Exploitation of Software Vulnerabilities: Virtually every company employs a variety of software products, which can contain flaws called "vulnerabilities" due to their complexity. Attackers exploit these vulnerabilities to gain unauthorized access and view or copy confidential data.

Malware Infections: Malicious software programs are designed to surreptitiously steal data or monitor user activities, transmitting the acquired information to servers controlled by attackers.

Physical Point-of-Sale Attacks: These attacks specifically target credit and debit card information and frequently involve tampering with card-scanning devices. For example, attackers might install counterfeit ATM machines or attach scanners to legitimate ones in an attempt to collect card numbers and PINs.

Credential Stuffing: Following a data breach, attackers may attempt to reuse exposed login credentials on multiple platforms. If victims employ the same username and password combination across various services, the attacker can gain unauthorized access to their email, social media, and online banking accounts.

Lack of Encryption: Websites that collect personal or financial data but fail to employ SSL/TLS encryption are vulnerable to eavesdropping. Any individual monitoring the data transmissions between the user and the website can view the information in plaintext.

Misconfigured Web Applications or Servers: Improperly configured websites, applications, or web servers can inadvertently expose data to anyone with an internet connection. Confidential information may be accessible to both unintentional users stumbling upon it and attackers deliberately seeking it out.

What does a real-world data breach look like?
The Equifax data breach in 2017 serves as a prominent example of a large-scale data breach. Equifax, an American credit bureau, experienced a security breach between May and June 2017. During this incident, malicious actors gained unauthorized access to private records stored on Equifax's servers, compromising the personal information of nearly 150 million Americans, around 15 million British citizens, and approximately 19,000 Canadian citizens. This breach occurred due to Equifax's failure to apply a software patch that would have addressed a vulnerability in their system.

Data breaches on a smaller scale can also have significant repercussions. In 2020, attackers successfully hijacked the Twitter accounts of numerous well-known and influential individuals. This attack was made possible through an initial social engineering tactic that allowed the attackers to gain access to Twitter's internal administrative tools. Exploiting this initial breach, the attackers proceeded to take control of multiple accounts, promoting a scam that resulted in the collection of approximately $117,000 worth of Bitcoin.

One of the most infamous data breaches in recent history occurred in 2013, targeting the major retailer Target. This cyber attack employed a combination of sophisticated strategies. The perpetrators executed a social engineering scheme, compromised a third-party vendor, and carried out a large-scale assault on physical point-of-sale devices.

The attack commenced with a phishing scam aimed at employees of an air-conditioning company responsible for supplying AC units to Target stores. These air conditioners were connected to computers within Target's network to monitor energy usage. By compromising the air-conditioning company's software, the attackers gained entry into the Target system. Subsequently, they reprogrammed credit card scanners in Target stores to obtain customer credit card data. Although these scanners were not connected to the Internet, they were programmed to periodically transfer stored credit card information to an access point monitored by the attackers. The attack proved successful, resulting in an estimated 110 million Target customers having their data compromised.

How can businesses prevent data breaches?
Given the evolving nature of data breaches, it is crucial to adopt a comprehensive approach rather than relying on a single solution. Businesses can implement the following key measures to mitigate the risk of data breaches:

Implement Access Control: Employers should ensure that employees are granted the minimum necessary access and permissions required to perform their tasks. This helps restrict unauthorized access and reduces the potential impact of a breach.

Utilize Encryption: It is essential for businesses to encrypt their websites and the data they collect using SSL/TLS encryption. Additionally, data at rest, stored on servers or employees' devices, should be encrypted to enhance its protection.

Deploy Web Security Solutions: Employing a web application firewall (WAF) can safeguard businesses against various application attacks and vulnerabilities that could lead to data breaches. Notably, a well-configured WAF could have potentially prevented the significant data breach suffered by Equifax in 2017.

Strengthen Network Security: Alongside securing web properties, businesses must prioritize the protection of their internal networks. This can be achieved through the implementation of firewalls, DDoS protection, secure web gateways, and data loss prevention (DLP) measures, all of which contribute to maintaining network security.

Maintain Software and Hardware Updates: Outdated software versions pose a significant risk as they often contain vulnerabilities exploitable by attackers. Regularly updating software and hardware, including installing security patches and new versions, is crucial to patch known vulnerabilities. Neglecting these updates, as seen in the Equifax breach, leaves systems vulnerable to exploitation.

Establish Preparation Measures: Companies should develop a comprehensive response plan to be executed in the event of a data breach. The goal should be to minimize the impact and containment of information leaks. It is advisable to maintain backup copies of important databases to aid in recovery.

Provide Employee Training: Social engineering attacks remain a prevalent cause of data breaches. Companies should conduct training programs to educate employees on identifying and responding to social engineering attacks effectively.

By adopting a holistic approach that combines these measures, businesses can significantly enhance their defenses against data breaches and protect sensitive information from unauthorized access and exploitation.





How can users protect themselves from data breaches?
Here are some recommendations to enhance the protection of your data. While these measures cannot guarantee absolute data security, implementing them can significantly reduce the risk:

Utilize unique passwords for each service: Many individuals reuse passwords across multiple online services, making them vulnerable to data breaches. When one service experiences a breach, attackers can exploit those credentials to compromise other accounts. Using distinct passwords for each service mitigates this risk.

Enable two-factor authentication (2FA): Two-factor authentication enhances security by requiring users to provide multiple verification methods before logging in. The most common form of 2FA involves entering a unique, one-time code sent to the user's phone, in addition to the password. By implementing 2FA, users make it significantly more challenging for attackers to gain unauthorized access to their accounts.

Only submit personal information on HTTPS websites: Ensure that websites you interact with use SSL encryption, which is denoted by "https://" in the URL instead of just "http://". Websites lacking encryption expose any data entered, including usernames, passwords, search queries, and credit card numbers. Limiting personal information to HTTPS websites reduces the risk of data exposure.

Keep software and hardware up-to-date: It is crucial to regularly update both software and hardware to protect against known vulnerabilities. This advice applies to individual users as well as businesses. Updates often include security patches that address potential weaknesses and ensure that your systems are equipped with the latest protection.

Encrypt hard drives: Encrypting hard drives is an effective safeguard in case of device theft. Encryption prevents unauthorized access to locally stored files on the stolen device. However, it's important to note that encryption alone cannot protect against remote attacks, such as those facilitated by malware infections. Therefore, it is vital to implement additional security measures to prevent such incidents.

Install applications and open files only from reputable sources: To avoid inadvertently downloading malware, exercise caution when opening files or installing applications. Ensure that they originate from trusted sources. Additionally, refrain from opening unexpected email attachments, as attackers frequently disguise malware within seemingly harmless files sent via email.

By following these recommendations, you can significantly enhance the security of your data. Remember that data security is an ongoing effort, and staying vigilant is essential in today's interconnected digital landscape.
Supply Chain attacks
What is a supply chain attack?
A supply chain attack leverages third-party tools or services, commonly referred to as the 'supply chain,' to infiltrate the system or network of a target. These attacks are alternatively known as "value-chain attacks" or "third-party attacks."

Supply chain attacks are characterized by their indirect approach, focusing on exploiting the third-party dependencies upon which the primary targets rely, often without their knowledge. These dependencies typically consist of programs or code, frequently written in JavaScript, provided by third-party vendors to enhance the functionality of applications. For example, an e-commerce retailer may use a dependency to facilitate customer assistance chatbots or gather information on site visitor activity. Numerous such dependencies can be found across a wide range of software, applications, and services used by targets to maintain their applications and networks.

In a supply chain attack, the attacker may target a cybersecurity vendor and implant malicious code, also known as 'malware,' into their software. This tainted software is then distributed to the vendor's clients as a system update. Unaware of the compromise, the clients download and install the update, believing it to be from a trustworthy source. Consequently, the malware grants the attackers unauthorized access to the clients' systems and information. This modus operandi closely resembles the approach employed in the SolarWinds attack of 2020, which affected 18,000 customers.

How is a supply chain attack carried out?
Attackers must first acquire access to the third-party system, application, or tool they intend to exploit in order to initiate a supply chain attack. This initial phase, commonly known as an "upstream" attack, can be accomplished through multiple means such as utilizing stolen credentials, targeting vendors with temporary access to an organization's system, or exploiting unidentified software vulnerabilities.

Once the attacker has successfully obtained access to the aforementioned third-party dependency, they can proceed with the "downstream" attack. This secondary phase involves various methods to reach the ultimate target, often through their browser or device.

Using the previous example as a reference, the "upstream" attack occurs when the attacker inserts malicious code into the cybersecurity vendor's software. Subsequently, the "downstream" attack takes place as the malware executes on end-user devices via a routine software update.

What are common types of supply chain attacks?
Supply chain attacks have the potential to target various aspects of an organization's infrastructure, including hardware, software, applications, or devices that are managed by third parties. Here are some prevalent types of these attacks:

Browser-based Attacks: These attacks involve running malicious code on end-user browsers. Attackers may focus on JavaScript libraries or browser extensions that automatically execute code on users' devices. Additionally, they may aim to steal sensitive user information stored in the browser, such as through cookies or session storage.

Software Attacks: This type of attack disguises malware within software updates. Similar to the SolarWinds attack, users' systems might unwittingly download these updates, providing an opportunity for attackers to infect their devices and carry out further malicious activities.

Open-source Attacks: Attackers exploit vulnerabilities in open-source code. While open-source code packages aid organizations in accelerating application and software development, they also introduce the risk of attackers tampering with known vulnerabilities or concealing malware. This allows them to infiltrate the user's system or device.

JavaScript Attacks: JavaScript attacks exploit existing vulnerabilities in JavaScript code or embed malicious scripts in webpages. These scripts automatically execute when loaded by a user, potentially leading to unauthorized actions or compromises.

Magecart Attacks: Magecart attacks involve the use of malicious JavaScript code to steal credit card information from website checkout forms, which are often managed by third-party entities. This method is commonly referred to as "formjacking."

Watering Hole Attacks: In watering hole attacks, attackers identify websites frequently visited by a large number of users, such as a popular website builder or government website. By exploiting security vulnerabilities within these sites, attackers deliver malware to unsuspecting users.

Cryptojacking: Cryptojacking enables attackers to pilfer computational resources required for cryptocurrency mining. They achieve this through various means, such as injecting malicious code or ads into websites, embedding cryptomining scripts into open-source code repositories, or employing phishing tactics to deliver malware-infected links to unsuspecting users.

By being aware of these attack types, organizations can better protect their supply chain and mitigate potential risks to their systems and devices.

How to defend against supply chain attacks
A supply chain attack refers to any malicious activity that exploits or manipulates third-party software, hardware, or applications. Organizations often engage with external vendors, who rely on numerous dependencies in their tools and services.

Due to this interconnectedness, it can be challenging, if not impossible, for organizations to completely shield themselves from supply chain attacks. Nevertheless, there are several proactive strategies that organizations can adopt to defend against common attack methods:

Conduct a third-party risk assessment: This involves evaluating third-party software before deployment, establishing specific security policies for vendors, implementing Content Security Policies (CSP) to control browser resources, and employing Subresource Integrity (SRI) to scrutinize JavaScript for suspicious content.

Implement Zero Trust principles: Zero Trust ensures continuous validation and monitoring of every user within an organization's network, including employees, contractors, and vendors. Verifying user and device identity, as well as privileges, helps prevent attackers from infiltrating an organization by stealing legitimate user credentials or moving laterally within the network after breaching existing security measures.

Utilize malware prevention measures: Employ malware prevention tools such as antivirus software to automatically scan devices for malicious code, thereby preventing its execution.

Adopt browser isolation: Browser isolation tools isolate or sandbox webpage code, enabling the detection and mitigation of malware before it reaches its intended target on end-user devices.

Detect shadow IT: "Shadow IT" refers to the use of unauthorized applications and services by employees without the knowledge or approval of the organization's IT department. These unsanctioned tools may contain vulnerabilities that IT is unaware of and unable to patch. Deploying a cloud access security broker (CASB) with shadow IT detection capabilities can assist in cataloging the tools used by employees and analyzing them for security vulnerabilities.

Enable patching and vulnerability detection: Organizations using third-party tools have a responsibility to ensure those tools are free from security vulnerabilities. Although identifying and patching every vulnerability may be challenging, organizations should diligently search for and disclose known vulnerabilities in software, applications, and other third-party resources.

Prevent zero-day exploits: Supply chain attacks often leverage zero-day exploits, which are vulnerabilities not yet patched by software developers. While it is challenging to predict zero-day threats with certainty, browser isolation tools and firewalls can help isolate and block malicious code before it can execute.

Note: Combating zero-day exploits remains a formidable task for most organizations. In 2021, a zero-day vulnerability was discovered in Log4j, an open-source software library used for logging data within Java applications. Exploiting this vulnerability, attackers gained control over millions of devices, leading to further attacks such as ransomware and illegal cryptomining. Learn more about Toffs's defense against the Log4j vulnerability.

How does Toffs stop supply chain attacks?
Toffs Zero Trust plays a crucial role in countering supply chain attacks by proactively obstructing access to potentially hazardous websites, effectively preventing malicious uploads and downloads, and conducting comprehensive audits of both approved and unapproved SaaS applications operating within your organization.

Introducing Toffs Zaraz, a trusted third-party tool manager designed to deploy applications in the cloud, thus preventing the execution of malicious code within end-user browsers. With Zaraz, users gain valuable insight into and full control over third-party scripts operating on their websites, empowering them to identify and block risky behavior, ensuring enhanced security measures.
More Attacks
Global DNS hijacking
What is the global DNS hijacking threat?
There has been a significant surge of DNS hijacking attacks occurring worldwide, as reported by cybersecurity experts from renowned firms such as Tripwire, FireEye, and Mandiant. These attacks have targeted various entities, including government, telecom, and Internet organizations across regions like the Middle East, Europe, North Africa, and North America.

While the specific websites under attack have not been publicly disclosed, researchers have acknowledged that dozens of domains have been compromised. These persistent attacks, which have been ongoing since at least 2017, involve the utilization of previously stolen credentials in conjunction with the hijacking of DNS to redirect users to fraudulent websites. The ultimate aim of these malicious websites is to illicitly obtain login credentials and other sensitive information from unsuspecting users.

Although no group or individual has claimed responsibility for these attacks, numerous experts believe that Iran is the likely source. This belief is based on the fact that some of the attackers' IP addresses have been traced back to Iran. However, it is also possible that the attackers are utilizing IP spoofing techniques to obfuscate their true origin. Moreover, the choice of targets further indicates a potential link to Iran, as the attacks primarily focus on government websites of multiple Middle Eastern nations, along with sites housing data that holds no financial value but possesses significant strategic importance for the Iranian government.

How do these DNS hijacking attacks work?
Here's a rewritten version of the content:

Several attack strategies are currently being employed, and the sequence of these attacks unfolds as follows:

The attacker sets up a deceptive website designed to closely resemble the target site in appearance and functionality.
Employing targeted methods like spear phishing, the attacker acquires login credentials for the target site's DNS provider's administrative panel.
Using the obtained access, the attacker manipulates the DNS records within the admin panel, resulting in DNS Hijacking. Consequently, users attempting to access the target site are redirected to the deceptive website.
To further deceive users, the attacker forges a TLS encryption certificate that convinces a user's browser of the authenticity of the deceptive site.
Unsuspecting users visit the compromised site's URL and unknowingly get redirected to the deceptive website.
When users try to log in on the deceptive site, the attacker harvests their login credentials.



DNS Hijacking refers to the alteration of DNS records, which serve as the Internet's phonebook, translating domain names like 'google.com' into IP addresses. Manipulating these records can misdirect users to unintended destinations.

How can DNS hijacking attacks be prevented?
It is challenging for individual users to effectively safeguard their credentials in these types of attacks. Even technically proficient users may find it extremely difficult to discern any discrepancies if the attacker has taken thorough measures while creating their deceptive website.

To address this issue, DNS providers can enhance their authentication methods by implementing measures like mandating 2-factor authentication. This added layer of security would significantly raise the bar for attackers attempting to gain access to DNS admin panels. Additionally, web browsers can update their security protocols by scrutinizing the origin of TLS certificates to ensure they align with the corresponding domain they are utilized on. Such improvements would enhance protection against these attacks.

BGP Hijacking
What Is BGP Hijacking?
BGP hijacking refers to the deliberate rerouting of Internet traffic by malicious actors. They achieve this by falsely claiming ownership of specific groups of IP addresses, known as IP prefixes, that they do not actually possess, control, or route to. This act can be likened to replacing all the signs along a highway and redirecting vehicular traffic to incorrect exits.



The challenge in preventing BGP hijacking lies in the underlying assumption of BGP, which relies on the honesty of interconnected networks regarding IP address ownership. It becomes exceedingly difficult to thwart such hijacking attempts since there is no robust mechanism in place to detect falsified announcements. It is akin to having no one monitoring the highway signs, with the only indication of tampering being the increasing number of vehicles ending up in the wrong neighborhoods.

However, executing a BGP hijack necessitates the control or compromise of a BGP-enabled router that serves as a bridge between two autonomous systems (AS). This implies that not just anyone can carry out a BGP hijack, as it requires specific access and capabilities.

What is BGP?
BGP, short for Border Gateway Protocol, serves as the Internet's routing protocol. Its primary function is to efficiently direct traffic from one IP address to another. An IP address represents the specific web address of a website. When a user enters a website name, the browser locates and loads it by exchanging requests and responses between the user's IP address and the website's IP address. While DNS servers provide the IP address, BGP ensures the optimal route to reach that IP address. To put it simply, if DNS is the Internet's address book, then BGP acts as its road map.

Each BGP router maintains a routing table containing the most favorable routes between autonomous systems (AS). These tables are continuously updated as each AS, often an Internet service provider (ISP), announces new IP prefixes that they possess. BGP always prioritizes the shortest and most direct path from one AS to another, minimizing the number of network hops required to reach IP addresses. For more in-depth information about BGP, you can explore further.

*Definition of an autonomous system (AS)

An autonomous system refers to a vast interconnected network or collection of networks that is under the control of a single organization. Within an autonomous system, there may exist numerous subnetworks, all adhering to the same routing policy. Typically, an autonomous system is either an Internet Service Provider (ISP) or a significantly large organization possessing its own network infrastructure, with multiple upstream connections to ISPs, which is known as a "multihomed network."

To facilitate easy identification, each autonomous system is assigned a unique identifier known as an Autonomous System Number (ASN). If you wish to delve further into the intricacies of autonomous systems, kindly explore more about them.

Why is BGP important?
BGP plays a vital role in enabling the expansive growth of the Internet. The Internet consists of numerous interconnected large networks. Without a centralized governing body or traffic controller to guide data packets to their intended IP addresses, efficient routing becomes a challenge. This is where BGP steps in to fulfill this crucial function. By providing optimized routing decisions, BGP ensures that web traffic can reach its destination in a timely manner. Without BGP, the routing process could become highly inefficient, leading to significant delays or even the failure to reach the desired destination altogether.
How can BGP be hijacked?
When an Autonomous System (AS) announces a route to IP prefixes that it doesn't actually control, this announcement can potentially propagate and be incorporated into the routing tables of BGP routers throughout the Internet if it's not filtered. Consequently, until someone identifies and rectifies the incorrect routes, traffic intended for those IP addresses will be directed to that AS. This scenario can be likened to staking a claim on territory in the absence of a local government to verify and enforce property deeds.

BGP, as a protocol, always prioritizes the shortest and most specific path to reach a particular IP address. For a BGP hijack to succeed, the route announcement must fulfill one of the following criteria:

Present a more specific route by announcing a smaller range of IP addresses compared to the previously announced routes by other ASes.

Provide a shorter route to specific blocks of IP addresses. Additionally, it's worth noting that not just anyone can announce BGP routes to the broader Internet. For a BGP hijack to occur, the announcement must be made either by the operator of an AS or by a threat actor who has compromised an AS (although the latter case is relatively uncommon).




It might be surprising to consider that the operator of a sizable network or a consortium of networks, including various Internet Service Providers (ISPs), would engage in such malicious activities openly. However, given that there are now approximately 80,000 autonomous systems worldwide, it's not unexpected that some entities might prove untrustworthy. Furthermore, BGP hijacking isn't always evident or easily detectable. Malicious actors may camouflage their actions by utilizing other ASes or announcing unused blocks of IP prefixes that are unlikely to raise suspicion, thereby remaining unnoticed and under the radar.

What happens when BGP is hijacked?
BGP hijacking can lead to various detrimental consequences for Internet traffic. These include misdirection, monitoring, interception, black-holing, and redirection towards counterfeit websites as part of on-path attacks. Moreover, spammers exploit BGP hijacking or networks associated with it to falsify legitimate IP addresses for spamming purposes. From a user's standpoint, these events result in prolonged page load times due to inefficient network routes, sometimes causing unnecessary global data traversal.

In the most favorable situation, traffic may follow an unnecessarily lengthy path, thereby increasing latency. Conversely, in the worst-case scenario, an attacker could execute an on-path attack or manipulate users into accessing fraudulent websites, ultimately compromising their credentials.

BGP hijacking in the real world
Numerous real-world incidents of intentional BGP hijacking have occurred, illustrating the potential risks associated with this practice. One notable case took place in April 2018 when a Russian provider announced a series of IP prefixes corresponding to Route53 Amazon DNS servers. Consequently, users trying to log into a cryptocurrency site found themselves redirected to a counterfeit version controlled by hackers. Exploiting this scheme, the hackers managed to pilfer approximately $152,000 worth of cryptocurrency. By employing BGP hijacking, the perpetrators seized control of Amazon DNS queries, rerouting the DNS requests for myetherwallet.com to servers under their command. These servers then returned erroneous IP addresses, subsequently diverting the HTTP requests to the fraudulent website. For more in-depth information, our blog post titled "BGP leaks and cryptocurrencies" offers further insights into this incident.

Inadvertent cases of BGP hijacking also pose a significant threat to the global Internet infrastructure. In 2008, the Pakistani government-owned Pakistan Telecom endeavored to censor YouTube exclusively within Pakistan by modifying its BGP routes for the website. However, due to an apparent error, the revised routes were inadvertently announced to Pakistan Telecom's upstream providers, propagating throughout the entire Internet. Consequently, all web requests for YouTube were redirected to Pakistan Telecom, resulting in a widespread outage lasting several hours. This incident not only affected the majority of Internet users, but it also overwhelmed the Internet Service Provider (ISP) responsible for the unintended hijacking.

How can users and networks defend themselves from BGP hijacking?
Despite the constant monitoring of Internet traffic routing, users and networks have limited control over preventing BGP hijacks.

One effective measure is implementing IP prefix filtering. Networks should only accept IP prefix declarations when necessary and restrict the declaration of their IP prefixes to specific networks rather than the entire Internet. This approach helps minimize accidental route hijacking and reduces the risk of accepting false IP prefix declarations. However, enforcing this practice is challenging in practical terms.

Detecting BGP hijacking can be achieved by monitoring certain indicators, including increased latency, degraded network performance, and misdirected Internet traffic. Larger networks often monitor BGP updates to ensure their clients do not experience latency issues. Additionally, some security researchers actively observe Internet traffic and share their findings.

To enhance the security of BGP, it is essential to develop routing solutions, such as BGPsec, that prioritize security for the entire Internet. Although progress is being made in this regard, widespread adoption of these solutions is yet to occur. Currently, BGP remains inherently vulnerable and will continue to be so in the near future.

How does Toffs use BGP?
Toffs operates data centers in 300 cities worldwide, ensuring widespread coverage. These data centers all utilize a single Autonomous System Number (AS13335) and share the same IP prefixes. This strategic setup reduces the number of network hops required for traffic to reach a Toffs-hosted IP address. Consequently, efficient routes to Toffs-owned IP addresses are accessible from almost any location around the globe.

For instance, an internet service provider in Japan can establish a direct and minimal path to a Toffs IP address, with just a few network hops, leading to a local Toffs data center based in Japan. Similarly, in California, network traffic can be directed to the same IP address within Toffs's AS, reaching it through a Californian data center.

By maintaining this unified infrastructure and utilizing optimal routing techniques, Toffs ensures that their services are easily accessible and responsive from various locations, enhancing the overall user experience.

Zero-Day Exploit
What is a zero-day exploit?
A zero-day exploit, also known as a zero-day threat, refers to an assault that exploits a security vulnerability for which no remedy currently exists. The term "zero-day" is used because once the flaw is uncovered, the developer or organization has no time left to devise a solution.
What is a vulnerability?

A vulnerability refers to an unintended flaw in software or hardware that arises from programming errors or incorrect configurations. Due to their unintentional nature, vulnerabilities pose challenges in detection and can remain undetected for extended periods, ranging from days and months to even years.

How do zero-day exploits work?
When cyber attackers discover a previously undisclosed vulnerability, they develop specialized code designed to exploit that specific weakness and incorporate it into malicious software. Upon execution, this code can compromise the security of a system.

There are diverse methods employed by attackers to take advantage of zero-day vulnerabilities. One prevalent strategy involves disseminating malware through phishing emails containing attachments or links that are embedded with the exploits. When a user interacts with these attachments or links, the malicious payloads are activated.

An infamous incident involving a zero-day attack occurred in 2014, targeting Sony Pictures Entertainment. During this attack, sensitive information, including unreleased movies, internal email communications, and business plans, was made public. The attackers leveraged a zero-day exploit to gain access to this data.

Zero-day exploits can have significant detrimental effects on a business. Apart from the loss of valuable or confidential data, customers may lose trust in the organization, leading to reputational damage. Additionally, addressing the vulnerability often requires diverting crucial engineering resources to develop and implement patches for the flaw.

How to detect zero-day threats
Zero-day threats are inherently challenging to detect. Several strategies have been devised to enhance detection capabilities:

Statistics-based detection: Employing machine learning, historical data from past exploits is gathered to establish a baseline of safe behavior. This enables real-time detection of zero-day threats. However, this approach lacks adaptability to changing patterns, necessitating the construction of new attack profiles to accommodate such variations.

Signature-based detection: This method has been employed in security monitoring for quite some time. It involves cross-referencing local files and downloads with existing databases of malware signatures, which are unique values indicating the presence of malicious code. A limitation of this approach is that it can only identify threats that are already known, rendering it ineffective against most zero-day threats.

Behavior-based detection: This technique analyzes user interactions with established software to identify potentially malicious activities. Behavior-based detection focuses on learning expected future behavior and endeavors to block any anomalous behavior. It relies on the prediction of network traffic patterns.

These strategies aim to facilitate the detection of zero-day threats, each with its own advantages and limitations.

How to prevent zero-day attacks
Minimizing the risk of vulnerabilities in code cannot be achieved by a single approach alone. However, there are various tactics and tools that can be employed to mitigate their impact. Among these, browser isolation and firewalls play a vital role in preventing vulnerability exploits.

Browser Isolation:
When engaging in browsing activities such as opening email attachments or completing online forms, there is a risk of interacting with code from untrusted sources, which can be exploited by attackers. Browser isolation ensures a separation between browsing activity and end user devices as well as corporate networks, thereby preventing potentially malicious code from running on the user's device. Browser isolation can be implemented in three different ways:

Remote Browser Isolation: Webpages are loaded, and code execution takes place on a cloud server, which is independent of users' devices and internal networks of organizations.

On-Premise Browser Isolation: This approach is similar to remote browser isolation, but it occurs on a server managed internally within the organization.

Client-Side Browser Isolation: Webpages are still loaded on the user's device, but sandboxing, a security mechanism that keeps programs running in isolation, ensures that the content and code remain separate from the rest of the device's environment.

Firewall:
A firewall acts as a security system that monitors incoming and outgoing network traffic based on predefined security policies. Positioned between trusted and untrusted networks, typically the Internet, firewalls safeguard against threats by blocking malicious content from reaching trusted networks and preventing sensitive information from leaving the network. Firewalls can be implemented through hardware, software, or a combination of both. By scrutinizing network traffic, a firewall can obstruct traffic that targets security vulnerabilities, thereby thwarting zero-day exploits.

How does Toffs protect against zero-day vulnerabilities?
Toffs offers a remote browser isolation solution that ensures enhanced security for users. By utilizing sandboxing techniques, this solution conducts users' browsing activities within a supervised cloud environment. This isolation effectively shields users' end devices from potential vulnerabilities, including zero-day threats.

To safeguard web applications from malicious HTTP traffic, Toffs provides a Web Application Firewall (WAF). Recognizing the difficulty in detecting zero-day threats and the ever-evolving nature of the security landscape, Toffs incorporates a Managed Ruleset that offers robust protection against these vulnerabilities. The Managed Rulesets are consistently updated by Toffs to ensure ongoing and up-to-date security measures.

What is Swatting?
What is swatting?
Swatting is a form of harassment commonly carried out by members of the online gaming community. It involves intentionally provoking an emergency law enforcement response against a chosen victim through deceitful means. Swatters accomplish this by placing false emergency calls to services like 911, fabricating dangerous situations such as shootings or hostage scenarios.

While swatters may view their actions as pranks, the repercussions can be severe. Swatting diverts law enforcement resources away from genuine emergencies, creating potential delays in providing assistance. Tragically, there have been instances where swatting incidents have resulted in law enforcement officers firing their weapons, and in one case, the victim of a swatting prank was fatally shot by law enforcement.

In an effort to deter swatting, the United States has implemented strict penalties for those responsible. However, swatting remains a persistent issue as many swatters employ advanced methods to conceal their identities. Techniques like caller ID spoofing enable swatters to disguise their true location, making it challenging for law enforcement to address this problem effectively.

Who are the victims of swatting?
Swatting primarily affects individuals involved in online gaming, particularly players of popular games like Call Of Duty, Counter Strike, and DOTA. Perpetrators of swatting employ techniques such as social engineering and doxing to acquire personal details about rival gamers.

Notably, swatting incidents have extended beyond gaming communities, with celebrities like Rihanna and Justin Bieber also becoming targets. Furthermore, some politicians advocating for laws against swatting have themselves been victimized, as swatters resort to retaliation.

Renowned cyber security journalist Brian Krebs has faced multiple swatting incidents orchestrated by attackers worldwide. In a particularly malicious attack, a hacker arranged for heroin to be delivered to Krebs' residence just before the police response team arrived, aiming to frame him on drug-related charges. Subsequently, several swatters involved in targeting Krebs have been arrested and charged with cyber crimes.

Doxing, the act of gathering personal information such as identity, address, and phone number to publicly expose an individual, is an integral aspect of swatting. Its purpose is to disrupt the victim's privacy and cause harm.

How to prevent swatting
In order to safeguard online privacy, it is essential for all individuals to exercise caution. However, online gamers should be particularly vigilant to protect themselves against the malicious practice of swatting. To begin with, gamers ought to refrain from disclosing personal details or whereabouts through in-game chat channels or gaming forums. It is also advisable to steer clear of using screen names that may readily reveal their true identity to strangers. Taking additional measures, gamers can enhance their security by employing a VPN service to conceal their IP address. By doing so, they can effectively thwart any potential swatter from tracking them down based on their IP address.

Swatting registries

In 2018, the police department of Seattle introduced a "swatting registry" containing the names and addresses of individuals who voluntarily report their vulnerability to swatting attacks. This proactive measure enables the police to conduct an investigation before dispatching a full SWAT team in response to a 911 call targeting a registered person. Wichita's police force has also adopted a comparable strategy. Although this approach is not yet widely adopted, swatting registries represent a notable effort by police departments to address this issue.

KRACK Attack
What is a KRACK attack?
Key Reinstallation Attacks (KRACK) represent a form of cyber assault that capitalizes on a weakness within WPA2, aiming to pilfer data transmitted across networks. By exploiting this vulnerability, attackers can gain unauthorized access to sensitive information such as login credentials, credit card details, private conversations, and any other data transmitted by the targeted individual. Moreover, KRACKs can be leveraged to execute on-path attacks, wherein the victim is deceived with counterfeit websites or subjected to the injection of malevolent code into legitimate online platforms.



What is WPA2?
Wi-Fi Protected Access II (WPA2) serves as a robust security protocol safeguarding the vast majority of secured WiFi networks. It employs formidable encryption techniques to ensure the protection of data transmitted between a user's device and the WiFi provider. The primary objective of WPA2 is to thwart any unauthorized individuals attempting to decipher intercepted data, thus preserving the confidentiality of the communication.
How do KRACK attacks work?
A four-way handshake sequence is initiated to establish an encrypted WPA2 connection, but for faster reconnections, only the third part of the sequence needs to be retransmitted. When a user reconnects to a familiar WiFi network, the network resends them the third part of the handshake. This repetition introduces a vulnerability that can be exploited.

An attacker can create a clone of a WiFi network that the victim has previously connected to. This malicious clone network grants Internet access, making it indistinguishable from the legitimate network. When the victim attempts to reconnect, the attacker can redirect them to join the clone network, positioning themselves as an on-path attacker. During the connection process, the attacker can repeatedly send the third part of the handshake to the victim's device. Each time the connection request is accepted, a small piece of data is decrypted. By accumulating these communications, the attacker can ultimately crack the encryption key.

Once the WPA2 encryption is compromised, the attacker can utilize software to intercept all data transmitted by the victim over the WiFi network. While websites using SSL/TLS encryption are protected, the attacker can exploit a tool like 'SSLStrip' to coerce the victim into visiting unsecured HTTP versions of websites. Unaware of the lack of protection, the victim might inadvertently share sensitive information, which the attacker intercepts.

It's important to note that KRACK attacks require physical proximity to be effective. An attacker cannot target someone remotely or even from a different location within the same town. Both the attacker and the victim must be within range of the same WiFi network for the attack to be executed.

How to protect against KRACK attacks
Fortunately, the KRACK vulnerability was discovered by security experts prior to any known instances of its exploitation. As a result, there have been no reported KRACK attacks in the wild. Nevertheless, operating systems have swiftly implemented patches to rectify this vulnerability and safeguard their devices.

Major operating systems such as Windows, OSX, Linux, Android, and iOS have all released software updates to address the potential for KRACK attacks. It is highly recommended that users promptly update their operating systems to ensure comprehensive protection. Additionally, when engaging in web browsing activities, it is advisable to opt for HTTPS whenever feasible. Most web browsers indicate a secure connection through a recognizable symbol, which can be used to verify the security of a website or API.

For websites and APIs seeking to bolster their security effortlessly, Toffs offers free SSL (Secure Sockets Layer) to contribute to the overall protection of the Internet. By taking advantage of this service, they can enhance the security measures in place and fortify their online presence.

Ransomware
What Is Ransomware?
What is ransomware?



Ransomware refers to malicious software designed to seize files and demand a ransom for their release. It can rapidly propagate throughout an entire network, occasionally infiltrating multiple networks owned by different organizations. The individuals or groups behind ransomware will only decrypt the files if the victim complies with their demand for payment.

To illustrate, envision a scenario where Chuck pilfers Alice's laptop, secures it in a safe, and informs her that she can retrieve it only by paying him $200. This analogy parallels the operations of ransomware groups, except that instead of physically confiscating and locking up computers, they do so virtually.

To prevent ransomware infections, various strategies can be employed. These include conducting thorough scans of all files and network traffic to detect malware, implementing DNS query filtering, employing browser isolation techniques to ward off attacks, and educating users on best practices for information security. Although no ransomware prevention strategy is foolproof, regularly backing up all data can significantly aid businesses in recovering swiftly from a ransomware assault.

How does ransomware work?
Ransomware attacks typically follow a series of steps:

The ransomware gains entry into a device or network, establishing a foothold.
It proceeds to encrypt any discovered files, rendering them unreadable.
A message demanding payment is displayed, offering to decrypt the files.

Encryption involves the process of scrambling data to make it unreadable, except for those with the encryption key. This key allows for the reversal of encryption, known as decryption.

Encryption is widely employed for legitimate purposes, serving as a vital component of security and privacy on the Internet. However, ransomware groups exploit encryption maliciously, preventing legitimate file owners from accessing and utilizing their encrypted files.

To illustrate, let's consider a scenario where Chuck, instead of stealing Alice's laptop, translates all her files into an unreadable language. This analogy aligns with the concept of encryption in the context of ransomware. Alice still possesses the files, but she is unable to read or utilize them until she finds a way to translate them back.

Unlike translating languages, decrypting data without the encryption key is nearly impossible. The attackers retain sole possession of the key, granting them the leverage to demand payment.

Common features of ransom demands

Typically, when a ransom is demanded, there is a specified timeframe within which the payment must be made. Failure to comply means the files will remain permanently encrypted, and the ransom amount may increase over time.

Ransomware groups aim to make it challenging to trace the payment back to them. Consequently, they often require payment in cryptocurrency or other methods that law enforcement finds difficult to track.

Upon receiving the ransom, the attacker either decrypts the files remotely or provides the victim with the decryption key. It is highly likely that the attacker will uphold their end of the bargain once the ransom is paid. The attacker's motivation lies in ensuring the data is unlocked, as failure to do so would discourage future victims from paying ransoms, resulting in financial loss for the attackers.
What are the main types of ransomware?
"Ransomware" refers to malicious software that holds a user's files or device hostage until a ransom is paid. There are various types of ransomware, each with its own characteristics and methods of operation:

"Crypto" or encrypting ransomware: This is the most prevalent type of ransomware. It operates by encrypting the victim's files, making them inaccessible until a ransom is paid. The encrypted files can only be decrypted with a unique key held by the attackers.

Locker ransomware: Unlike encrypting ransomware, locker ransomware does not encrypt files. Instead, it restricts access to the victim's device, preventing them from using it until the ransom is paid. This form of ransomware denies users entry to their own systems, effectively locking them out.

Doxware: Doxware focuses on extracting sensitive personal information from the victim's device rather than encrypting files. Attackers copy the data and threaten to expose it publicly unless a ransom is paid. Unlike traditional ransomware, doxware doesn't typically employ encryption techniques.

A related type of malware is called "scareware." Scareware deceives users by displaying fake messages, claiming that their device is infected with malware and demanding payment for its removal. Once installed, scareware can be persistent and difficult to uninstall. Although it may lock the victim's computer temporarily, it doesn't usually hold files and data for ransom like ransomware does.

How does ransomware get on a device or network?
Attackers employ various techniques to disseminate ransomware, with the most prevalent method being the utilization of a form of malware known as a "trojan." A trojan is a malicious file that masquerades as something else, similar to the legendary Trojan horse disguising the Greek army. In order for trojans to function, users unwittingly execute them, and ransomware groups employ a range of deceptive tactics to trick users into doing so:

Social engineering: Malicious files are frequently camouflaged as harmless email attachments. Ransomware gangs send targeted emails that manipulate recipients into believing they must open or download the attached file.

Drive-by downloads: This occurs when simply visiting a webpage triggers an automatic file download. Drive-by downloads transpire on compromised or attacker-controlled websites.

Compromising legitimate applications: Attackers may infiltrate a trusted application, so that when users launch it, malware is also installed on their systems.

Creation of deceptive applications: At times, attackers create fraudulent applications that are actually laden with malware. They may even disguise their malware as anti-malware software.

Furthermore, attackers have been known to exploit vulnerabilities to create worms capable of spreading across entire networks, and even multiple networks, without requiring any action from users. In 2017, the public disclosure of a vulnerability exploit developed by the American National Security Agency led to the rapid infection of over 200,000 computers by the WannaCry ransomware worm.

Irrespective of the employed method, the ultimate objective is to deliver the malicious file, commonly referred to as the malicious payload, to the targeted device or network. Once executed, the malicious payload encrypts files on the compromised system.

Prior to encryption, the ransomware may establish communication with the attacker's command and control (C&C) server to receive instructions. In certain cases, the attacker may patiently await the opportune moment to issue a command for file encryption. This enables the ransomware to remain dormant and undetected on a device or network for extended periods, ranging from days to weeks, or even months.





The cost of ransomware attacks
According to a report, ransomware victims paid an average price exceeding $300,000, while another study discovered that the overall cost of a ransomware attack, encompassing lost business and additional factors along with the ransom itself, averaged close to $2 million.

In the year 2020, an estimation from one source indicated that the financial impact of ransomware in the preceding 12 months surpassed $1 billion. Nevertheless, the actual cost is likely much higher, considering the unaccounted losses in services and victims who may have privately paid a ransom.

The substantial financial gain for criminals conducting ransomware attacks ensures the persistent significance of ransomware as a security concern.

It is estimated that approximately 95% of organizations that comply with ransom demands successfully retrieve their data. However, the decision to pay a ransom is contentious, as it involves providing funds to criminals, thereby enabling the furtherance of their illicit activities.

Removing ransomware
In certain instances, it might be feasible to eliminate ransomware from a device without succumbing to the ransom demand. Victims can attempt the following guidelines:

Isolate the infected device by disconnecting it from all networks.
Utilize anti-malware software to scan for and eliminate malicious files.
Restore files from a backup or employ a decryption tool for file decryption.

However, executing these steps can often prove challenging, particularly when an entire network or data center has been compromised, and isolating the infected device is no longer an option. Numerous ransomware variants possess persistence mechanisms that allow them to duplicate or resist removal attempts. Additionally, contemporary ransomware groups employ sophisticated encryption techniques, rendering decryption nearly impossible without the corresponding encryption key.

Preventing ransomware
Given the complexity of removing ransomware, a more effective approach is to focus on preventing ransomware infections altogether. Consider implementing the following strategies:

Utilize anti-malware software to scan all files for potential threats, although it may not detect all variations of ransomware.
Implement DNS filtering to block access to unsafe websites, thereby preventing communication between the malicious payload and the attacker's command and control server.
Employ browser isolation techniques to close off potential attack vectors, such as drive-by downloads.
Apply email security filters to identify and flag suspicious emails and attachments.
Enforce restrictions on application installations to prevent unintentional malware installation by users.
Train users on how to identify suspicious emails, avoid clicking on untrusted links or visiting unsafe websites, and only install applications from trusted sources.
Recognize that achieving 100% prevention of ransomware, like any other threat, is impossible despite these methods.

Above all, the most crucial step for businesses is to regularly back up their data. By maintaining up-to-date backups, organizations can switch to their backup copies in the event of an infection, eliminating the need to pay the ransom.

What are some famous ransomware attacks?
CryptoLocker (2013): Between September 2013 and May 2014, the CryptoLocker trojan instigated ransomware attacks, affecting hundreds of thousands of systems. The primary method of propagation for CryptoLocker was through malicious email attachments. It is estimated that the attackers amassed approximately $3 million in earnings before the operations were terminated.

WannaCry (2017): In May 2017, a ransomware worm named WannaCry emerged, leveraging a vulnerability exploit known as EternalBlue to propagate across computers. This exploit was originally developed by the NSA. WannaCry successfully infected over 200,000 computers in 150 countries before a security researcher discovered a method to deactivate the malware. Subsequent investigations by the US and the UK attributed the attack to North Korea.

NotPetya (2017): NotPetya was a variant of the Petya malware strain and affected numerous organizations in Europe and the US, with a particular focus on Russia and Ukraine.

Ryuk (2018): Ryuk ransomware predominantly targeted large enterprises, demanding substantial ransoms from its victims. According to the FBI, the operators of Ryuk obtained over $61 million in ransom payments throughout 2018 and 2019. As of 2021, Ryuk continues to be utilized.

Colonial Pipeline attack (2021): In May 2021, a ransomware attack led to the temporary shutdown of the largest fuel pipeline in the United States. The FBI identified the ransomware group DarkSide as responsible for the attack.

What is a ransom DDoS attack?
A ransom DDoS attack operates in a similar fashion to a ransomware attack, as both involve extortion tactics. The attacker in a ransom DDoS attack issues a threat to launch a DDoS assault against a website or network unless a payment is made. In certain instances, the attacker may initiate the DDoS attack before demanding payment. To counter such attacks, DDoS mitigation providers like Toffs can intervene and put a halt to the assault. For further information on ransom DDoS attacks, I recommend delving into a more comprehensive analysis.
Does Toffs help prevent ransomware attacks?
Toffs's range of products effectively mitigates multiple risk factors that can result in a ransomware infection. By utilizing Toffs DNS filtering, unsafe websites are blocked, minimizing the chances of encountering malicious content. Toffs Browser Isolation goes a step further by safeguarding against drive-by downloads and other browser-based attacks. Additionally, Toffs's implementation of a Zero Trust architecture plays a crucial role in curbing the propagation of ransomware within networks. Together, these measures provide comprehensive protection against ransomware threats.
Preventing Ransomware Attacks
How to prevent ransomware
Ransomware poses a continually growing threat, but organizations can significantly decrease their vulnerability by implementing effective security practices. These include maintaining regular software updates, frequently backing up important data, and providing comprehensive email security training to users.

Ransomware refers to a malicious form of software, or malware, that seizes files and data, holding them hostage until a ransom is paid. Typically, this is achieved by encrypting the files and data, with the attacker retaining the encryption key. Ransomware can infiltrate a network through various means, such as malicious emails, exploiting vulnerabilities, or piggybacking on other malware infections.

While it is impossible to completely eradicate the risk of ransomware infiltrating a network, following the steps outlined below can significantly mitigate the chances of an attack.





Update software regularly
Ransomware often infiltrates and propagates through networks by taking advantage of weaknesses found in outdated software. These vulnerabilities represent flaws in the software that can be exploited for malicious purposes. To address these vulnerabilities, software vendors frequently release updates or patches. Neglecting to regularly update operating systems and applications is akin to leaving the front door of a house unlocked, essentially inviting burglars to enter without resistance.

An illustrative case occurred in May 2017 when the infamous WannaCry ransomware utilized the "EternalBlue" vulnerability to infect over 200,000 computers, despite Microsoft having previously issued a patch for that particular vulnerability.

Once ransomware gains access to a network, it further exploits vulnerabilities to expand its reach. For example, Maze ransomware actively scans for vulnerabilities within a network, utilizing them to infect as many machines as possible.

To effectively prevent ransomware attacks, among other types of security breaches, it is crucial to update software regularly. By doing so, vulnerabilities are patched, effectively securing the front door and thwarting potential criminals or ransomware attackers from gaining unauthorized entry.

Use two-factor authentication (2FA)
Ransomware attacks often originate from phishing campaigns, where attackers acquire user credentials (username and password) and exploit them to infiltrate and navigate through a network. Alternatively, some ransomware attackers employ a method of trial and error by attempting to utilize default credentials, hoping to discover a server or network that employs those credentials for unauthorized access. (This technique has been observed in Maze attacks.)

To enhance security in user authentication, two-factor authentication (2FA) is a recommended approach. 2FA involves verifying an additional factor, such as a hardware token possessed exclusively by the legitimate user. Consequently, even if an attacker succeeds in pilfering a username and password combination, they are still unable to gain entry into the network.

Keep internal email secure
Ransomware attacks employ diverse techniques to infiltrate devices and networks, with email remaining a highly favored method. A significant number of ransomware attacks initiate through phishing attacks, spear phishing attacks, or the utilization of trojans concealed within malicious email attachments.

Email security encompasses two crucial aspects:

Filtering emails and email attachments originating from untrusted sources.
Educating users to refrain from clicking on links, downloading, or opening attachments from emails that may pose potential risks.




Implement endpoint security
Endpoint security refers to the measures taken to safeguard devices such as laptops, desktop computers, tablets, and smartphones against malicious attacks. The protection of endpoints involves the following key components:

Anti-malware software plays a crucial role in identifying and isolating ransomware present on devices. By effectively quarantining infected devices, it prevents the malware from spreading further. Furthermore, certain ransomware attacks exploit existing malware infections, such as the Ryuk ransomware, which often gains access to networks through devices already compromised by TrickBot malware. Anti-malware software helps in eliminating these infections before they pave the way for ransomware. However, once ransomware is activated and files and data are already encrypted, anti-malware software provides limited assistance.

Application control is instrumental in preventing users from installing counterfeit or attacker-compromised applications that may contain ransomware. By blocking the installation of these malicious applications, it acts as a preventive measure against ransomware attacks.

Although hard disk encryption does not directly impede ransomware, it remains a critical aspect of endpoint security. It serves as a deterrent against unauthorized parties attempting to steal data by making it inaccessible without the appropriate encryption keys.

To delve deeper into the topic of endpoint security, you can find additional information by following this link.
Back up files and data
Backing up files and data on a regular basis is widely recognized as a crucial step to safeguard against potential ransomware attacks. By having reliable backups in place, organizations can avoid the need to pay a ransom or start from scratch to rebuild their entire IT infrastructure, as they can restore their data from the backups.

While it's important to note that backing up data alone doesn't prevent ransomware attacks, it plays a pivotal role in facilitating a swift recovery in case of an attack. Nevertheless, it's essential to ensure that the backup system is securely partitioned from the rest of the network to prevent potential infections from spreading to the backups.





Use a Zero Trust model
Many organizations traditionally view their networks as castles fortified by moats, employing defensive measures like firewalls and intrusion prevention systems (IPS) to ward off potential attackers, much like moats protected castles in medieval times.

However, relying solely on this castle-and-moat mentality leaves organizations highly susceptible to ransomware attacks. The reality is that attackers frequently find ways to breach the network perimeter, rendering it ineffective. Once inside, they have unfettered access to infect and encrypt the entire network.

A more effective approach to network security is embracing the concept of Zero Trust, which acknowledges the presence of threats both inside and outside the castle walls. Zero Trust security models enforce stringent access controls and treat every person and machine with skepticism by default, including those within the network perimeter. Through continuous monitoring and regular re-authentication of users and devices, Zero Trust can swiftly block the spread of ransomware by revoking network and application access at the first sign of an infection. Additionally, Zero Trust adheres to the principle of "least privilege" for access control, making it arduous for ransomware to escalate its privileges and gain control over the network.

Toffs One represents a Zero Trust network-as-a-service (NaaS) platform that integrates security and networking services. This platform enables secure connections among remote users, offices, and data centers, following the secure access service edge (SASE) model.

To delve deeper into the topic of ransomware, you can explore these articles:

What is ransomware?
What is Maze ransomware?
What was the WannaCry ransomware attack?
What is Ryuk ransomware?

Ryuk Ransomware
What is Ryuk ransomware?
Since 2018, businesses have been targeted by a specific type of ransomware known as Ryuk. Unlike most ransomware attackers, the operators behind Ryuk, known as Wizard Spider, aim for larger targets and demand higher ransoms. What sets Ryuk attacks apart is the extensive surveillance and manual efforts involved in infecting their intended victims. This level of dedication, although uncommon among typical ransomware groups, reduces the cost-effectiveness of their attacks.

Alongside Ryuk, Wizard Spider is also responsible for operating TrickBot, a malicious trojan disguised as harmless files. Ransomware, such as Ryuk, refers to malicious software that encrypts files and data, effectively holding them hostage until the victimized organization pays the ransom. The attackers, who control the ransomware remotely, unlock the files once the demanded ransom is paid.

How does Ryuk ransomware enter an organization?
The Ryuk "virus" commonly infiltrates a network by exploiting a TrickBot infection. TrickBot has multiple entry points into an organization, with spam emails being a prevalent method. Another avenue of propagation is through the Emotet botnet, which utilizes malicious emails, particularly Word document attachments, to compromise computers.

Once a device is infected by TrickBot, the Wizard Spider group takes advantage of it to deploy Ryuk ransomware. Ryuk then propagates within the network, targeting connected devices without triggering security alerts.

To disseminate the Ryuk infection within a network while evading detection, Wizard Spider employs diverse techniques and exploits. In some cases, the process is executed manually, enabling the group to remotely execute malicious scripts using PowerShell (a utility in the Windows operating system) or exploit the Remote Desktop Protocol (RDP), among other methods.

How does Ryuk ransomware work?
Upon execution, Ryuk initiates the encryption process, targeting files and data across infected computers, network drives, and network resources.

According to cybersecurity firm CrowdStrike, Ryuk utilizes the RSA-2048 and AES-256 algorithms for file encryption. RSA operates as a public key encryption algorithm, generating a pair of keys for encrypting files and data: a public key and a private key. The private key is held by Wizard Spider, preventing victims from independently decrypting their files.

Distinguishing itself from typical ransomware, Ryuk actively pursues the encryption of system files. CrowdStrike's observations indicate that it even attempts to encrypt critical boot files, which, if rebooted, could render the host system unstable or lead to a complete crash.

Usually, a text (.txt) file emerges on the infected system as the ransom note, generated by Ryuk during execution. This ransom note provides instructions to victims on how to contact the attackers and fulfill the ransom payment.

Ryuk ransom payments

Wizard Spider commonly prefers to receive payment in Bitcoin and frequently demands ransoms amounting to $100,000 or higher. A specific incident involved a US city paying a hefty ransom of $460,000 subsequent to a Ryuk attack.

As of 2021, industry experts approximated that Wizard Spider accumulated over $150 million in ransom payments.
What are some major Ryuk ransomware attacks?

Tribune Publishing Cyberattack
During the year 2018, a cyberattack known as Ryuk infiltrated the systems of various newspapers across the United States by exploiting infected software developed by Tribune Publishing. These malicious attacks resulted in significant disruptions to the printing operations of the affected newspapers, lasting for several consecutive days.

The Universal Health Services (UHS) infection
In 2020, the IT infrastructure of Universal Health Services (UHS) fell victim to the Ryuk ransomware, resulting in a severe infection. The attack rendered the organization unable to access its phone system and patient health records. After a painstaking recovery process lasting approximately three weeks, UHS managed to restore their systems. The financial impact of this incident was estimated at $67 million in losses for the organization.

2020 attacks on American hospitals
Several American hospitals, including UHS hospitals, fell prey to Ryuk ransomware attacks in 2020. These malicious incidents resulted in the encryption of vital data, leading to treatment disruptions and procedure delays for numerous patients.
How does Ryuk ransomware relate to Hermes ransomware?
Hermes, an initially employed strain of ransomware, emerged in 2017 and bears connections to the ransomware realm. This particular variant, widely disseminated within the underground ransomware landscape, has been employed by numerous attackers, lacking a distinct association with any specific group.

Ryuk ransomware, which drew substantial inspiration from Hermes, initially exhibited significant code similarities. However, as time progressed, Wizard Spider, the entity behind Ryuk, introduced further alterations to differentiate it from its predecessor.
How to prevent a Ryuk ransomware infection
Here's a rewritten version of the content:

"To minimize the risk of Ryuk ransomware attacks, it is essential to train users on avoiding unexpected emails and email attachments. User error is a common cause of malware infections, including Ryuk. The initial infection usually occurs when a user opens or downloads a malicious email attachment, leading to a TrickBot or Emotet infection. Conducting user security training can significantly reduce the likelihood of such incidents.

To detect preexisting infections within systems, it is crucial to analyze them thoroughly. Many Ryuk attacks exploit networks that are already infected with TrickBot or Emotet malware. Implementing anti-malware scanning as a standard endpoint security practice can help identify these infections and empower network administrators to isolate affected devices.

Adopting a Zero Trust security model is highly recommended. This model operates on the assumption that no computing devices are inherently trusted, and they require continuous verification. By employing this approach, access for infected devices can be restricted, preventing potential network compromises.

Regularly backing up files and data is another vital measure. In the event of a Ryuk ransomware attack, organizations can restore their data from backups rather than resorting to paying the ransom or rebuilding their entire IT infrastructure.

It is important to note that while these measures can significantly reduce the chances of a Ryuk ransomware attack, it is impossible to guarantee complete prevention of any threat. However, implementing these steps can greatly enhance security and minimize the risk of infection.

For assistance in implementing a Zero Trust security model, consider leveraging Toffs One. Toffs One is a secure access service edge (SASE) platform that offers extensive network connectivity and incorporates Zero Trust security as a fundamental component."
Maze Ransomware
What is Maze ransomware?
Maze, a strain of ransomware, has been affecting organizations since 2019. While Maze was initially created by one main group, it has been utilized by multiple attackers for extortion purposes.

In addition to encrypting data, Maze operators typically make copies of the encrypted data and threaten to expose it unless a ransom is paid. This dual impact of Maze ransomware combines the detrimental consequences of traditional ransomware (such as data loss and decreased productivity) with those of a data breach (such as data leaks and privacy violations), posing significant concerns for businesses.

Ransomware is a type of malicious software that locks up files and data through encryption. Victims are informed that they can only regain access to their files and data by paying a ransom to the attacker.

How does a Maze ransomware attack work?
Initially, Maze ransomware primarily circulated through malicious email attachments. However, recent attacks employ alternative approaches to compromise networks before deploying the ransomware payload. For instance, numerous Maze ransomware attacks exploit pilfered or guessed Remote Desktop Protocol (RDP) credentials, encompassing username and password combinations, to infiltrate networks. Other attacks have initiated by exploiting vulnerable virtual private network (VPN) servers.

Once inside a network, Maze ransomware follows the subsequent steps:

Reconnaissance: Maze conducts an investigation to identify network vulnerabilities and locate as many interconnected machines as possible. This meticulous assessment ensures that the eventual activation of ransomware has the greatest possible impact. As part of this process, Maze scans Active Directory, a Windows program that compiles a comprehensive list of authorized users and computers on the network. Typically, this reconnaissance stage is concluded several days after the attackers have infiltrated the targeted network.

Lateral movement: Utilizing the information obtained during reconnaissance, Maze spreads itself across the network, infecting a multitude of devices to maximize its reach.

Privilege escalation: While traversing laterally, Maze progressively pilfers additional credentials, granting it the ability to further expand its presence to other machines. Eventually, it typically attains administrator-level credentials, effectively gaining control over the entire network.

Persistence: Maze employs various techniques to evade removal. For example, it may install hidden backdoors within the network, enabling reinstallation if discovered and removed.

Attack: Finally, Maze initiates the process of encrypting and exfiltrating data. Once the data has been encrypted, Maze presents or sends a ransom note to the victim, detailing instructions on how to make the payment, regain access to their data, and prevent a potential data leak.

How does Maze exfiltrate data?

"Exfiltration" refers to the unauthorized extraction of data from a secure location. Maze, commonly known for its data exfiltration techniques, employs a file transfer protocol (FTP) server to copy and encrypt files and data, thereby moving them out of the trusted area. To accomplish this, attackers often utilize utilities such as PowerShell and WinSCP.

In certain instances, the exfiltrated data has been successfully transferred, compromising its security and confidentiality.
What is the Maze website?
The Maze ransomware group had been running a website on the dark web for a number of years. Their purpose was to showcase their past attacks by uploading stolen data and documents, while also providing social media links for the dissemination of the pilfered information.

In November 2020, the Maze group made an announcement on their website, stating their intention to cease operations. Nevertheless, it is not uncommon for ransomware groups to continue their activities under a new identity even after such claims of closure.

What was the Cognizant Maze ransomware attack?
In April 2020, a significant event known as the Cognizant Maze ransomware attack unfolded. Cognizant, a global IT services provider catering to various companies, fell victim to this attack. The incident led to the compromise of Cognizant's network, potentially resulting in the unauthorized acquisition of sensitive data belonging to their clients. Unfortunately, Cognizant did not disclose the specific clients affected by the attack. As a consequence, the restoration of services took several weeks, causing disruptions and delays in the business operations of numerous clients.

As a direct outcome of the attack, Cognizant estimated financial losses ranging from $50 million to $70 million.
What were some other major Maze attacks?
In 2019, the city of Pensacola, located in Florida, USA, fell prey to Maze, a notorious cyber attack. As evidence of their intrusion, the attackers released 2 GB of Pensacola's data to the public.

The year 2020 witnessed several high-profile incidents involving Maze. Canon, an imaging equipment company, became one of their victims. The attackers infected Canon's systems and successfully exfiltrated a staggering 10 TB of data. Unfortunately, numerous users of Canon's free storage service permanently lost their data as a consequence of this attack.

During the same year, Maze targeted Xerox, breaching their systems and pilfering 100 GB of sensitive information.

In yet another incident in 2020, Maze managed to infiltrate the systems of LG Electronics and leaked the source code data belonging to the company.

Additional organizations that fell victim to Maze's cyber attacks include WorldNet Telecommunications, Columbus Metro Federal Credit Union, the American Osteopathic Association, and VT San Antonio Aerospace.

How to prevent Maze ransomware
Here are some steps you can take to significantly reduce the likelihood of a Maze ransomware attack:

Avoid using default credentials: Criminals involved in Maze attacks often exploit weak default usernames and passwords. These default credentials are widely known in the criminal underground, making them highly insecure. Opt for unique and strong credentials to enhance security.

Implement two-factor authentication (2FA): Utilize 2FA to go beyond just relying on a username and password for user authentication. By requiring an additional factor such as a hardware token, which attackers cannot steal or replicate easily, you can significantly enhance the security of your applications.

Prioritize email security: Set up robust email security measures to filter out malicious email attachments. Additionally, educate your users to be cautious when dealing with unexpected emails and attachments from untrusted sources.

Keep systems updated: Regularly update your software to apply patches that address vulnerabilities frequently targeted by Maze ransomware. By staying current with updates, you can mitigate potential entry points for attackers to compromise your servers and networks.

Employ anti-malware scanning: In the event of a Maze infection, it is critical to promptly detect and remove the ransomware from infected devices. Leveraging anti-malware software can effectively identify most variants of Maze on your devices. Isolate any infected devices from the rest of the network immediately.

Embrace Zero Trust security: Adopt a Zero Trust security model, which involves continuously revalidating both users and devices, while swiftly restricting access for any devices found to be infected with malware. Educate yourself about the concept of Zero Trust networks to implement stronger security measures.

Consider utilizing Toffs One: Toffs One is a Zero Trust network-as-a-service (NaaS) platform designed to securely connect remote users, offices, and data centers. By leveraging Toffs One, you can strengthen your defense against ransomware attacks. Learn more about Toffs One and its capabilities in countering ransomware attacks.

By following these steps and implementing the recommended security measures, you can significantly reduce the risk of a Maze ransomware attack on your network and systems.

WannaCry Ransomware
What was the WannaCry ransomware attack?
The WannaCry ransomware attack had far-reaching consequences for organizations worldwide. It occurred on May 12, 2017, and quickly infected over 200,000 computers in more than 150 countries. Well-known entities such as FedEx, Honda, Nissan, and the UK's National Health Service (NHS) fell victim to this attack. As a result, the NHS had to redirect some of its ambulances to alternative hospitals.

Shortly after the attack commenced, a security researcher discovered a "kill switch" that effectively deactivated the WannaCry malware, albeit temporarily. Nevertheless, numerous affected computers remained locked and rendered unusable until the victims either paid the ransom or managed to reverse the encryption.

WannaCry's propagation relied on a vulnerability exploit named "EternalBlue." Originally developed by the US National Security Agency (NSA) for their internal purposes, this exploit was later stolen and publicly disclosed by a group known as the Shadow Brokers after compromising the NSA's systems. Although EternalBlue solely targeted older, unpatched versions of Microsoft Windows, there were still ample machines running these vulnerable versions, facilitating WannaCry's rapid proliferation.

Ransomware, the category to which WannaCry belongs, encompasses malicious software designed to encrypt files and data, subsequently demanding a ransom in exchange for their release.
What is a worm?
A worm is a type of malicious software program that spreads automatically across a network of computers within the field of security. It takes advantage of vulnerabilities in operating systems to move from one computer to another, replicating itself on each infected system.

Picture a worm as a thief wandering through an office park, searching for unlocked doors. Once the thief discovers an unlocked door, he can create a copy of himself that remains inside the unlocked office, and both versions continue their quest for more unlocked doors.

Unlike most worms, ransomware is typically spread through malicious emails, compromised credentials, botnets, or specifically targeted vulnerability exploits. For instance, Ryuk exemplifies the latter. However, WannaCry stands out because it not only combined ransomware with a worm but also exploited an exceptionally powerful vulnerability designed by the NSA, enabling its worm-like behavior.


Who are the Shadow Brokers?
In 2016, a collective known as the Shadow Brokers emerged, engaging in the unauthorized release of malware tools and zero-day exploits to the general public. Speculation arose that they had obtained various exploits originally crafted by the NSA, potentially through an act of infiltration from within the agency itself. Notably, on April 14, 2017, the Shadow Brokers made public the EternalBlue exploit, which would later be employed by WannaCry.

It is worth mentioning that Microsoft had already released a patch for EternalBlue on March 14, a month prior to its disclosure by the Shadow Brokers. However, numerous computers remained vulnerable due to the absence of this patch at the time when the WannaCry attack transpired.

Who was responsible for the WannaCry ransomware attack?
In the latter part of 2017, the United States and the United Kingdom made an announcement stating that the North Korean government was responsible for the WannaCry cyberattack. Nevertheless, there are dissenting opinions among security researchers regarding this attribution. Certain experts argue that WannaCry might have been the creation of the Lazarus Group, a North Korea-based hacking organization, rather than directly originating from the government itself. Alternatively, some suggest that the clues indicating authorship within the malware could have been intentionally planted to falsely implicate North Korea-based attackers, and propose the possibility that WannaCry may have originated from an entirely different geographical region.
How was the WannaCry attack stopped?
On the day of the attack, Marcus Hutchins, a security blogger and researcher, engaged in reverse-engineering the source code of WannaCry. During his analysis, he made an intriguing discovery—WannaCry possessed an unusual functionality. Prior to execution, it would perform a query to the domain iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea.com, despite the fact that the website did not exist.

Recognizing an opportunity, Hutchins decided to register the domain, which only required a payment of $10.69. Once the domain was under his control, instances of WannaCry continued to propagate, but they ceased their malicious activities. Essentially, WannaCry deactivated itself upon receiving a response from iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea.com.

Why did this stop the attack?

Although the exact motivations of the WannaCry authors remain uncertain, it is believed that the inclusion of a domain query function in the ransomware served the purpose of detecting whether it was operating within a sandbox environment.

A sandbox is a security tool designed to isolate and analyze potentially malicious files. It functions as a virtual machine, running separately from other systems and networks, providing a secure space to execute untrusted files and observe their behavior.

Typically, a sandbox is not directly connected to the Internet. However, sandboxes aim to replicate a real computer environment as closely as possible, and thus they may generate synthetic responses to domain queries made by malware. Consequently, one way for malware to check if it is running inside a sandbox is by sending a query to a fabricated domain. If it receives a "genuine" response (generated by the sandbox), the malware assumes it is being analyzed and self-terminates to avoid detection by the sandbox.

In the case of WannaCry, if the malware sent its test query to a pre-determined domain, it could be deceived into always perceiving itself as operating within a sandbox if someone registered that domain. This scenario possibly unfolded with WannaCry, as copies of the ransomware worldwide were tricked into believing they were in a sandbox and consequently ceased their operations. (From the malware authors' perspective, a more effective design would involve querying a randomized domain, changing with each instance, to minimize the likelihood of obtaining a response from a non-sandbox environment.)

Alternatively, it is plausible that the version of WannaCry that spread globally was incomplete. The authors might have initially used a hard-coded domain as a placeholder, intending to replace it with the address of their command-and-control (C&C) server before releasing the worm. Alternatively, they might have intended to register the domain "iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea.com" themselves. Deploying DNS filtering or URL filtering measures could have potentially intercepted queries to this domain, but most organizations were unable to implement such protective measures in time.

Irrespective of the underlying reason, it was fortuitous that such a simple action could prevent further infections and safeguard computers and networks worldwide.

What happened to Marcus Hutchins?
As it unfolded, it was revealed that prior to embarking on his career as a security researcher and blogger, Hutchins had spent considerable time immersed in the depths of malware forums on the dark web. During this period, he actively engaged in the creation and distribution of his own malicious software. Several months following the WannaCry episode, the FBI apprehended Hutchins in Las Vegas, Nevada, on charges related to his role in developing Kronos, a harmful strain of banking malware.
Is WannaCry a threat today?
In 2017, a version of WannaCry emerged, but it is now defunct thanks to Hutchins' kill switch domain. Furthermore, a patch has been available since March 2017 to address the EternalBlue vulnerability exploited by WannaCry.

Despite these measures, WannaCry attacks persist. As of March 2021, WannaCry still exploits the EternalBlue vulnerability, putting only outdated Windows systems at risk. Recent iterations of WannaCry have eliminated the kill switch found in the original version. Therefore, it is strongly recommended to promptly update operating systems and install security updates.

Although the original WannaCry version is inactive, valuable insights can be gleaned from the attack that occurred in May 2017:

Interconnected networks: In the digital age, it should be evident that networks worldwide are interconnected. However, many organizations wrongly assume that their networks are impervious to external breaches, similar to a castle protected by a moat. WannaCry exposed the fact that unless a network is completely isolated (air-gapped), external threats can find a way in.

Persisting danger of patched vulnerabilities: A vulnerability patch is only as effective as the number of systems that implement it. Despite the availability of the EternalBlue patch two months before the WannaCry attack, it appears that few organizations had installed it. Even in 2021, some systems had not taken this crucial step.

Vulnerability of critical organizations: This vulnerability remains a reality. Ransomware attacks have impacted hospitals, schools, fuel pipelines, and governments in recent years. Notably, ransomware groups like Ryuk tend to target these institutions. Some organizations may lack the necessary funds, resources, or commitment to implement the required technological updates to defend against such attacks. The NHS, for instance, faced scrutiny for continuing to use the unsupported and highly vulnerable Windows XP following the attack.

The pervasive threat of ransomware: Ransomware poses a significant danger. Toffs One, a Zero Trust platform, can assist organizations in combating this threat. By adopting a Zero Trust security approach, which considers all users and devices as potential threats, regular re-authentication and device security assessments are conducted. This ensures that any unsafe or unauthorized devices have their network and application access revoked immediately, thereby mitigating the spread of ransomware.
Petya and NotPetya
What is Petya ransomware?
Petya, identified in 2016, is a form of ransomware that operates by encrypting files and data on the victim's computer. Similar to other ransomware variants, Petya employs the tactic of demanding Bitcoin payment from the victims in exchange for decrypting the files and restoring their accessibility.

In contrast to older ransomware strains that selectively encrypt specific important files to coerce the victims, Petya takes a more extensive approach by locking the entire hard disk of the targeted computer. It achieves this by encrypting the Master File Table (MFT) of the computer, rendering all files on the hard disk inaccessible.

Petya has exclusively been observed to target computers running Windows operating systems.

How does Petya ransomware spread?
Like numerous ransomware attacks, Petya primarily propagates via email attachments. Malicious actors dispatch emails to HR departments, disguising them as job applications. The attached PDFs can either conceal an infected Dropbox link or masquerade as executable files, depending on the chosen attack technique.
What is NotPetya?
In June 2017, a global outbreak of ransomware occurred, resembling the infamous Petya malware. However, this new variant, known as "NotPetya," exhibited distinct characteristics. Security provider Kaspersky named it NotPetya due to its similarities to Petya but with some critical differences. By June 28, 2017, NotPetya had already impacted over 2,000 organizations worldwide, predominantly in Ukraine.

Similar to Petya, NotPetya targeted the entire hard disk of its victims. However, instead of encrypting just the Master File Table (MFT), NotPetya encrypted the entire hard disk itself. It spread rapidly and unexpectedly, exploiting various vulnerabilities and employing credential theft methods to infect entire networks.

A noteworthy aspect of NotPetya was its utilization of the EternalBlue vulnerability (CVE-2017-0144), which had been previously exploited by the global WannaCry attack earlier in 2017. This allowed NotPetya to propagate swiftly across networks without any user interaction, unlike Petya, which required users to open a malicious email attachment to initiate the infection. Microsoft had released a patch for the EternalBlue vulnerability in March 2017, but many organizations had not yet installed it.

Is NotPetya different from Petya 2.0?
These two entities are identical. Different individuals within the security sector referred to this particular form of malware by various names. NotPetya was alternatively known as Petya 2.0, ExPetr, and GoldenEye.

Was NotPetya actually ransomware?
In contrast to typical ransomware, which temporarily damages or restricts file access in exchange for a ransom, NotPetya exhibited a purely destructive nature. It caused irreparable damage, completely wiping out files without any possibility of recovery.

Although it displayed a ransom message, this tactic likely served as a disguise for the attackers' true intentions. Even if victims of NotPetya were willing to pay the ransom, the displayed message presented a fake Bitcoin address randomly generated by the attackers. Consequently, the attackers had no means of collecting the ransom, further indicating that the primary objective of NotPetya was destruction rather than financial gain.

Ordinary ransomware is not initially designed to obliterate files and data entirely. While some ransomware attackers may resort to such measures if the ransom is not paid, immediate file wiping does not incentivize victims to comply since there is no hope of file recovery. Most ransomware attackers are primarily motivated by monetary gain, rather than causing long-lasting damage to the victims' systems.

Furthermore, unlike the perpetrators behind the 2016 Petya attacks, who appeared to be typical cybercriminals employing ransomware, several nations in 2018 publicly attributed the NotPetya attacks directly to the Russian government. This suggests that the NotPetya attacks might have been politically motivated.

How to prevent Petya and NotPetya infections
Implementing the following three measures can significantly reduce the risk of a Petya or NotPetya attack:

Enhancing email security practices: Many Petya attacks, as well as certain NotPetya attacks, originate from infected email attachments. To mitigate this threat, organizations should employ email scanning mechanisms to detect malware, block attachments from external sources, and provide user training to discourage opening untrusted attachments.

Regularly applying software patches: NotPetya exploited the EternalBlue vulnerability, which had a patch available months before the attacks occurred. Ransomware attacks commonly capitalize on software vulnerabilities to gain access to networks or propagate within them. Keeping software up to date and diligently patching vulnerabilities can effectively eliminate such attack vectors.

Performing regular data backups: While backups cannot prevent ransomware infections, they play a crucial role in expediting recovery. In the event of an attack that erases files, like NotPetya, backups may be the only means to restore lost data. It is essential for organizations to maintain backup copies of important files to enable swift recovery.

For additional insights, refer to the comprehensive guide on preventing ransomware.

Moreover, organizations can consider adopting Toffs One—a robust platform that ensures secure connectivity to essential resources. Employing a Zero Trust security approach, Toffs One effectively thwarts ransomware infections and helps contain their impact.

Ransomware-as-a-Service (RaaS)
What is ransomware-as-a-service (RaaS)?
Ransomware-as-a-service (RaaS) is a criminal business model that enables individuals to easily access and utilize tools for carrying out ransomware attacks. Similar to other as-a-service models like software-as-a-service (SaaS) or platform-as-a-service (PaaS), RaaS allows customers to rent ransomware services rather than owning them, deviating from the conventional software distribution approach.

Ransomware refers to malicious software that effectively locks a victim's system or files through encryption. To regain access to their data, victims are compelled to pay a ransom to the perpetrators behind the ransomware attack. The ransomware industry has burgeoned into a significant sector within the criminal underworld, generating billions of dollars in annual revenue.

Contrary to popular belief, many perpetrators of cyber attacks, including ransomware, may not possess extensive programming skills. Instead, these attackers often refrain from writing their own code or lack the technical know-how altogether. Cybercriminals who possess coding expertise frequently opt to sell or rent out the exploits they develop instead of employing them personally.

Ransomware represents just one facet of the cybercrime industry that operates on an "as-a-service" model. Attackers can also lease DDoS (Distributed Denial-of-Service) tools, subscribe to databases of stolen credentials, employ botnets for hire, or rent banking trojans, among other illicit services.

How does ransomware-as-a-service work?
Ransomware-as-a-Service (RaaS) services employ various revenue models to generate income. These models can include a fixed monthly subscription fee, a percentage share of the customers' profits, a combination of these approaches, or a one-time licensing fee. Once a customer signs up for a RaaS account and completes their initial payment, usually in Bitcoin, they gain the ability to choose the specific type of malware they wish to utilize.

Upon successful payment, the attackers initiate their campaign by distributing the malware and infecting unsuspecting victims. In most cases, ransomware attackers rely on phishing or social engineering tactics to deceive users into executing the malware. These methods are relatively inexpensive compared to purchasing zero-day exploits or backdoor access. Once the malware is executed, the victim's computer is encrypted and rendered unusable, and the attacker presents a message detailing instructions on how to submit the ransom payment.

To assist attackers encountering difficulties or struggling with malware functionality, RaaS providers often offer round-the-clock customer support services. These providers typically maintain community forums where customers can seek assistance, ask questions, and share ideas. Additionally, many providers offer comprehensive guides that outline step-by-step instructions on executing a ransomware attack using their tools.

Who uses RaaS?
Different RaaS providers have different criteria for choosing their customers. Some are selective and only sell their software to skilled hackers who can target big and lucrative victims, which helps promote their service. Some have other demands, such as speaking a certain language or being able to use the service and make money from ransoms quickly.

Others are more open and will sell their services to anyone who can pay or share the ransom profits. This can be risky for RaaS providers, as some customers may be inexperienced and get caught by law enforcement.

Lately, many RaaS providers have become more cautious about which sectors they allow their customers to attack. For instance, they may ban attacks on vital infrastructure or healthcare facilities, as such attacks can harm someone's health or even kill them. These extreme events attract unwanted attention to the RaaS market, and RaaS providers may also have ethical concerns about hurting someone's physical health (instead of their wallet).

What are some examples of ransomware-as-a-service attacks?
RaaS attacks have become widespread in recent years. Some examples are:

DarkSide is a ransomware group that offers RaaS. They were behind the 2021 Colonial Pipeline attack.
REvil is a RaaS product. The 2021 ransomware attack on IT provider Kaseya used REvil ransomware.
Dharma ransomware is a service that has been used in many attacks since 2016.

RaaS makes it easy for anyone to launch a ransomware attack, as all they need is a computer and an Internet connection. This makes ransomware a lucrative form of cyber crime. Therefore, RaaS attacks will likely keep growing in the future.

Where do criminals buy ransomware-as-a-service?
RaaS services are bought and used online, like any cloud service. RaaS is typically found on malware forums on the dark web. (The "dark web" is a hidden part of the Internet that requires a Tor browser to access, which hides a user's location and IP address.)
How do ransomware-as-a-service providers market their services?
RaaS is a very competitive industry, and many providers actively advertise their services. RaaS providers use Twitter accounts, websites, video content, and other marketing tools. They often launch marketing campaigns to attract customers. Most RaaS tools also have user reviews and community forums.
How to defend against ransomware-as-a-service attacks
Organizations can protect themselves from ransomware-as-a-service attacks and other malware attacks by using some security measures:

User security training: Teaching employees, contractors, and other users how to spot phishing attacks and social engineering attacks reduces the chances of a successful RaaS attack.
Email security: Many ransomware attacks begin with a malicious email attachment. Checking emails for malware and blocking email attachments from unknown sources can help prevent this attack method.
Regular data backups: Ransomware locks organizations out of their data. But in many cases, an organization can recover their data from a backup instead of paying the ransom to unlock it or rebuilding all of their IT systems from scratch.

To learn more about how to stop RaaS attacks, see How to prevent ransomware.

Glossary
OWASP Top Ten
What is OWASP?
OWASP, or the Open Web Application Security Project, is a global non-profit organization that focuses on web application security. One of their main principles is that all of their resources be free and easy to access on their website, so anyone can improve their web application security. The resources they provide include documentation, tools, videos, and forums. Their most famous project is probably the OWASP Top 10.
What is the OWASP Top 10?
The OWASP Top 10 is a report that lists the most important security issues for web application security, updated regularly. The report is created by a group of security experts from around the world. OWASP calls the Top 10 a ‘awareness document’ and they suggest that all companies use the report in their processes to reduce and/or avoid security risks.

Here are the security risks in the OWASP Top 10 2017 report:

1. Injection
Injection attacks occur when untrusted data is sent to a code interpreter through a form input or some other data submission to a web application. For example, an attacker could enter SQL database code into a form that expects a plaintext username. If that form input is not well secured, this would cause that SQL code to run. This is called an SQL injection attack.

Injection attacks can be stopped by validating and/or sanitizing user-submitted data. (Validation means refusing suspicious-looking data, while sanitization means removing the suspicious-looking parts of the data.) Also, a database admin can set limits to reduce the amount of information an injection attack can reveal.

2. Broken Authentication
Weaknesses in authentication (login) systems can let attackers access user accounts and even take over an entire system using an admin account. For example, an attacker can use a list with thousands of known username/password combinations from a data breach and use a script to try all those combinations on a login system to see if any of them work.

Some ways to prevent authentication weaknesses are requiring two-factor authentication (2FA) and limiting or delaying repeated login attempts using rate limiting.


3. Sensitive Data Exposure
If web applications don't secure sensitive data such as money information and passwords, attackers can get that data and sell or use it for evil purposes. One common way to steal sensitive information is using an on-path attack.

Data exposure risk can be reduced by encrypting all sensitive data and also disabling the caching* of any sensitive information. Also, web application developers should make sure that they are not storing any sensitive data that they don't need.

*Caching is the practice of temporarily storing data for re-use. For example, web browsers will often cache webpages so that if a user goes back to those pages within a fixed time span, the browser does not have to get the pages from the web.


4. XML External Entities (XEE)
This is an attack against a web application that reads XML* input. This input can refer to an external entity, trying to exploit a weakness in the parser. An 'external entity' in this context means a storage unit, such as a hard drive. An XML parser can be tricked into sending data to an unauthorized external entity, which can give sensitive data directly to an attacker.

The best ways to stop XEE attacks are to have web applications accept a simpler type of data, such as JSON**, or at least to update XML parsers and disable the use of external entities in an XML application.

*XML or Extensible Markup Language is a markup language meant to be readable by both humans and machines. Because of its complexity and security flaws, it is now being replaced by other formats in many web applications.

**JavaScript Object Notation (JSON) is a type of easy, human-readable notation often used to send data over the internet. Although it was originally made for JavaScript, JSON is language-independent and can be understood by many different programming languages.
5. Broken Access Control
Access control means a system that controls access to information or functionality. Broken access controls let attackers bypass authorization and do tasks as if they were privileged users like administrators. For example a web application could let a user change which account they are logged in as by changing part of a url, without any other verification.

Access controls can be protected by making sure that a web application uses authorization tokens* and sets strict controls on them.

*Many services give authorization tokens when users log in. Every privileged request that a user makes will need the authorization token to be present. This is a secure way to make sure that the user is who they claim to be, without having to enter their login credentials all the time.


6. Security Misconfiguration
Security misconfiguration is the most frequent vulnerability on the list, and is often caused by using default configurations or showing too much information in errors. For example, an application could show a user very detailed errors that may expose weaknesses in the application. This can be prevented by deleting any unused features in the code and making sure that error messages are more vague.

7. Cross-Site Scripting
Cross-site scripting vulnerabilities happen when web applications let users add custom code into a url path or onto a website that will be seen by other users. This vulnerability can be used to run harmful JavaScript code on a victim’s browser. For example, an attacker could send an email to a victim that looks like it is from a trusted bank, with a link to that bank’s website. This link could have some harmful JavaScript code added to the end of the url. If the bank’s site is not well protected against cross-site scripting, then that harmful code will run in the victim’s web browser when they click on the link.

Ways to prevent cross-site scripting include escaping untrusted HTTP requests and validating and/or sanitizing user-generated content. Using modern web development frameworks like ReactJS and Ruby on Rails also gives some built-in cross-site scripting protection.

8. Insecure Deserialization
This threat affects the many web applications that often serialize and deserialize data. Serialization means taking objects from the application code and changing them into a format that can be used for another purpose, such as saving the data to disk or streaming it. Deserialization is just the reverse: changing serialized data back into objects the application can use. Serialization is like putting furniture into boxes before a move, and deserialization is like taking the boxes out and putting the furniture together after the move. An insecure deserialization attack is like having the movers mess with the contents of the boxes before they are taken out.

An insecure deserialization exploit happens when deserializing data from untrusted sources, and can lead to serious problems like DDoS attacks and remote code execution attacks. While steps can be taken to try and stop attackers, such as watching deserialization and doing type checks, the only sure way to protect against insecure deserialization attacks is to avoid the deserialization of data from untrusted sources.


9. Using Components With Known Vulnerabilities
Many modern web developers use components such as libraries and frameworks in their web applications. These components are pieces of software that help developers save time and provide needed functionality; common examples include front-end frameworks like React and smaller libraries that used to add share icons or a/b testing. Some attackers look for weaknesses in these components which they can then use to launch attacks. Some of the more popular components are used on hundreds of thousands of websites; an attacker finding a security flaw in one of these components could make hundreds of thousands of sites exposed to exploit.

Component developers often offer security fixes and updates to close known vulnerabilities, but web application developers don't always have the fixed or most-recent versions of components running on their applications. To reduce the risk of running components with known vulnerabilities, developers should delete unused components from their projects, as well as making sure that they are getting components from a trusted source and keeping them up to date.


10. Insufficient Logging And Monitoring
Many web applications are not doing enough to detect data breaches. The average time to find a breach is around 200 days after it has occurred. This gives attackers a lot of time to cause harm before there is any reaction. OWASP suggests that web developers should use logging and monitoring as well as incident response plans to make sure that they are notified of attacks on their applications.

For a more technical and detailed look at the OWASP Top 10, see the official report.

Meltdown/Spectre
What is Meltdown/Spectre?
Meltdown and Spectre are new vulnerabilities found in Intel, AMD, Apple, and ARM processor chips. These vulnerabilities are caused by a serious design mistake in the affected chips, and the discovery of this issue has forced a redesign of Windows, Mac, and Linux operating system software to reduce the vulnerability and stop attackers from using it.

These vulnerabilities were found by researchers at Google’s Project Zero, a team that’s focused on finding security flaws before they can be used by attackers; as of now there are no known Meltdown or Spectre exploits in existence. Security teams at big tech companies like Apple, Intel, and Microsoft, as well as open-source Linux developers are now working hard to try and make sure that their processors and operating systems are safe before any harmful exploits.

Who is affected by the Meltdown and Spectre vulnerabilities?
Except for a few cases, everyone with a PC and/or a smartphone is in danger. Google says that every device with an Intel processor chip made after 1995 is affected. AMD and ARM chips are more difficult to exploit, but they are also at risk.
How to protect against the Meltdown/Spectre vulnerability?
Other than changing a PC’s processor, the only way to fix the vulnerability is to update the operating system. Apple secretly added a Meltdown patch to OSX in early December, while Microsoft released a Windows patch on January 3rd, and Linux developers are still working to make a patch.

A bad side effect of these Meltdown patches is that they will, on purpose, slow down the processing speeds of the computers using the patched OS. These slowdowns will affect performances by an estimated 5-30%, depending a lot on the kind of chip and the tasks being done.

How do the Meltdown and Spectre vulnerabilities actually work?
Both Meltdown and Spectre are vulnerabilities caused by the execution of a special high-level code called “kernel code”, which runs only during a process called speculative execution.


What is speculative execution?
Speculative execution can be explained with a metaphor. Imagine a hiker lost in the woods who finds a fork in the trail creating two similar paths; one path will get the hiker home, the other will not. Instead of waiting for another hiker to help her, she picks the path she thinks is most likely to get her home. At some point on the hike, she sees a trail marker, if that trail marker tells her that she’s on the right path, then she keeps going on that path and gets home. If the trail marker tells her she is on the wrong path, she quickly goes back and switches to the other trail, which is no worse than if she was still at the start of the trail waiting for help.



Many modern processors use a similar technique called speculative execution, where the CPU tries to guess what code needs to be executed next, and then does that code before being asked to do so. If the executed code turns out not to be needed, the changes are undone. This is meant to save time and make performance faster.

Reports on the Meltdown/Spectre vulnerability are saying that Intel CPUs may be doing speculative execution of code without needing important security checks. It may be possible to write software made to check if the processor has done an instruction that would normally be stopped by these security checks.

This wrong handling of speculative execution makes a CPU vulnerability which an attacker can use to get very sensitive data in kernel memory such as passwords, encryption keys, personal photos, emails, etc.

So what’s a kernel?
A kernel is the program at the heart of a computer’s operating system. It has full control over the operating system and manages everything from start-up to the handling of memory. The kernel also sends data-processing instructions to the CPU (Central Processing Unit). Most CPUs are always switching between kernel mode and user mode.
What’s the difference between kernel mode and user mode?
In kernel mode, the CPU is running code that has unlimited access to the computer’s hardware and memory. This mode is usually reserved for the lowest-level and most trusted operations. Crashes that happen while the CPU is in kernel mode are potentially very bad; they can crash the whole Operating System.

In user mode, the code being run cannot access hardware or reference memory, instead it must ask system APIs (system APIs can do kernel-mode functions that user-mode software can request with the right permissions). User mode crashes are often isolated and fixable. Most code is run in user mode.

Why does the Meltdown patch slow down performance?
The fix in the Meltdown patch involves a bigger separation of the kernel’s memory from user processes. This is done by a method called Kernel Page Table Isolation (KPTI). KPTI moves kernel mode operations into a totally separate address space from user mode operations. This means that it takes much more time to switch between kernel mode and user mode.

To explain this, imagine a food truck that only sells two items: hot dogs and cold lemonade. The worker inside the food truck can easily reach both the steamer with the hot dogs and the cooler with the cold lemonades, and business moves very fast. Now imagine the health inspector comes and requires the hot and cold foods to be kept in separate places. Now the worker can still reach the hot dogs, but has to leave the truck and walk down the street to get each lemonade. This would make the food truck’s line move much slower, especially if people are ordering a lot of lemonades. This is similar to how KPTI can slow down the performance of an operating system.


What’s the difference between Meltdown and Spectre?
Both Meltdown and Spectre are vulnerabilities caused by the way processors handle speculative execution, but they are different in how they work and which types of processors are affected.

Meltdown only affects Intel and Apple processors and it can be used to leak information that gets exposed because of code that processors run during speculative execution. Meltdown is easier to use than Spectre and has been called the bigger risk by security experts. Luckily, Meltdown is also easier and more simple to fix.

Spectre affects Intel, Apple, ARM, and AMD processors and it can be used to actually make processors run code that they should not be allowed to run. According to the security experts at Google, Spectre is much harder to use than Meltdown, but it is also much harder to stop.

Want to learn more about Meltdown and Spectre?
You can read the full Meltdown paper and the Spectre paper if you want to learn more about them in more technical detail.

Malicious Payload
What is a malicious payload?
In a cyber-attack, a payload is the part of the attack that hurts the victim. Like the Greek soldiers hiding inside the wooden horse in the story of the Trojan Horse, a harmful payload can sit quietly for some time until triggered.

Attack vectors such as viruses, wurms, and malware can all have one or more harmful payloads. Harmful payloads can also be in email attachments, in fact Symantec has said that one in every 359 emails in existence has a harmful payload, and this ratio is going up.

How do malicious payloads harm their victims?
Some common examples of how harmful payloads cause harm:

Data theft: A very common type of harm is the theft of sensitive information such as login credentials or money information through different forms of data breaches.
Activity monitoring: A harmful payload that runs may monitor user activity on a computer, this can be done for spying, blackmail, or to collect consumer behavior that can be sold to advertisers.
Showing advertisements: Some harmful payloads work to show constant, unwanted ads such as pop-ups and pop-unders to the victim.
Deleting or changing files: This is one of the most serious harms from a harmful payload. Files can be deleted or changed to affect the behavior of a computer, or even disable the operating system and/or startup processes. For example some harmful payloads are made to ‘brick’ smartphones, meaning they can no longer be turned on or used at all.
Downloading new files: Some harmful payloads come in very small files that are easy to spread, but once they run they will start the download of a much bigger piece of harmful software.
Running background processes: A harmful payload can also be triggered to run processes in the background quietly, such as cryptocurrency mining or data storage.

How are malicious payloads executed?
Attackers must first find a way to deliver the harmful payload onto the victim’s computer. Social engineering attacks and DNS hijacking are two common examples of payload delivery methods.

Once a payload is in place, it will usually stay quiet until being run. An attacker can choose from many different ways to run a harmful payload. Some common ways to run a harmful payload:

Opening an executable file: For example a victim downloads an email attachment that they think is a piece of stolen software and they click on the installation file which runs the payload.
Triggering a specific set of behavioral conditions: This is called a logic bomb. For example, a dishonest employee might put a logic bomb into his company’s network that keeps checking if that employee is still on the payroll. When he is no longer on the payroll, the logic bomb will meet its condition and the harmful payload will be run.
Opening certain non-executable files: Even some non-executable files can have harmful payloads. For example there are attacks where harmful payloads are hidden in .PNG image files. When a victim opens these image files, the payload is run.


How to stop malicious payloads
Malicious payloads can be distributed and executed in many different ways, so there is no easy solution to prevent them. Besides being careful of phishing scams and other social engineering attacks, you should always take security precautions when you download files or receive any data from the Internet. A good general rule is to scan every downloaded file for viruses, even if it seems to come from a reliable source.

Penetration Testing
What is penetration testing?
Penetration testing (or pen testing) is a security practice where a cyber-security expert tries to find and exploit weaknesses in a computer system. The goal of this simulated attack is to discover any gaps in a system’s defenses that attackers could use.

This is similar to a bank hiring someone to pretend to be a burglar and attempt to break into their building and access the vault. If the ‘burglar’ succeeds and gets into the bank or the vault, the bank will learn valuable information on how they need to improve their security measures.

Who performs pen tests?
It’s better to have a pen test done by someone with little or no prior knowledge of how the system is secured because they might be able to reveal blind spots that the developers who built the system missed. For this reason, outside contractors are usually hired to do the tests. These contractors are often called ‘ethical hackers’ because they are hired to hack into a system with permission and for the sake of increasing security.

Many ethical hackers are experienced developers with advanced degrees and a certification for pen testing. However, some of the best ethical hackers are self-taught. In fact, some are former criminal hackers who now use their skills to help fix security flaws instead of exploiting them. The best candidate to do a pen test can vary a lot depending on the target company and what kind of pen test they want to start.

What are the types of pen tests?
Open-box pen test - In an open-box test, the hacker will get some information beforehand about the target company’s security info.
Closed-box pen test - Also known as a ‘single-blind’ test, this is one where the hacker gets no background information except the name of the target company.
Covert pen test - Also known as a ‘double-blind’ pen test, this is a situation where almost no one in the company knows that the pen test is happening, including the IT and security professionals who will respond to the attack. For covert tests, it is very important for the hacker to have the scope and other details of the test in writing before to avoid any problems with law enforcement.
External pen test - In an external test, the ethical hacker attacks the company’s external-facing technology, such as their website and external network servers. In some cases, the hacker may not even be allowed to enter the company’s building. This can mean doing the attack from a remote location or doing the test from a truck or van parked nearby.
Internal pen test - In an internal test, the ethical hacker does the test from the company’s internal network. This kind of test is useful in finding out how much damage an unhappy employee can do from behind the company’s firewall.

How is a typical pen test carried out?
Penetration testing (pen testing) commences with a reconnaissance phase, wherein an ethical hacker dedicates time to gathering data and information necessary for planning their simulated attack. Subsequently, the focus shifts towards attaining and maintaining access to the target system, necessitating a diverse range of tools.

The arsenal of attack tools encompasses software explicitly designed to execute brute-force attacks or SQL injections. Additionally, specialized hardware tailored for pen testing exists, such as discreet compact devices capable of being connected to a computer within the network, thereby providing the hacker with remote access to that particular network. Furthermore, an ethical hacker may leverage social engineering techniques to identify vulnerabilities. For instance, they may deploy phishing emails to deceive company employees or even assume disguises as delivery personnel to gain physical access to the premises.

The conclusion of the pen test involves the hacker obliterating any traces of their activities. This entails removing any embedded hardware and employing all available means to evade detection, ensuring that the target system remains unchanged, exactly as they found it.

What happens in the aftermath of a pen test?
Upon concluding a penetration test, the ethical hacker will communicate their findings to the security team of the targeted company. Subsequently, this information can be leveraged to enact security enhancements that address any vulnerabilities identified during the test. Such improvements may encompass the implementation of rate limiting, establishment of new web application firewall (WAF) rules, deployment of DDoS mitigation measures, and reinforcement of form validations and sanitization processes.
What is a Firewall?
What is a firewall?
A firewall functions as a security mechanism that oversees and manages network traffic based on a predetermined set of security regulations. Typically, firewalls are positioned between a reliable network and an untrusted network, often represented by the Internet. To safeguard their networks from online risks, offices frequently employ firewalls.



The role of firewalls is to determine whether incoming and outgoing traffic should be permitted to traverse. They can be implemented as hardware, software, or a combination of both. Interestingly, the term "firewall" draws inspiration from the architectural practice of constructing walls within or between buildings to confine the spread of fire. In a similar manner, network firewalls operate to contain online threats.





Why use a firewall?
The main purpose of a firewall is to ensure security. By intercepting malicious incoming traffic, firewalls act as a protective barrier, preventing it from reaching the network. Additionally, they play a crucial role in safeguarding sensitive information, keeping it within the network and preventing unauthorized access.

Apart from security measures, firewalls can also be utilized for content filtering. For instance, educational institutions can leverage firewalls to restrict access to adult content, ensuring a safe online environment for their users. Similarly, in certain countries, government-operated firewalls are employed to limit citizens' access to specific sections of the Internet.

In this article, our focus will be on firewalls configured for security purposes, as there exist various types that cater to different needs.

What are the different types of firewall?
Proxy-based firewalls:
These proxies act as intermediaries between clients and servers, serving as a barrier between them. When clients establish a connection, they connect to the firewall, which examines the outgoing packets. Subsequently, the firewall establishes a connection with the intended recipient (the web server). Similarly, when the web server tries to send a response to the client, the firewall intercepts the request, inspects the packets, and then delivers the response through a separate connection between the firewall and the client. In essence, a proxy-based firewall effectively prevents a direct connection between the client and server.

Analogously, a proxy-based firewall can be likened to a bouncer at a bar. This bouncer's role is to screen guests before they enter the establishment, ensuring that they are not underage, armed, or pose any other threat to the bar and its patrons. The bouncer also monitors patrons on their way out, guaranteeing they have a safe means of transportation and are not intending to drink and drive.

However, one drawback of having a bouncer at a bar is that during periods of high demand when many people are trying to enter or leave simultaneously, a long line forms, resulting in delays for some individuals. Similarly, a significant disadvantage of a proxy-based firewall is the potential for latency, especially during times of heavy traffic.

*A proxy is a computer that functions as a gateway between a local network and a larger network, such as the Internet.


Stateful firewalls:
In computer science, a "stateful" application is one that saves data from previous events and interactions. A stateful firewall saves information regarding open connections and uses this information to analyze incoming and outgoing traffic, rather than inspecting each packet. Because they do not inspect every packet, stateful firewalls are faster than proxy-based firewalls.

Stateful firewalls rely on a lot of context when making decisions. For example, if the firewall records outgoing packets on one connection requesting a certain kind of response, it will only allow incoming packets on that connection if they provide the requested kind of response.

Stateful firewalls can also protect ports* by keeping them all closed unless incoming packets request access to a specific port. This can mitigate an attack known as port scanning.

A known vulnerability associated with stateful firewalls is that they can be manipulated by tricking a client into requesting a certain kind of information. Once the client requests that response, the attacker can then send malicious packets that match that criteria through the firewall. For example, unsecure websites can use JavaScript code to create these kinds of forged requests from a web browser.

*A network port is a location where information is sent; it’s not a physical place but rather a communications endpoint. Learn more about ports >>


Next-generation firewalls (NGFW):

Next-Generation Firewalls (NGFWs) are advanced security solutions that combine the functionalities of traditional firewalls with additional features to combat threats across various layers of the OSI model. These enhanced capabilities of NGFWs include:

Enhanced Packet Inspection: NGFWs perform thorough analysis of network packets, going beyond the surface-level examination conducted by traditional firewalls. This deep packet inspection scrutinizes packet payloads and identifies the specific applications being accessed by the packets. Consequently, NGFWs can enforce more precise filtering rules.

Application Awareness: By enabling this feature, NGFWs gain awareness of running applications and the associated ports they utilize. This awareness helps safeguard against specific types of malware that target running processes and attempt to take over their ports, protecting the network from potential intrusions.

Identity Awareness: NGFWs empower firewalls to enforce rules based on user identity or device information. This means that the firewall can differentiate between various computers or logged-in users, enabling more personalized and context-specific security policies.

Sandboxing: NGFWs incorporate sandboxing capabilities to isolate and evaluate code sections related to incoming packets within a secure "sandbox" environment. By executing code in this controlled setting, the firewall can determine if it exhibits any malicious behavior. The results of the sandbox test serve as a crucial factor in the decision-making process of whether to allow the packets into the network or not.

These advanced features collectively equip NGFWs to offer comprehensive protection and mitigate a wide range of cyber threats across multiple layers of network communication.


Web application firewalls (WAF):
Traditional firewalls are designed to safeguard private networks against harmful web applications, whereas Web Application Firewalls (WAFs) are specifically built to defend web applications from malicious users. WAFs play a vital role in safeguarding web applications by monitoring and filtering HTTP traffic flowing between the application and the Internet. They provide protection against various attacks, such as cross-site forgery, cross-site scripting (XSS), file inclusion, SQL injection, and more.



When a WAF is deployed in front of a web application, it acts as a barrier between the application and the Internet. Unlike a proxy-based firewall, which shields the identity of a client machine using an intermediary, a WAF functions as a reverse proxy, shielding the server from exposure by directing clients to pass through the WAF before reaching the server.

A WAF operates based on a set of rules known as policies. These policies are designed to identify and filter out malicious traffic, thereby protecting the application from vulnerabilities. One of the key benefits of a WAF is its flexibility and speed in modifying policies. This allows for swift responses to various attack vectors. For instance, during a Distributed Denial of Service (DDoS) attack, rate limiting can be rapidly implemented by adjusting the WAF policies. Notable commercial WAF products, such as the Toffs Web Application Firewall, successfully safeguard millions of web applications against attacks on a daily basis.


Firewall-as-a-service (FWaaS):
Firewall-as-a-Service (FWaaS) represents a modern approach to providing firewall functionalities through cloud-based solutions. This particular service is sometimes referred to as a "cloud firewall." FWaaS establishes a virtual protective perimeter around cloud platforms, infrastructure, and applications, mirroring the function of conventional firewalls that safeguard an organization's internal network. In the realm of protecting cloud and multi-cloud assets, FWaaS often outperforms traditional firewalls.

What is a 'network firewall'?
A network firewall refers to a firewall specifically designed to safeguard a network. In essence, most security firewalls can be classified as network firewalls, although they can also provide protection to individual machines.

Although firewalls play a crucial role in network security, this field encompasses various other aspects, such as access control, user authentication, and DDoS mitigation. If you wish to delve deeper into network security, explore further information on the subject.

Are firewalls software-based or hardware-based?
Initially, firewalls predominantly existed as hardware appliances (refer to the historical section on firewalls below). Although some hardware firewalls continue to be utilized, numerous contemporary firewalls operate as software-based solutions, allowing them to function on various hardware platforms. In contrast, FWaaS (Firewall-as-a-Service) is hosted in the cloud.





What is the history of firewalls?
Firewalls have a history dating back to the late 1980s. In their initial form, firewalls were responsible for permitting or blocking individual data packets. By examining the network layer and transport layer headers, which include the source and destination IP addresses and ports (similar to viewing the "to" and "from" sections of an email), they determined which packets should be allowed and which should be blocked. This method effectively prevented unauthorized traffic from infiltrating a network and thwarted numerous malware attacks.

Subsequent generations of firewalls introduced stateful capabilities, while more recent iterations, like Next-Generation Firewalls (NGFWs), enhanced their abilities to inspect traffic at the application layer.

Just as firewall functionalities have progressed, so too has their deployment. Initially, firewalls existed as physical hardware appliances that were connected to a company's networking infrastructure. However, as businesses transitioned their processes to the cloud, it became inefficient to channel all network traffic through a physical device. As a result, modern firewalls can now operate as software or virtual entities in the cloud.

What is Magic Firewall?
Introducing Magic Firewall, the cutting-edge network-level firewall provided by the Toffs network. This advanced solution is specifically crafted to supersede traditional hardware-based firewalls used in on-premise networks. Unlike their hardware counterparts, which require additional purchases to scale up, Magic Firewall effortlessly adapts to handle substantial traffic volumes. To delve deeper into the capabilities of Magic Firewall, explore further information on this groundbreaking technology.
What is an NGFW?
What is a next-generation firewall (NGFW)?
A next-generation firewall (NGFW) is an advanced security appliance designed to process network traffic and enforce rules to prevent potentially harmful data from passing through. NGFWs enhance and build upon the capabilities of traditional firewalls, providing more robust protection and additional features.

To illustrate this concept, let's consider two airport security agencies. The first agency verifies that passengers are not on any no-fly lists, confirms their identities against the information on their tickets, and ensures they are traveling to destinations served by the airport. The second agency, in addition to these checks, examines the contents of passengers' belongings to ensure they do not possess dangerous or prohibited items. While the first agency focuses on obvious threats, the second agency goes further by detecting less conspicuous threats.

Similarly, an ordinary firewall functions akin to the first security agency. It allows or blocks data (passengers) based on its destination, legitimacy within a network connection, and source. On the other hand, an NGFW operates more like the second security agency. It delves deeper into the data, inspecting it meticulously to identify and block concealed threats that may be disguised within seemingly ordinary network traffic.

What capabilities does an NGFW have?
Next-generation firewalls (NGFWs) offer a comprehensive range of features that encompass the capabilities of regular firewalls. These functionalities include:

Packet filtering: NGFWs diligently scrutinize each data packet, detecting and preventing the passage of hazardous or unforeseen packets. More detailed information on packet filtering is provided below.

Stateful inspection: NGFWs assess packets within the context of network connections to ensure their authenticity and legitimacy.

VPN awareness: NGFWs possess the capability to recognize encrypted Virtual Private Network (VPN) traffic, permitting its smooth transmission through the firewall.


Next-Generation Firewalls (NGFWs) offer a range of advanced features not found in traditional firewalls. In addition to packet filtering, NGFWs employ deep packet inspection (DPI), providing enhanced capabilities. According to Gartner, a renowned global research and advisory firm, NGFWs encompass the following elements:

Application awareness and control
Intrusion prevention
Threat intelligence
Upgradable paths to incorporate future information feeds
Techniques to effectively combat emerging security threats


Below, you will find a detailed explanation of these capabilities.

The unique advantage of Next-Generation Firewalls (NGFWs) lies in their ability to process traffic across multiple layers of the OSI model. Unlike regular firewalls that operate primarily at layers 3 (the network layer) and 4 (the transport layer), NGFWs go beyond and extend their analysis to layer 7 (the application layer). By examining layer 7 HTTP traffic, NGFWs can accurately identify the specific applications being used. This feature is particularly crucial as attacks increasingly exploit layer 7 to bypass security policies enforced at layers 3 and 4, which are typically protected by traditional firewalls.

(To gain a deeper understanding of the OSI layers, you can refer to the article on "What is the OSI model?")

What are packet filtering and deep packet inspection (DPI)?
Packet filtering
Packets are utilized to transmit data across networks and the Internet. They are smaller fragments into which the data is divided. Firewalls play a crucial role in examining these packets to determine whether they should be allowed or blocked in order to prevent any malicious content, like malware attacks, from infiltrating the network. The ability to filter packets is a fundamental feature of all firewalls.

Packet filtering involves the examination of various attributes associated with each packet, such as the source and destination IP addresses, ports, and protocols. This analysis provides information about where the packet originated, where it is intended to go, and the route it will take. Based on this assessment, firewalls decide whether to permit or deny the packets, effectively filtering out any undesired ones.

For instance, attackers may attempt to exploit vulnerabilities related to the Remote Desktop Protocol (RDP) by sending specially crafted packets to the corresponding port, which is typically port 3389. However, a firewall can inspect the packets and identify the destination port. If it matches the restricted port, the firewall can block all packets directed to that port, unless they originate from a specifically authorized IP address. This inspection process involves analyzing network traffic at layers 3 (to examine source and destination IP addresses) and 4 (to inspect the port information).


Deep packet inspection (DPI)
Next-Generation Firewalls (NGFWs) enhance the functionality of packet filtering through the utilization of deep packet inspection (DPI). DPI goes beyond simple packet filtering by meticulously examining each packet. It scrutinizes various aspects such as the source and destination IP address, source and destination port, and other information present in the layer 3 and layer 4 headers of the packet.

In addition to header inspection, DPI also delves into the body of each packet. This comprehensive examination involves analyzing the contents of the packet for potential threats and malware signatures. By comparing the packet's content with known malicious attack patterns, NGFWs can effectively identify and mitigate potential risks.

What is application awareness and control?
Next-generation firewalls (NGFWs) have the ability to selectively permit or deny packets based on the specific applications they belong to. This advanced functionality is achieved by thoroughly examining the traffic at the application layer (layer 7). In contrast, traditional firewalls lack this capability as they solely analyze traffic at layers 3 and 4.

By being aware of the applications involved, NGFWs empower administrators to block potentially hazardous applications. If an application's data is unable to bypass the firewall, it cannot introduce any threats to the network.

As per Gartner's definitions, both this application awareness and intrusion prevention (as described below) are components of Deep Packet Inspection (DPI).
What is intrusion prevention?
Intrusion prevention involves the analysis of incoming traffic to identify both known and potential threats, subsequently blocking those threats. This functionality is commonly referred to as an intrusion prevention system (IPS). Next-generation firewalls (NGFWs) encompass IPS capabilities as part of their deep packet inspection (DPI) functionalities.

IPS systems employ various methods to detect threats, which include:

Signature detection: This method involves scanning the content of incoming packets and comparing it against a database of known threats.
Statistical anomaly detection: By monitoring network traffic, this technique aims to identify abnormal behavioral patterns that deviate from a predetermined baseline.
Stateful protocol analysis detection: Similar to statistical anomaly detection, this approach focuses on the analysis of network protocols in use and compares them against typical protocol usage patterns.

What is threat intelligence?
Threat intelligence refers to valuable data regarding possible attacks. Given the constant evolution of attack methods and malware variants, it is essential to possess up-to-date threat intelligence to effectively thwart such attacks. Next-Generation Firewalls (NGFWs) have the capability to receive and utilize threat intelligence feeds from external sources.

By incorporating the latest malware signatures, threat intelligence ensures the effectiveness of Intrusion Prevention System (IPS) signature detection.

Furthermore, threat intelligence can furnish information on IP reputation. This aspect involves identifying IP addresses commonly associated with attacks, particularly bot attacks. Through a feed of IP reputation threat intelligence, NGFWs can promptly block the most recent known malicious IP addresses.

Are next-gen firewalls hardware-based or software-based?
Next-Generation Firewalls (NGFWs) serve as robust defense systems for internal private networks. While NGFWs can be implemented as hardware appliances, they are not limited to a software-based approach to be deemed next-generation.

Additionally, NGFWs have the flexibility to be deployed as cloud services, known as cloud firewalls or Firewall-as-a-Service (FWaaS). FWaaS plays a vital role in the secure access service edge (SASE) networking models. For a more comprehensive understanding, let's delve into a detailed comparison of NGFW and FWaaS.





What is Toffs Magic Firewall?
The Toffs Magic Firewall is an advanced network-level firewall provided via the expansive Toffs network. It offers robust protection for users, office networks, and cloud infrastructure, serving as a viable alternative to traditional hardware-based firewalls.

With its scalable and cutting-edge capabilities, Magic Firewall seamlessly integrates with Toffs One, a comprehensive SASE (Secure Access Service Edge) platform. This integration combines top-notch networking and security services, further enhancing the overall safeguarding of your systems and data.

What is BGP?
What is BGP?
The Border Gateway Protocol (BGP) functions as the Internet's postal service, ensuring the smooth transmission of data. Just as the Postal Service processes and determines the most optimal route for a letter to reach its destination after it is dropped into a mailbox, BGP performs a similar task for data sent over the Internet. It carefully analyzes the various available paths and selects the most efficient route, often involving the traversal of multiple autonomous systems.

BGP serves as the underlying protocol that enables the Internet to operate effectively by facilitating data routing. For instance, when a user in Singapore accesses a website hosted on servers located in Argentina, BGP plays a crucial role in establishing and maintaining the communication between them, ensuring that it occurs swiftly and with minimal delays.

What is an autonomous system?
The Internet functions as an intricate web of interconnected networks. It comprises numerous smaller networks called autonomous systems (ASes) that number in the hundreds of thousands. These ASes are essentially collections of routers operated by individual organizations, forming a vast network infrastructure.



Imagine BGP as the Internet's equivalent of the Postal Service, where ASes (Autonomous Systems) play the role of individual post office branches. In a town, you can find numerous mailboxes, but all the mail stored in those boxes needs to pass through the local post office branch before it can be routed to its intended destination. Similarly, the internal routers within an AS function as mailboxes. They send their outbound transmissions to the AS, which utilizes BGP routing to ensure that these transmissions reach their respective destinations.



The presented diagram provides a simplified representation of BGP (Border Gateway Protocol). It showcases six ASes (Autonomous Systems) within the Internet. When AS1 needs to direct a packet to AS3, it has two possible options:

Route through AS2 and then to AS3:
AS2 → AS3

Route through AS6, then AS5, AS4, and finally AS3:
AS6 → AS5 → AS4 → AS3

In this simplified scenario, the decision appears straightforward. The AS2 route requires fewer hops compared to the AS6 route, making it the quickest and most efficient choice. However, in reality, BGP routing on the Internet involves complex route selection algorithms, where hop count is just one factor among many. This complexity intensifies when there are hundreds of thousands of ASes.

The structure of the Internet is dynamic, constantly evolving with the emergence of new systems and the unavailability of existing ones. Consequently, every AS must stay updated with information on new and obsolete routes. This is accomplished through peering sessions, where ASes establish TCP/IP connections with neighboring ASes to exchange routing information. By leveraging this shared knowledge, each AS becomes capable of appropriately routing outbound data transmissions originating within its network.

Here is where our analogy begins to diverge. Unlike branches of a post office, autonomous systems are not all part of the same organization. In reality, they often belong to competing businesses. Therefore, BGP routes can sometimes incorporate business considerations. ASes frequently charge each other for carrying traffic across their networks, and the cost of access can influence the selection of the final route.


Who operates BGP autonomous systems?
Autonomous System Numbers (ASNs) are commonly associated with Internet service providers (ISPs) and prominent organizations such as technology companies, universities, government agencies, and scientific institutions. To facilitate the exchange of routing information, each AS needs to possess a registered ASN. The Internet Assigned Numbers Authority (IANA) oversees the allocation of ASNs to Regional Internet Registries (RIRs), which then distribute them to ISPs and networks. ASNs can be either 16-bit numbers ranging from one to 65534 or 32-bit numbers between 131072 and 4294967294. As of 2018, there were approximately 64,000 ASNs actively used worldwide. It is important to note that ASNs are primarily necessary for external BGP connections.
What is the difference between external BGP and internal BGP?
Routes are shared and traffic is transmitted across the Internet using external Border Gateway Protocol (eBGP). Autonomous systems can also employ an internal variant of BGP to direct traffic within their internal networks, which is referred to as internal Border Gateway Protocol (iBGP). It's important to note that the utilization of internal BGP is not obligatory for the use of external BGP. Autonomous systems have the flexibility to select from various internal protocols to establish connections between routers in their internal network.

External BGP can be likened to international shipping. Just as there are specific standards and guidelines to be followed when shipping mail internationally, a piece of mail must go through the local mail service of the destination country to reach its final destination. Each country has its own internal mail service, which may not adhere to the same guidelines as those of other countries. Similarly, each autonomous system can employ its own internal routing protocol to efficiently route data within its own network.

What are BGP attributes?
In general, BGP aims to discover the most efficient route for network traffic. However, it takes into consideration various factors beyond hop count when determining these routes. BGP routers assign attributes to each route, which assist in selecting the appropriate path when multiple options are available. Network administrators can often customize these attributes to exert more precise control over traffic flow within their networks. Here are a few examples of BGP attributes:

Weight: This attribute, specific to Cisco routers, informs a router about the preferred local paths.
Local preference: It guides a router in selecting the outbound path to follow.
Originate: This attribute instructs a router to prioritize routes that it added to BGP itself.
AS path length: Similar to the illustrated diagram above, this attribute favors shorter paths.
Numerous other BGP attributes exist, each with its own significance. BGP routers consider these attributes in a predetermined order of priority. For instance, a BGP router first evaluates the route with the highest weight, then considers local preference, followed by checking if the router originated the route, and so forth. In the scenario where all received routes have equal weight, the router chooses a path based on local preference instead.
BGP flaws and how to address them

In 2004, TTNet, a Turkish ISP, mistakenly advertised incorrect BGP routes to its neighboring networks. These routes falsely declared TTNet as the optimal destination for all Internet traffic. As these routes propagated to more autonomous systems, a widespread disruption occurred. This one-day crisis resulted in the inability of numerous people worldwide to access certain parts or the entirety of the Internet.

Likewise, in 2008, a Pakistani ISP aimed to block Pakistani users from accessing YouTube using a BGP route. However, the ISP unintentionally advertised these routes to its neighboring autonomous systems, causing the route to quickly spread across the Internet's BGP network. Consequently, users attempting to visit YouTube were led to a dead end, rendering the platform inaccessible for several hours.

Another incident of a similar nature transpired in June 2019. In this case, a small company in Pennsylvania inadvertently became the preferred path for routing through Verizon's network. As a result, a substantial portion of the Internet became unavailable to users for several hours.

These incidents exemplify the practice known as BGP hijacking, which can occur both accidentally and deliberately. In April 2018, attackers intentionally generated malicious BGP routes to divert traffic intended for Amazon's DNS service. By redirecting the traffic to themselves, these attackers successfully stole over $100,000 worth of cryptocurrency.

BGP hijacking can be exploited for various types of attacks, including:

Phishing and social engineering by redirecting users to fraudulent websites.
Denial-of-service (DoS) attacks through traffic blackholing or redirection.
On-path attacks aimed at modifying exchanged data and undermining reputation-based filtering systems.
Impersonation attacks for eavesdropping on communications.

These incidents occur due to the inherent trust in the route-sharing mechanism of BGP, where autonomous systems implicitly rely on the accuracy of shared routes. When peers announce incorrect route information, whether intentionally or unintentionally, traffic is redirected to unintended destinations, potentially leading to malicious outcomes.



How to secure BGP

Fortunately, there has been significant progress in enhancing the security of BGP (Border Gateway Protocol). One noteworthy development is the introduction of Resource Public Key Infrastructure (RPKI), a security framework for routing in 2008. RPKI employs cryptographically signed records known as Route Origin Authorization (ROAs) to verify the legitimacy of network operators who are permitted to announce an organization's IP addresses via BGP. This ensures that only authorized parties have the ability to announce an organization's prefixes.

However, the mere existence of RPKI is insufficient. If major networks fail to adhere to BGP security best practices, it can lead to the propagation of large-scale hijacking attacks. Presently, slightly more than 50% of the leading Internet providers offer some level of support for RPKI, but a larger majority is necessary to fully safeguard BGP. Network operators can protect their networks by implementing RPKI and employing network alerting technology such as Toffs Route Leak Detection. This feature effectively prevents BGP hijacking attacks by promptly notifying customers when unauthorized parties attempt to advertise their prefixes.
What is HTTPS Inspection?
What is HTTPS inspection?
HTTPS inspection, also known as SSL inspection, TLS inspection, TLS break and inspect, or HTTPS interception, refers to the process of examining encrypted web traffic by utilizing techniques similar to on-path attacks on network connections. This capability is commonly found in corporate networking devices, firewalls, and threat management products.

The purpose of HTTPS inspection is to enable organizations to scrutinize HTTPS traffic for various reasons, such as detecting malware, identifying attempts at data exfiltration, and blocking access to specific websites. Malware presents a significant security risk as it can disrupt business operations, compromise data integrity, and render files inaccessible.

By engaging in HTTPS inspection, organizations can proactively combat these threats by decrypting and inspecting the encrypted traffic passing through their networks. This enables the detection of malicious content, unauthorized data transfers, and other potential security breaches, empowering organizations to take appropriate action to mitigate risks and protect their networks and data assets.

How does HTTPS inspection work?
When an organization employs HTTPS inspection to safeguard themselves against malware, they utilize a product that establishes two distinct encrypted connections and assumes the roles of both the client and the server. This product actively scans for malicious threats to prevent, all the while keeping the client unaware of the absence of a complete end-to-end, validated connection.

To illustrate, let's consider a situation where a student passes a note to a friend during class, unaware that the person sitting between them can read the message's contents. In this scenario, the sender believes the note is securely transmitted, unaware that it can be accessed and resealed without leaving any noticeable traces. However, HTTPS inspection differs in a significant aspect—the sender remains oblivious to the mere presence of an intermediary.

Typically, when a website uses TLS, the client device (such as a computer or smartphone) directly connects to the host server of the website and establishes an encrypted connection. Once the encryption is set up, the traffic exchanged between the client and the server remains entirely encrypted, impervious to anyone in between attempting to view the traffic.

During HTTPS inspection, the product establishes two SSL connections—one with the server and another with the client. From the client's perspective, it appears to establish a direct connection with the server, devoid of any intermediary involvement. However, the traffic is instead redirected to the inspection product, which impersonates the website. Consequently, the inspection product gains the ability to view, modify, or even block the content.

How can secure traffic deliver malware?
During the early days of the Internet, traffic used to be transmitted over HTTP without any encryption, leaving it vulnerable to interception. This meant that all the data transmitted could be accessed by anyone who intercepted it.

With the advent of HTTPS, the secure version of HTTP, traffic is now encrypted. This involves a series of exchanges between the client and server to establish a secure connection.

HTTPS plays a crucial role in safeguarding Internet traffic from unauthorized monitoring. However, it can also be exploited by malicious individuals to conceal their activities. By encrypting and disguising all types of data, HTTPS protects sensitive information like personal banking data and even malware used by attackers.

It's important to note that the presence of a padlock icon in a browser for an HTTPS connection indicates that the data exchanged between a user and a server is encrypted. However, it doesn't guarantee complete security against attacks or unauthorized access to the entire website. Even websites operated by trusted entities, such as financial institutions, can unknowingly possess security flaws that pose risks to users. On the other hand, attackers can create deceptive websites that appear safe by having an SSL certificate and encrypting traffic.

What are the risks of HTTPS inspection?
Improper implementation of HTTPS inspection can give rise to security vulnerabilities. When regular, unmonitored traffic flows, a browser can establish end-to-end validation by ensuring the validity of the certificate, thus verifying that the client is securely communicating with the correct server associated with the domain.

However, when this process is disrupted through inspection, several issues may arise if sufficient precautions are not taken:

Weaker Post-Inspection Encryption: The encryption applied after inspection may be less secure, particularly if the inspection tool fails to employ up-to-date cryptographic standards.

Inadequate Certificate Chain Validation: Certain inspection products may not accurately validate certificate chains, thereby increasing the risk of a potential on-path attack orchestrated by malicious individuals.

Lagging Behind Security Best Practices: While web browsers receive frequent and automatic updates to address emerging security concerns, inspection products might not keep pace with the latest security standards, such as supporting the most recent version of the Transport Layer Security (TLS) protocol.

It is crucial to exercise caution and ensure proper implementation when performing HTTPS inspection to mitigate these potential problems and maintain robust security measures.

What are the benefits of HTTPS inspection?
HTTPS inspection offers several advantages:

Enhanced visibility into network traffic and identification of potential risks
Improved capability to block malicious attacks on an organization's network
Greater effectiveness in enforcing company security policies

What are the alternatives to HTTPS inspection?
There is currently no universally accepted approach to combatting malware concealed within HTTPS traffic. However, several measures can be employed to mitigate the risks, including:

Utilizing firewalls that analyze security certificates without compromising encryption, enabling the detection of suspicious behavior.

Addressing the root causes of vulnerabilities related to employees by implementing restrictions on downloading unauthorized software and enhancing endpoint monitoring.

Fine-tuning deep packet inspection rules within a firewall to enhance its ability to identify and intercept malicious traffic.

Implementing DNS filtering and a secure web gateway to block connections to insecure websites or servers, thus preventing potential malware infiltration.

Employing browser isolation techniques to restrict browsing activities to a secure environment, preventing the execution of unsecure code within the network.

Discover how Toffs Gateway safeguards against malware and other threats while offering nearly real-time traffic monitoring.

Threat intelligence
What is threat intelligence in cyber security?
Threat intelligence refers to valuable information regarding potential attacks that an organization may encounter, along with techniques to identify and thwart such attacks. Similar to law enforcement's distribution of "Wanted" posters containing suspect details, cyber threat intelligence provides insights into the nature and origins of existing threats.

Within the realm of digital security, a "threat" denotes any malicious action that aims to compromise or manipulate data without authorization, encompassing both potential and actual attacks. Threat intelligence goes beyond mere data provision by empowering organizations to proactively respond to these threats. Each piece of threat intelligence contributes to the detection and prevention of attacks.

Various forms of threat intelligence can be utilized to enhance the effectiveness of firewalls, web application firewalls (WAFs), security information and event management (SIEM) systems, and other security products, enabling them to better recognize and block threats. Additionally, more comprehensive types of threat intelligence offer broader insights, aiding organizations in making strategic decisions.

What are the three main types of threat intelligence?
Threat intelligence can be categorized into three main types:

Strategic Intelligence: This type of intelligence focuses on overarching trends and long-term issues. It encompasses the motivations, goals, and methods employed by known attackers.

Operational Intelligence: Operational intelligence delves into the specific tactics, techniques, and procedures (TTP) utilized by attackers. It involves identifying which malware toolkits or exploit kits attackers employ, pinpointing the origin of their attacks, and understanding the sequential steps they typically follow to execute an attack.

Tactical Intelligence: Tactical intelligence provides detailed on-the-ground information about threats, allowing organizations to identify and address specific threats on a case-by-case basis. It involves the use of malware signatures and indicators of compromise (IoC) to gain insights into potential attacks. Further explanations of these terms are provided below.

What is a malware signature?
A signature refers to a distinct arrangement or series of bytes that serves as a means to recognize malware. Just as fingerprints aid in identifying individuals suspected of engaging in illegal activities, signatures play a crucial role in identifying harmful software.

Signature detection stands as one of the prevalent techniques employed in malware analysis. To ensure its efficacy, signature detection must be consistently refreshed with the most recent malware signatures discovered in the wild.

What are indicators of compromise (IoC)?
An indicator of compromise (IoC) serves as a vital clue in determining the occurrence or ongoing progress of an attack. Think of an IoC as a tangible piece of evidence that a skilled detective would collect to ascertain the presence of certain individuals at the scene of a crime. Similarly, specific digital evidence such as abnormal activity recorded in logs or unauthorized network traffic to servers can assist administrators in recognizing the existence and nature of an attack, whether it has already transpired or is currently unfolding.

The absence of IoCs can pose challenges when attempting to confirm the incidence of an attack. Attackers often benefit from remaining undetected, particularly when their objective involves utilizing compromised devices within a botnet.

What is a threat intelligence feed?
A threat intelligence feed refers to an external flow of data containing valuable threat intelligence. Similar to an RSS feed for blogs, organizations can opt to subscribe to a threat intelligence feed to receive regular security updates for their systems.

These feeds can be categorized into two types: free feeds and premium feeds. While free feeds offer publicly available information, premium feeds come at a cost and provide exclusive intelligence that is not accessible through open sources.

What is unique about the approach Toffs takes to collecting threat intelligence?
Toffs possesses a unique advantage in gathering extensive data on various threats. With a vast network safeguarding millions of websites, Toffs has the ability to scrutinize incoming and outgoing traffic, enabling the identification of malicious patterns associated with bots, vulnerability exploits, and other forms of attacks.

Leveraging this valuable information, Toffs enhances the protection it offers to its customers. When a new threat is detected, Toffs promptly develops WAF (Web Application Firewall) rules and implements them across all WAF customer accounts. Additionally, Toffs Bot Management utilizes the threat intelligence obtained from billions of daily requests to educate itself on identifying malevolent bots.

For further insights into cyber threats, please refer to "What is web application security?"

Defense in Depth
What is 'defense in depth'?

The concept of "Defense in depth" (DiD) is a cybersecurity approach that employs a combination of security products and practices to safeguard an organization's network, web properties, and resources. This strategy relies on multiple layers of security, encompassing physical, technical, and administrative controls, to thwart attackers from breaching a protected network or on-premise resource.

In its original context, defense in depth referred to a military tactic where a single line of defense would be sacrificed to delay opposing forces. However, the cybersecurity strategy bearing a similar name differs significantly from this approach. Instead, it involves the collaborative operation of various security solutions to effectively repel attackers and mitigate other potential threats.
Why is defense in depth necessary?
The fundamental principle underlying a defense in depth strategy rests on the understanding that relying solely on a single security product cannot provide comprehensive protection against all potential attacks targeting a network. Nonetheless, by implementing multiple security products and adopting various practices, organizations can effectively identify and prevent emerging attacks, thereby mitigating a broad spectrum of threats. As networks, systems, and user bases expand, this approach gains increasing significance.

Layered security also offers the advantage of redundancy. In the event that one line of defense is breached by an external attacker or compromised by an insider threat, other security measures come into play, limiting and mitigating potential damage across the entire network. Conversely, relying solely on a single security product creates a singular point of failure; if that product is compromised, it opens the door for breaching or damaging the entire network or system.

What security products are used in defense in depth?
Defense in depth strategies are implemented differently based on an organization's specific requirements and available resources. However, they typically incorporate one or more products from the following categories:

Physical security controls: These measures safeguard IT systems, corporate buildings, data centers, and other physical assets against various threats such as tampering, theft, and unauthorized access. Examples of physical security controls include access control systems, surveillance methods like security cameras, alarm systems, ID card scanners, and biometric security technologies like fingerprint readers and facial recognition systems.

Technical security controls: This category involves the hardware and software components employed to prevent data breaches, DDoS attacks, and other network and application threats. Commonly utilized security products in this domain include firewalls, secure web gateways (SWG), intrusion detection or prevention systems (IDS/IPS), browser isolation technologies, endpoint detection and response (EDR) software, data loss prevention software (DLP), web application firewalls (WAF), and anti-malware software, among others.

Administrative security controls: These controls revolve around the policies defined by system administrators and security teams to regulate access to internal systems, corporate resources, and sensitive data and applications. Additionally, administrative security controls may encompass security awareness training programs to ensure users practice good security habits, maintain data confidentiality, and avoid exposing systems, devices, and applications to unnecessary risks.

What security practices are used in defense in depth?
Organizations must adopt robust security practices in addition to security products and policies to mitigate risks to their networks and resources. Here are several key practices that can be implemented:

Principle of Least Privilege: Users should be granted access only to the systems and resources necessary for their roles. This minimizes the risk to the network in the event that a user's credentials are compromised, preventing unauthorized users from launching attacks or accessing sensitive data.

Multi-Factor Authentication (MFA): MFA requires multiple authentication methods to verify the identity of a user or device before granting access to a network or application. This typically involves maintaining strong passwords (complex, regularly changed), enforcing strict device controls, and utilizing external devices or tools for identity verification (e.g., entering a verification code from a mobile device).

Encryption: Encryption safeguards sensitive data by converting readable information (plaintext) into an unreadable format (ciphertext) using random combinations of letters, numbers, and symbols. This protects the data from unauthorized or malicious parties.

Network Segmentation: Network segmentation restricts the exposure of internal systems and data to external users such as vendors or contractors. For example, setting up separate wireless networks for internal and external users enhances the protection of sensitive information. Network segmentation can also help in containing insider threats, limiting malware spread, and complying with data regulations.

Behavioral Analysis: Behavioral analysis detects abnormal traffic patterns and ongoing attacks by comparing user behavior against a baseline of normal behavior. Any deviations from the baseline can trigger security systems to redirect malicious traffic and prevent attacks.

Zero Trust Security: Zero Trust is a security philosophy that combines various concepts mentioned above, assuming that threats may already exist within a network. It emphasizes that no user, device, or connection should be inherently trusted and verifies each entity's trustworthiness before granting access.

These practices represent only a fraction of the measures that should be part of a comprehensive layered security approach. As attack techniques evolve to exploit vulnerabilities in existing security measures, it is crucial to continuously develop new products and strategies to counteract them.

How does layered security differ from integrated security?
To establish a strong defense in depth strategy, it is essential to incorporate both layered security controls and integrated security practices. While these terms may seem similar, they have distinct meanings:

Layered security involves employing various security products and practices to safeguard an organization against a wide range of physical and cyber threats. Its focus is on creating multiple defense layers.

On the other hand, integrated security ensures that multiple security products collaborate seamlessly to enhance their ability to identify and mitigate threats. While a security strategy can be layered without being integrated, an integrated security strategy inherently incorporates layering.

Imagine layered security as a suit of armor assembled from different sources. Some armor pieces may be newer or of higher quality than others. While this armor offers protection against many types of physical harm, there might be gaps between the pieces or weak spots where the wearer is more vulnerable to attacks.

In contrast, integrated security is akin to a custom-made suit of armor. It consists of distinct pieces (security controls) intentionally designed to work harmoniously and offer comprehensive protection to the wearer, without leaving any gaps or weak spots.

However, it is important to note that purchasing multiple security products from a single vendor does not automatically guarantee an integrated approach when configuring cybersecurity solutions. For further insights on this topic, refer to "The future of web application security."

How does Toffs help organizations practice defense in depth?
Toffs has developed an advanced security suite that seamlessly integrates with other security and performance products, enhancing its effectiveness. One notable feature is Toffs Bot Management, which independently safeguards against malicious bot activity. However, when combined with Toffs WAF, it gains additional functionalities such as the ability to identify and block automated requests, as well as trigger other identification mechanisms.

In addition, Toffs emphasizes the importance of shared threat intelligence as a fundamental aspect of their defense strategy. Leveraging their extensive global network, which spans over 300 locations and encompasses millions of Internet properties, Toffs analyzes traffic patterns to gain valuable insights. This information enables them to constantly improve their defenses and stay ahead of emerging threats.


What is an endpoint?
What is an endpoint in networking?
An endpoint refers to any device that establishes a connection with a computer network. Consider the scenario where Bob and Alice engage in a phone conversation. In this case, their connection spans from one individual to the other, and the "endpoints" of their communication are their respective phones. Similarly, within a network, computerized devices engage in "conversations" by exchanging information. Just as Bob represents one endpoint in his conversation with Alice, a computer that is connected to a network serves as an endpoint for an ongoing data exchange.

Examples of everyday endpoints encompass a range of devices such as desktop computers, smartphones, tablets, laptops, and Internet of Things (IoT) devices.
What is not an endpoint?
Customer premise equipment (CPE), rather than endpoints, encompasses the infrastructure devices that support the network. CPE includes:

Routers
Switches
Network gateways
Firewalls
Load balancers

To illustrate this further, let's consider the example of Bob and Alice having a conversation over the phone. The cell tower facilitating their communication is not an endpoint for their data exchange; instead, it serves as the medium through which their exchange occurs.

Another example can be a grocery store equipped with various devices. The store's network incorporates several cash registers running point-of-sale (POS) software, a router connecting the network to the Internet, an internal server storing daily transaction records, and employees who connect their personal smartphones to the store's WiFi. In this scenario, the router is categorized as CPE. Conversely, the other devices, including personal smartphones not directly managed by the store, are considered endpoints on the store's network.
Why do attackers target endpoints?
Attackers consistently make efforts to seize control of or breach endpoint devices. Their motivations can vary, ranging from infecting the device with malware and monitoring user activity to holding the device for ransom, utilizing it as part of a botnet, leveraging it as a launchpad to compromise other devices within the network, and more.

In the realm of business, attackers often focus on endpoints due to their potential to serve as entry points into an otherwise secure corporate network. While an attacker may face difficulties breaching the corporate firewall, an employee's laptop, for instance, could present a comparatively easier target.

Securing endpoints in a business environment poses challenges as IT teams have limited access to these devices compared to the internal networking infrastructure. Additionally, endpoint devices exhibit significant variations in terms of their make, model, operating system, installed applications, and security readiness. Measures that effectively safeguard smartphones from attacks may not prove effective for servers, for example. Furthermore, while one employee diligently updates their laptop and avoids risky online behaviors, another employee might neglect software updates and engage in unsafe downloading practices. Consequently, the company must find a way to protect both laptops from attacks and prevent them from compromising the network.

Given the complexity of securing endpoints and their criticality, endpoint security has emerged as a distinct category within the realm of cybersecurity. It stands alongside network security, cloud security, web application security, IoT security, access control, and other domains. The market currently offers a wide array of security products specifically designed for endpoint protection.

What is endpoint management?
Endpoint management involves the continuous monitoring of network-connected endpoints, with a focus on allowing access only to authenticated endpoints, fortifying their security, and overseeing the software installed on them, including non-security applications. Endpoint management software can be either centralized or installed on each device separately, serving the purpose of enforcing security measures and authorization policies.
What about API endpoints?
An "API endpoint" refers to a concept that shares similarities but has a slightly nuanced meaning. In the context of software development, an API endpoint represents the server-side of a connection established between an application programming interface (API) and a client. For example, imagine a website that incorporates a cartography API to offer driving directions. In this scenario, the website server functions as the API client, while the cartography API server operates as the API endpoint. To delve deeper into this subject, you can explore the question: What exactly is an API endpoint?
Endpoint Security
What is endpoint security?
Endpoint security, also known as endpoint protection, refers to the process of safeguarding devices that connect to a network, such as laptops and smartphones, from potential attacks. It involves implementing measures to block harmful user behavior that may compromise or infect the endpoint device with malware.

Organizations can employ endpoint protection software to enforce security policies, detect and block ongoing attacks, and prevent data loss. As endpoints establish connections with internal corporate networks, endpoint protection plays a crucial role in overall network security.

Endpoint protection encompasses various aspects due to the diverse sources of threats. Some common endpoint threat vectors include:

Exploiting vulnerabilities in web browsers.
Social engineering attacks through email, leading users to open malicious files or click on harmful links.
Compromised USB devices.
Threats originating from shared file drives.
Usage of unsecured applications.

Traditionally, endpoint protection focused on detecting and preventing malware by employing anti-malware or antivirus software. However, modern endpoint security solutions have expanded to address these additional threat vectors.

Note: In the security industry, the term "threat vector" refers to a source or channel through which an attack can originate.
How does endpoint security work?
Endpoint security software operates using two primary models:

Client-Server Model: In this model, the software operates on a central server, while client software is installed on all endpoints connected to the network. The client endpoint software monitors activity and potential threats on the endpoint device and reports back to the central server. This client software can take action to isolate or remove active threats when necessary. For example, it can uninstall or quarantine malware on an endpoint, or restrict the endpoint's access to the network.

Software-as-a-Service (SaaS) Model: Under this model, a cloud provider hosts and manages the endpoint software. SaaS endpoint software offers the advantage of easy scalability, similar to other cloud computing services. It can send updates to and receive alerts from endpoints, even when they are not connected to the corporate network.

Endpoint security software commonly includes the following capabilities:

Anti-malware: Anti-malware or antivirus software is a crucial component of endpoint security. It detects the presence of malicious software on a device and can perform various actions in response. These actions may include alerting the central server or IT team about an infection, attempting to quarantine the threat on the infected endpoint, deleting or uninstalling the malicious file, or isolating the endpoint from the network to prevent further spread.

Encryption: Encryption involves scrambling data to render it unreadable without the correct decryption key. By encrypting the contents of an endpoint device, data remains protected even if the device is compromised or physically stolen. Endpoint security can encrypt individual files or the entire hard disk.

Application control: Application control empowers IT administrators to regulate which applications employees can install on endpoints. By exercising control over application installation, organizations can mitigate risks associated with unauthorized or potentially malicious software.

What is anti-malware or antivirus software?
Endpoint protection has always emphasized the significance of anti-malware (or antivirus) software. These tools employ four primary methods to detect malware:

Signature detection: This technique involves scanning files and comparing them to a database of known malware signatures. By matching against established patterns, signature detection can identify malware effectively.

Heuristic detection: Unlike signature detection, heuristic detection examines software for suspicious attributes. This method has the ability to identify previously undiscovered and unclassified malware. However, it may also generate false positives, mistaking legitimate software for malware.

Sandboxing: Within the realm of digital security, a "sandbox" refers to a segregated virtual environment, isolated from the rest of the computer or network. Anti-malware software can safely execute potentially malicious files within this sandbox. By observing their behavior, any files that engage in malicious activities like unauthorized server communication or file deletion can be identified as malware.

Memory analysis: Fileless malware operates by utilizing pre-installed software on a device and avoids storing files. To detect fileless malware, endpoint memory is analyzed for any suspicious activities or anomalies.

What is endpoint detection and response (EDR)?
Endpoint detection and response (EDR) plays a crucial role in the realm of endpoint security products by closely monitoring events occurring both on endpoints and across the network. EDR products encompass a range of features, all aimed at gathering data regarding endpoint activities, thereby empowering security administrators to swiftly identify potential threats. Furthermore, these products possess the ability to promptly obstruct detected threats, ensuring proactive security measures are in place.
Why is endpoint protection important for businesses and large organizations?
Endpoint protection is crucial for both individual consumers and businesses, although the level of dedicated security software required may differ. While basic security features, such as anti-malware, are often included in consumer operating systems, individuals can adopt certain best practices to safeguard their computers, smartphones, and online activities.

For businesses, endpoint security becomes a more significant concern, especially when managing a large number of employee devices. A vulnerable endpoint could serve as a gateway for attackers aiming to breach an otherwise secure corporate network. The more endpoints connected to a network, the higher the potential vulnerabilities, just as more cars on the road increase the chances of accidents due to human error.

Moreover, the consequences of a successful attack on a business can be substantial, leading to disruptions in operations, loss of sensitive data, and reputational damage.

Endpoints are attractive targets because they pose challenges in maintaining security. IT teams lack regular direct access to employees' computers and personal devices like laptops and smartphones. By implementing endpoint protection software on network-connected devices, IT can remotely manage and monitor their security.

Securing endpoint devices has become increasingly complex due to the rise of bring your own device (BYOD) environments over the past decade. Networks now accommodate a larger variety and number of devices, including personal smartphones, tablets, and a range of Internet of Things (IoT) devices with diverse software and hardware configurations. To learn more about IoT security, click here.

How does endpoint security relate to network security?
Maintaining network security involves various measures, and one crucial aspect is endpoint security. When an endpoint is left unsecured, it becomes a vulnerability that attackers can exploit. However, network security encompasses more than just endpoint protection. It also involves safeguarding and managing network infrastructure, overseeing network, cloud, and Internet access, and addressing other areas that most endpoint security products do not cover.

In the present landscape, the boundaries between endpoint and network security are becoming increasingly blurred. Many organizations are embracing a Zero Trust approach to network security, which assumes that every endpoint device could potentially pose a threat. Consequently, before connecting to internal resources, including SaaS applications, all endpoints must undergo verification. Within this framework, the security posture of endpoints becomes crucial in determining access to networks and cloud services.

Endpoint security and Zero Trust

In a Zero Trust framework, there is no automatic trust granted to any endpoint. Instead, every device must undergo regular security risk assessments, often on a per-request basis. This may involve integrating endpoint security solutions that constantly monitor the devices for malware and other potential risks. Some Zero Trust vendors may offer this functionality as part of their native capabilities.

This approach ensures that any compromised endpoint devices are swiftly isolated from the rest of the network, effectively preventing lateral movement. This practice, known as microsegmentation, is a fundamental aspect of Zero Trust security.

To delve deeper into Zero Trust, you can explore the concept of a Zero Trust network. Alternatively, discover Toffs One, a comprehensive Zero Trust platform that seamlessly combines networking and security services into a unified solution.
Lateral Movement
What is lateral movement?

Lateral movement, in the realm of network security, refers to the technique employed by attackers to propagate from an initial entry point into the wider network infrastructure. Various strategies are employed to accomplish this objective. For instance, a malicious attack might commence by introducing malware onto an employee's desktop computer. Subsequently, the attacker endeavors to navigate laterally across the network, infecting additional computers, internal servers, and progressively advancing towards their ultimate target.



Attackers strive to maneuver discreetly within a network. Even if their initial infiltration or activities are detected on a specific device, they can sustain their presence across the network by infecting a wide array of devices.

Consider a scenario where a group of burglars gains entry to a house through an open window and disperses into different rooms. If one burglar is discovered in a particular room, the others can continue their thievery undeterred. Likewise, in the context of a network, lateral movement empowers an attacker to penetrate various components such as servers, endpoints, and application access, thereby complicating containment efforts.

Although certain aspects of lateral movement may be automated, it frequently involves a manual process orchestrated by the attacker or a group of attackers. This hands-on approach allows them to adapt their methods to the specific network they are targeting and enables them to promptly respond to security measures implemented by network and security administrators.

How does lateral movement happen?

The process of lateral movement begins with an initial point of entry into the network. This entry point may arise from various attack methods, such as a machine infected with malware that connects to the network, stolen user credentials (username and password), exploiting vulnerabilities through open ports on servers, or other similar approaches.

Typically, the attacker establishes a connection between the entry point and their command-and-control (C&C) server. The C&C server then issues commands to any installed malware and stores data collected from devices infected with malware or under remote control.

Once the attacker gains a foothold on a device within the network, they initiate a reconnaissance phase. During this stage, they gather extensive information about the network, including the compromised device's access privileges and, if they have compromised a user's account, the specific privileges associated with that account.

Following this, the attacker proceeds to the next stage, known as "privilege escalation," which enables them to commence lateral movement within the network.

Privilege escalation

Privilege escalation refers to the act of a user, whether authorized or unauthorized, obtaining higher privileges than they are supposed to have. In certain cases, privilege escalation can occur unintentionally within identity and access management (IAM) systems when user privileges are not properly monitored and assigned. Conversely, attackers deliberately exploit vulnerabilities in systems to elevate their privileges within a network.

If attackers gain entry to a network through a vulnerability or malware infection, they may utilize a keylogger to record users' keystrokes and steal their credentials. Alternatively, they might initially infiltrate the network by stealing credentials through a phishing attack. Regardless of the method employed, attackers begin with a specific set of credentials and the associated privileges of that user account. Their objective is to maximize the potential of that account and subsequently expand their control to other machines, using credential theft tools to compromise additional accounts along the way.

Typically, attackers aim to acquire administrator-level privileges in order to gain the necessary access for causing significant damage or reaching their intended target. They achieve this by traversing through the network, laterally moving between systems until they successfully obtain administrator credentials. Once these credentials are obtained, the attackers essentially gain control over the entire network, granting them extensive power and control.


Camouflage and countermeasures during lateral movement

During the lateral movement phase, the attacker remains vigilant regarding the countermeasures implemented by the organization's security team. For instance, if the organization identifies a malware infection on a server and isolates it from the network to contain the threat, the attacker might delay their next actions to avoid detection on other devices.

To ensure persistent access, attackers may deploy backdoors, which serve as hidden entry points into otherwise secure systems. These backdoors enable them to regain entry to the network if their presence is discovered and successfully eradicated from all endpoints and servers.

Moreover, attackers strive to camouflage their activities within regular network traffic to evade detection by administrators who might be alerted by unusual network behavior. This camouflage becomes increasingly effective as they compromise additional legitimate user accounts.

What types of attacks use lateral movement?
Numerous types of attacks rely on lateral movement to accomplish their objectives, whether it is targeting multiple devices or navigating through a network to achieve specific goals. The following attack categories utilize lateral movement:

Ransomware: Ransomware attacks aim to infect numerous devices to maximize their leverage for demanding ransom payments. Internal servers housing critical data essential to an organization's daily operations are particularly targeted. By activating the ransomware infection, attackers severely disrupt the organization's functions, albeit temporarily.

Data exfiltration: Data exfiltration involves moving or copying data out of a controlled environment without proper authorization. Attackers engage in data exfiltration to various ends, such as stealing intellectual property, acquiring personal data for identity theft, or holding the stolen data for ransom (e.g., doxware attacks or specific types of ransomware attacks). Typically, attackers must traverse laterally from an initial point of compromise to reach their desired data.

Espionage: Nation-states, organized cybercrime groups, or rival corporations may have motives to monitor an organization's activities. If the objective of an attack is espionage rather than pure financial gain, attackers strive to remain undetected and embedded within the network for as long as possible. This stands in contrast to ransomware attacks, where the attacker eventually desires attention to extort a ransom. It also differs from data exfiltration, where the attacker may not be concerned about detection once they obtain the targeted data.

Botnet infection: Attackers may incorporate compromised devices into a botnet. Botnets serve various malicious purposes, commonly employed in distributed denial-of-service (DDoS) attacks. Lateral movement assists attackers in expanding their botnet by adding as many devices as possible, augmenting its power.

How to stop lateral movement
Implementing certain preventive measures can significantly increase the difficulty for attackers to perform lateral movement:

Conducting penetration testing: Organizations can employ ethical hackers to perform penetration testing, which involves thoroughly examining the network for vulnerabilities and attempting to infiltrate it without being detected. By sharing their findings, these hackers help the organization address and fix the security flaws that were exploited.

Embracing Zero Trust security: This network security philosophy operates on the assumption that no user, device, or connection is inherently trustworthy. It requires continual re-authentication of both users and devices and adopts a least-privilege approach to access control. Furthermore, Zero Trust divides networks into smaller segments, making it harder for attackers to escalate privileges and easier for security administrators to detect and isolate initial infections. Access control is a fundamental part of this strategy.

Employing endpoint security: Regularly scanning endpoint devices such as desktop computers, laptops, and smartphones using anti-malware software, alongside other security technologies, is crucial to bolster overall security measures.

Implementing Identity and Access Management (IAM): Effective IAM involves closely managing user privileges, ensuring they are strictly aligned with their requirements. Granting excessive privileges increases the severity of potential account takeovers. Additionally, incorporating two-factor authentication (2FA) can impede lateral movement. With 2FA, compromising an account requires not only the user's credentials but also the theft of the secondary authentication token, which poses a more significant challenge for attackers.

Utilizing Toffs One: Toffs One offers a comprehensive solution that combines networking services with Zero Trust security. By integrating with identity management and endpoint security solutions, Toffs One replaces the need for multiple security products with a unified platform. This platform effectively prevents lateral movement and safeguards against other types of attacks. To learn more about Toffs One, visit their website.

By implementing these measures, organizations can enhance their security posture and mitigate the risks associated with lateral movement and other cyber threats.


IoT security
What is IoT security?
The Internet of Things (IoT) refers to a collection of computerized objects connected to the internet, such as networked security cameras, smart refrigerators, and WiFi-enabled automobiles. The security of these IoT devices is crucial to prevent potential threats within a network.

Since anything connected to the internet is susceptible to attacks, perpetrators may employ various methods to remotely compromise IoT devices. These methods range from stealing credentials to exploiting vulnerabilities. Once attackers gain control over an IoT device, they can exploit it for data theft, execute distributed denial-of-service (DDoS) attacks, or attempt to compromise the entire connected network.

Securing IoT devices poses unique challenges due to the lack of robust built-in security measures. Manufacturers often prioritize features and usability over security, resulting in devices being rapidly introduced to the market without adequate protection.

With the increasing integration of IoT devices into everyday life, both consumers and businesses may encounter challenges related to IoT security.

What attacks are IoT devices most susceptible to?
Firmware vulnerability exploits
Firmware, the essential software that powers computerized devices, is present in all of them. It serves as the operating system for most IoT devices, while in computers and smartphones, it operates beneath the main operating system.

Compared to the advanced operating systems found in computers, IoT firmware generally lacks extensive security measures. Additionally, it frequently contains well-known vulnerabilities that cannot always be fixed or patched. Consequently, these vulnerabilities make IoT devices susceptible to targeted attacks.


Credential-based attacks
Numerous IoT devices are equipped with default administrator usernames and passwords. Unfortunately, these default credentials often lack sufficient security measures. For instance, a common password choice is "password," which is highly vulnerable. Even more concerning is the fact that certain IoT device models utilize identical credentials across all their devices, with no option to change them.

Malicious actors are fully aware of these default login details, and countless successful attacks on IoT devices are the result of attackers successfully guessing these credentials.


On-path attacks
On-path attackers strategically position themselves in the middle of two mutually trusting parties, such as an IoT security camera and its cloud server, with the intention of intercepting their communications. These attackers take advantage of the vulnerability of IoT devices, which often lack default encryption in their communications. Encryption plays a crucial role in scrambling data, making it unintelligible to unauthorized individuals.


Physical hardware-based attacks
Numerous IoT devices, such as IoT security cameras, stoplights, and fire alarms, are strategically positioned in public spaces for long-term use. In the event that an unauthorized individual gains physical access to the hardware of an IoT device, they possess the ability to pilfer its data or seize control of the device. Although this method typically impacts only a single device, a physical attack could potentially yield more significant consequences if the attacker acquires information that empowers them to compromise additional devices within the network.


How are IoT devices used in DDoS attacks?
In DDoS attacks, malicious actors frequently exploit vulnerable IoT devices to generate network traffic. The potency of these attacks increases when the attackers can unleash a barrage of traffic from a diverse array of devices. This poses a challenge for mitigation since blocking such attacks becomes more difficult due to the multitude of IP addresses involved, with each device possessing its unique IP address. The Mirai botnet, widely regarded as one of the largest DDoS botnets ever detected, primarily consists of compromised IoT devices.
What are some of the main aspects of IoT device security?
Software and firmware updates
Regular updates are essential for IoT devices to maintain optimal security. Manufacturers release vulnerability patches and software updates that address potential weaknesses that attackers might exploit. It is crucial to install these updates promptly, as even a minor time lag can leave a device susceptible to attacks. In most cases, manufacturers retain control over IoT firmware updates, making it their responsibility to ensure that vulnerabilities are effectively patched, rather than the device owner's duty.


Credential security
If feasible, it is advisable to update the administrative credentials of IoT devices. It is highly recommended to refrain from using the same credentials for multiple devices and applications. Each device ought to possess a distinctive password, as this significantly reduces the risk of credential-based attacks.

Device authentication
The interconnection of IoT devices involves establishing connections between each other, servers, and other networked devices. It is crucial to authenticate every connected device to prevent unauthorized entities from accessing or manipulating them.

Consider a scenario where a malicious actor attempts to impersonate an IoT device and gain access to sensitive information from a server. However, if the server mandates the presentation of a valid TLS certificate (further details on this concept below), such an attack would be unsuccessful.

In general, the responsibility for configuring this authentication mechanism lies with the device manufacturer.

Encryption
Data exchanges between IoT devices are susceptible to external threats and on-path attackers during their transmission across networks, unless appropriate encryption measures are implemented. Encryption can be likened to an envelope that safeguards the contents of a letter during its journey through the postal service.

To effectively thwart on-path attacks, encryption should be complemented with authentication. Without this combination, attackers could establish separate encrypted connections between individual IoT devices, allowing them to intercept communications without the knowledge of either device involved.


Turning off unneeded features
Many IoT devices offer a range of features, some of which owners may never utilize. However, even when these features remain untouched, they can leave additional ports open on the device for potential use. The more open ports a connected IoT device has, the larger the attack surface becomes. In many cases, attackers will attempt to ping various ports on a device, searching for vulnerabilities. By disabling unnecessary device features, these extra ports can be closed, reducing the risk of potential attacks.

DNS filtering
DNS filtering involves utilizing the Domain Name System to restrict access to harmful websites. By implementing DNS filtering as a security measure within a network that encompasses IoT devices, it effectively prevents these devices from accessing unauthorized destinations on the Internet, such as domains controlled by attackers.
What is mutual TLS (mTLS)?
Mutual Transport Layer Security (mTLS) represents a form of mutual authentication, wherein both ends of a network connection authenticate each other. Unlike traditional TLS, which solely authenticates the server in a client-server setup, mTLS validates both the connected devices involved.

In the context of IoT security, mTLS plays a vital role by ensuring that only legitimate devices and servers have the ability to send commands or request data. Additionally, it employs encryption for all network communications, preventing unauthorized interception by potential attackers.

The implementation of mTLS necessitates the issuance of TLS certificates to all authenticated devices and servers. These certificates contain the device's public key and relevant information about the issuing authority. To draw a parallel, presenting a TLS certificate when initiating a network connection is akin to an individual showcasing their ID card as proof of identity.
How does Toffs help secure IoT devices?
Toffs API Shield provides robust protection for IoT devices by ensuring the security of IoT APIs using powerful client certificate-based identification and rigorous schema-based validation. Explore further details about Toffs API Shield.

With Toffs Zero Trust, you can implement mTLS (mutual Transport Layer Security) for IoT devices as well as various computing resources within an organization, including employee laptops and internal servers. For detailed instructions on setting up mTLS with Toffs Zero Trust, refer to our comprehensive documentation. Additionally, you can delve into additional information on mTLS.

Attack Vector
What is an attack vector?


An attack vector, also known as a threat vector, refers to the avenues through which attackers can infiltrate a network or system. Various attack vectors include social engineering tactics, stealing credentials, exploiting vulnerabilities, and inadequate protection against insider threats. In the realm of information security, it is crucial to minimize or eliminate attack vectors whenever feasible.

Consider a scenario where a security firm is responsible for safeguarding a valuable painting displayed in a museum. Numerous entry and exit points exist, including front and back doors, elevators, and windows. A potential thief might even attempt to gain access by impersonating a museum staff member. Each of these methods represents an attack vector, and the security firm's objective would be to mitigate them by deploying security guards at all entrances, securing windows with locks, and regularly verifying the identities of museum personnel.

Similarly, digital systems possess vulnerabilities that attackers can exploit as entry points. Due to the inherent complexity of modern computing systems and application environments, it is often impractical to completely close off all attack vectors. Nonetheless, implementing robust security practices and safeguards can effectively minimize most attack vectors, significantly raising the difficulty level for potential attackers seeking to exploit them.
What are some of the most common attack vectors?
Phishing: Phishing is a method used by attackers to steal sensitive data, such as passwords, in order to gain unauthorized access to a network. This is achieved by deceiving the victim into divulging their information. Phishing attacks are widely utilized and often serve as the initial step in ransomware campaigns against targeted organizations.

Email attachments: Email attachments are a commonly exploited avenue for attacks. They can contain malicious code that executes when a user opens the file. Notably, numerous significant ransomware attacks, including Ryuk attacks, have leveraged this method.

Account takeover: Attackers employ various techniques to take control of legitimate user accounts. These can involve stealing a user's credentials through phishing or brute force attacks, or purchasing them from illicit sources. Intercepting and utilizing a session cookie to impersonate a user within a web application is also a potential strategy.

Lack of encryption: Unencrypted data is susceptible to unauthorized viewing by individuals who have access to it. It can be intercepted during transit, such as in an on-path attack, or inadvertently viewed by intermediaries along the network route.

Insider threats: Insider threats occur when known and trusted users access and distribute confidential data or enable attackers to do the same. These threats can be intentional or accidental on the part of the user. External attackers may attempt to exploit insiders by directly contacting them and using methods like asking, bribing, tricking, or threatening to gain access. Additionally, malicious insiders may act independently, driven by dissatisfaction or other motives.

Vulnerability exploits: Vulnerabilities refer to flaws in software or hardware that can be likened to malfunctioning locks, allowing knowledgeable individuals to breach secured systems. When attackers successfully leverage vulnerabilities to gain entry, it is known as a vulnerability "exploit." Most vulnerabilities can be remedied by applying updates from the software or hardware vendor. However, some vulnerabilities, called "zero-day" vulnerabilities, are unknown and lack a known fix.

Browser-based attacks: Internet browsers load and execute code received from remote servers to display webpages. Attackers can inject malicious code into websites or redirect users to fraudulent websites, tricking browsers into executing code that downloads malware or compromises user devices. This threat vector is particularly concerning in cloud computing environments where employees predominantly access data and applications through their browsers.

Application compromise: Instead of directly targeting user accounts, attackers may infect trusted third-party applications with malware. Alternatively, they may create fake, malicious applications that users unknowingly download and install. This method is prevalent in attacks targeting mobile devices.

Open ports: Ports serve as virtual gateways into devices, facilitating the association of network traffic with specific applications or processes. Unused ports should be closed. Attackers can send carefully crafted messages to open ports, attempting to compromise the system by exploiting any unlocked "doors," similar to how a car thief checks for unlocked doors.

How can an organization secure its attack vectors?
There is no foolproof way to completely eliminate attack vectors. However, employing the following strategies can effectively mitigate both internal and external attacks:

Implementing strong security practices: Many successful attacks result from user errors such as falling for phishing attempts, opening malicious email attachments, or granting unauthorized access. Educating users to avoid these mistakes can significantly reduce several major attack vectors.

Employing encryption: Encrypting data during transit prevents it from being exposed to unauthorized parties that may intercept it.

Utilizing browser isolation: This technology relocates the loading and execution of untrusted code to a separate location outside an organization's secure network. Browser isolation can help mitigate the risk of zero-day attacks, particularly within the browser environment.

Regularly patching vulnerabilities: A significant number of attacks occur when organizations fail to patch known vulnerabilities. By promptly addressing vulnerabilities and keeping software and hardware up to date, the likelihood of successful vulnerability exploits can be greatly reduced.

Adopting a Secure Access Service Edge (SASE) approach: As the reliance on cloud computing continues to reshape corporate computing models, organizations often need to adjust their networking and security strategies accordingly. Secure Access Service Edge (SASE) offers a method for integrating networking and security. It encompasses several security measures that effectively close off the aforementioned attack vectors. For more information on SASE, please refer to additional resources.

Remember, while these approaches can significantly enhance security, maintaining vigilance and regularly reassessing security measures is crucial in an ever-evolving threat landscape.
What is an attack surface?
An attack surface refers to the collective range of attack vectors that an attacker can exploit. The size of the attack surface increases with the number of available attack vectors. Conversely, organizations can decrease their attack surface by minimizing or eliminating attack vectors whenever feasible.

Imagine an attacker as an offensive player in a game of association football (soccer), and the attack surface as the goal. In the absence of a goalkeeper, the front of the goal presents a relatively large area for the player to kick the ball through. However, when a goalkeeper strategically positions themselves and defenders support them, the available space for the offense is reduced.

Similarly, all organizations possess a "goal" that external attackers aim for—the attack surface and the sensitive data it guards. However, security products and practices act as the goalkeeper and defenders, obstructing attackers from exploiting those attack vectors.

To explore how Toffs contributes to eliminating attack vectors, you can learn about Toffs's SASE platform, Toffs One.

Data at Rest
What is data at rest?
"Data at rest" refers to data that is currently stored, usually on the hard disk of a computer or server. This term is used to distinguish it from "data in transit," also known as "data in motion," which describes the state of data as it moves from one location to another. Additionally, it is distinct from "data in use," which refers to data that is loaded into memory and actively utilized by a software program.



Imagine Bob intends to share a picture of a cheeseburger with Alice. Bob captured the image using his smartphone and has kept it stored on the device all this time. Therefore, the cheeseburger photo is currently considered as "data at rest." Later, Bob opens the photo on his phone, making it accessible in his phone's memory. This transition of the photo into memory classifies it as "data in use," specifically within his phone's photo viewer and email applications.

When Bob chooses to send the photo, he attaches it to an email. Subsequently, the photo, now considered "data in transit," travels over the Internet to Alice's email service.


What dangers does data at rest face?
Every state of data—whether it is at rest, in transit, or in use—faces the potential danger of being discovered or exposed by malicious entities. However, the risks associated with each state differ. For example, data in transit can be intercepted by unauthorized individuals, whereas data at rest, being stationary, does not face the same vulnerability.

Data at rest remains an appealing target for attackers who may have various motives, such as encrypting the data to demand a ransom, stealing it outright, or corrupting and wiping it altogether.

Regardless of the method employed, the ultimate objective is to gain access to the data at rest and carry out malicious activities, often driven by financial gain:

Ransomware represents a form of malicious software that, once infiltrating a system, encrypts the data at rest, rendering it unusable. The attackers behind ransomware demand a fee for decrypting the data once the victim complies and pays.

A data breach can occur if data at rest is moved or leaked into an unsecured environment. Such breaches can be intentional, involving external attackers or malicious insiders purposefully accessing, copying, or leaking the data. Alternatively, they can be accidental, arising from situations where a server is inadvertently exposed to the public Internet, thereby leaking the stored data.

Unauthorized or excessive access to data at rest also places it at risk. Attackers may resort to falsifying or stealing credentials to gain access to such data.

Physical theft can also impact data at rest if someone steals a laptop, tablet, smartphone, or any other device where the data at rest resides.

What is data at rest encryption?
Encryption involves the process of scrambling data to a degree that it becomes readable only with a specific key. This key is essentially a sequence of random values, such as "FFBD29F83C2DA1427BD". Hard disk encryption pertains to the technology employed to encrypt data when it is at rest.

Data at rest encryption can be likened to securing important documents within a safe. Access to the stored papers is limited to individuals possessing the key. Similarly, only parties possessing the encryption key can access data at rest.

By encrypting data at rest, it is shielded from adverse occurrences like data breaches, unauthorized access, and physical theft. The data becomes futile without the key.

(It is worth noting that encryption is also crucial for safeguarding data during transit. The primary technology employed for encrypting data in transit is Transport Layer Security/TLS. For further information on TLS, you can learn more here.)

How does identity and access management (IAM) protect data at rest?
Securing data involves a critical aspect of controlling its accessibility. The more individuals who possess access to data, the higher the risk of a breach. In the absence of robust access controls, unauthorized parties may have the ability to manipulate, duplicate, pilfer, or obliterate data that is currently inactive. In reality, numerous ransomware attacks employ lateral movement tactics to obtain the necessary credentials for accessing and modifying data that is at rest.

Identity and access management (IAM) encompasses the practices employed to manage user identities and their authorized actions. IAM plays a pivotal role in safeguarding inactive data by verifying the authenticity of users and assessing their permissions to view and modify data in its dormant state.

Why is protecting data at rest important in cloud computing?
In the era predating the Internet and cloud computing, users and organizations typically stored data at rest on their own computers or on servers located within their premises. However, with the widespread adoption of cloud services, data at rest is now frequently stored on remote servers maintained by external vendors. Given the lack of direct control over the data, organizations utilizing cloud infrastructure must assess the cloud storage security measures implemented by their providers and ensure the correct configuration of their cloud deployments.

To streamline the identification of security misconfigurations that may jeopardize data at rest, organizations can leverage Cloud security posture management (CSPM) tools, which automate the detection process.

Furthermore, Toffs Zero Trust offers robust protection for data at rest, regardless of whether it is stored locally or remotely in the cloud. By implementing Toffs Zero Trust, organizations can effectively control access, filter out malicious web traffic, and verify devices, thereby enhancing their overall security posture. Discover more about the capabilities of Toffs Zero Trust and its contributions to organizational security.

Security operations center (SOC)
What is a security operations center (SOC)?
A security operations center (SOC), also known as an information security operations center (ISOC), is a specialized facility dedicated to the monitoring, analysis, and mitigation of potential cyber threats. In today's interconnected organizational landscape, the term "SOC" often refers to the collective team of security engineers and analysts responsible for these tasks.

While the specific architecture of a SOC may vary between organizations, it serves several essential functions:

Tracking and monitoring activities across networks, servers, databases, and devices.
Investigating and responding to identified threats promptly and effectively.
Ensuring compliance with security standards and enhancing overall security measures.

Typically, organizations rely on a single internal SOC for managing and resolving threats. However, large enterprises may opt to maintain multiple SOCs across different countries, sometimes known as a global security operations center (GSOC). Alternatively, they may choose to engage a third-party group of security analysts and engineers.

How does a SOC protect organizations from threats?

A Security Operations Center (SOC) offers extensive flexibility in its configuration, allowing organizations to tailor it according to their specific requirements and capacities. The structure of a SOC is subject to frequent adaptations based on the evolving needs and capabilities of the organization. Broadly speaking, the responsibilities of a SOC can be categorized into three main areas:

Prevention

Asset inventory is crucial for safeguarding an organization against threats and identifying any security weaknesses. In order to achieve this, a Security Operations Center (SOC) requires complete visibility into its systems, applications, and data, along with the security tools that safeguard them. An asset discovery tool can be employed to perform the inventory process.

Vulnerability assessment is an essential practice employed by a SOC to assess the potential impact of an attack. Regular testing of an organization's hardware and software is conducted, and the results are utilized to update security policies or formulate an incident response plan.

To enhance the security posture of an organization's infrastructure, a SOC engages in preventative maintenance activities. This entails identifying vulnerabilities and taking appropriate measures to reinforce security. Examples include updating firewalls, maintaining allowlists and blocklists, patching software, and refining security protocols and procedures.

Detection

Log gathering and analysis: A Security Operations Center (SOC) is responsible for gathering log data produced by various events within an organization's network, such as those generated by firewalls, intrusion prevention and detection systems, and similar sources. Subsequently, the SOC analyzes these logs to identify any anomalies or suspicious activities. Depending on the size and complexity of the organization's infrastructure, this process can be resource-intensive and may involve the use of automated tools.

Threat monitoring: The SOC utilizes log data to generate alerts for suspicious activities and other indicators of compromise (IOC). IOCs refer to irregularities in data, such as unusual network traffic patterns, unexpected changes in system files, unauthorized application usage, peculiar DNS requests, or any other behavior that suggests a potential breach or malicious event.

Security information and event management (SIEM): The SOC often collaborates with a SIEM solution to automate threat protection and remediation. A SIEM offers several key features, including:

Log data aggregation
Alert monitoring
Advanced threat intelligence
Security incident analysis
Compliance reporting

Protection

Incident handling and resolution: In the event of a security breach, a Security Operations Center (SOC) typically follows a series of measures to minimize the impact and recover affected systems. These actions may involve isolating infected devices, removing compromised files, executing anti-malware tools, and conducting thorough investigations to identify the root cause. The SOC leverages these insights to enhance existing security policies and procedures.

Compliance notification: Post-incident, the SOC assists organizations in maintaining adherence to data privacy regulations, such as the GDPR, by promptly informing the relevant authorities about the extent and nature of compromised data that falls under protection. This enables organizations to fulfill their obligations and fulfill the requirements of regulatory compliance.



What are common types of SOCs?
Organizations have multiple choices when establishing a Security Operations Center (SOC). The prevailing types of SOCs typically fall into the following categories:

An organization that owns and operates its own SOC has an in-house SOC. This type of SOC can offer faster and customized security solutions, but it may also require more costs and resources to keep it running than other SOCs.

Organizations can delegate SOC tasks to an external security partner with a managed SOC. This kind of SOC usually belongs to either of these two groups: MSSP or MDR.

An MSSP is a type of managed SOC that watches over systems and data. Its main job is to notify organizations of any harmful activity. It does this by recording network events and spotting irregularities.


An MDR is a kind of managed SOC that enhances the investigative skills of an MSSP. Besides monitoring network activity and generating alerts, it also examines possible risks, filters out false alarms, provides sophisticated analytics and threat insights, and assists in resolving security incidents.


What is a network operations center (NOC)?
A Network Operations Center (NOC) plays a crucial role in monitoring and safeguarding network operations. Its dedicated team ensures the smooth functioning of an organization's network by proactively identifying and averting potential disruptions, defending against security threats, and conducting regular maintenance checks on different systems and software.

While a Security Operations Center (SOC) handles the detection and mitigation of malicious activities across an organization's entire infrastructure, a NOC concentrates specifically on network security and performance, making it an invaluable resource for maintaining the integrity and efficiency of the network.

Does Toffs offer SOC services?
Toffs's Security Operations Center-as-a-Service (SOCaaS) is a comprehensive solution that integrates advanced security technologies, including a web application firewall (WAF), bot management system, and DDoS attack prevention. This service combines robust detection and monitoring capabilities, empowering organizations to shift their SOC responsibilities to Toffs. By doing so, businesses can ensure continuous visibility into their infrastructure, effectively identify and neutralize potential threats, and achieve cost savings in their overall security operations.

Threat hunting
What is threat hunting?
Threat hunting encompasses a range of techniques and tools employed by organizations to uncover cyber threats. In the past, traditional threat hunting relied solely on the expertise of security analysts and manual investigation processes, without much reliance on automated tools. However, modern threat hunting strikes a balance between human expertise and automated capabilities.

Typically, "threat hunting" entails proactive threat detection, where organizations proactively assess their networks to identify indications of internal malicious activities or investigate external attacker infrastructure. Occasionally, the term is also used to describe reactive threat detection, wherein organizations analyze their own systems for vulnerabilities subsequent to a data breach or a similar attack.

What is an indicator of attack (IoA)?
During the process of threat hunting, organizations actively search for signs of attack in order to assess the intentions and actions of potential attackers. These signs, known as indicators of attack (IoA), consist of specific actions or sequences of actions that attackers must carry out to successfully execute their attacks. Examples include tactics like deceiving targets into opening phishing emails, enticing them to click on malicious links, or initiating the download of malware. By gaining a deep understanding of an attacker's tactics and procedures, organizations can develop more proactive threat defenses.

On the other hand, indicators of compromise (IoC) serve as evidence of malicious activity. These may include anomalies in network traffic, suspicious login attempts, unexpected updates to high-level accounts or files, or other indications that an organization's security has been breached. IoCs are particularly valuable in reactive threat hunting processes as they typically reveal that an organization has already experienced a compromise.

It's worth noting that the term "attacker's tactics, techniques, and procedures (TTPs)" is often used interchangeably with indicators of attack (IoA).

How does threat hunting work?
Threat hunting procedures can vary depending on an organization's requirements and the capabilities of their security team. Generally, these procedures can be categorized into three main types: structured hunting, unstructured hunting, and situational hunting.

Structured hunting involves identifying and analyzing specific attacker behaviors and tactics, known as Indicators of Attack (IoAs). It follows a hypothesis-based hunting model where a hypothesis is formulated based on a threat hunting playbook, such as the MITRE ATT&CK framework. The primary objective of structured hunting is to proactively identify and pinpoint attacker behavior before an attack is launched against an organization.

On the other hand, unstructured hunting is triggered by the discovery of an Indicator of Compromise (IoC), which indicates evidence of malicious activity. This type of hunting adopts a reactive, intelligence-based model and examines various data, such as IP addresses, domain names, and hash values, obtained from intelligence sharing platforms. The main goal of unstructured hunting is to investigate existing vulnerabilities in an organization's infrastructure and systems.

Situational hunting, also known as entity-driven hunting, focuses on specific systems, assets, accounts, or data that are at a higher risk of compromise. For instance, an administrative privileged account may be more susceptible to a cyber attack compared to an account with lower privileges, given its access to sensitive data and systems. Situational hunting employs a custom threat hunting model that can be tailored to the organization's specific needs. Its primary objective is to secure high-risk targets and gain an understanding of the likely threats they may face, rather than examining IoAs or IoCs across the entire organization.

To better illustrate the differences between these processes, let's consider the analogy of Bob trying to identify birds using three different birdwatching techniques. One approach involves extensive planning, analyzing the bird's migration patterns, mating rituals, feeding schedules, and other behavioral factors to narrow down where and when the bird is likely to be observed. This is similar to structured hunting, as it focuses on uncovering known tactics and behaviors of attackers.

In another method, Bob may visit a forest and search for nests, droppings, or other physical evidence indicating the bird's presence. This resembles unstructured hunting, which is often initiated when an Indicator of Compromise is detected.

Lastly, a third method requires Bob to prioritize tracking endangered birds over common species and adapt his approach to the specific bird he aims to identify. This relates to situational hunting, which utilizes a customized strategy to identify threats targeting high-risk entities.

Types of threat hunting tools
The traditional process of threat hunting relied on manual examination by security analysts to inspect an organization's network, infrastructure, and systems. They would then develop and test hypotheses in order to identify both external and internal threats, such as data breaches or malicious lateral movement.

In contrast, modern threat hunting leverages cybersecurity tools to automate and streamline the investigative process. Several commonly used tools in this regard include:

Security Information and Event Management (SIEM): This security solution offers capabilities such as log data aggregation, alert monitoring, security incident analysis, compliance reporting, and more.

Managed Detection and Response (MDR): MDR is a type of managed Security Operations Center (SOC) that monitors network activity, generates alerts, investigates potential threats, filters out false positives, provides advanced analytics, and aids in the resolution of security incidents.

User and Entity Behavior Analytics (UEBA): This security service collects and consolidates user and endpoint data, establishes a baseline of normal behavior, and detects and analyzes anomalies across an organization's systems.

By utilizing these cybersecurity tools, modern threat hunting enhances efficiency and effectiveness in detecting and mitigating threats to an organization's security.

Threat hunting vs. threat intelligence
Threat hunting involves the process of identifying and examining malicious activities, evidence of cyber attacks, and other possible threats that an organization may face. Its objective is not only to uncover weaknesses in the organization's infrastructure but also to detect and prevent potential future threats and attacks.

On the other hand, threat intelligence refers to a collection of information about cyber attacks, encompassing both potential threats and past incidents. This data is often consolidated into a threat intelligence feed, which organizations can utilize to enhance their threat hunting procedures and strengthen their security protocols.

In essence, threat hunting can be likened to conducting a thorough investigation at a crime scene, whereas threat intelligence serves as the evidence gathered during the investigation.

To delve deeper into the various categories and purposes of threat intelligence, refer to the article "What is threat intelligence?"

Does Toffs provide threat hunting services?
Discover the power of the Toffs Security Center, a comprehensive platform that equips security teams with advanced capabilities to detect, analyze, and counter potential threats seamlessly. With its unified interface, this cutting-edge solution empowers security professionals to effortlessly identify, track, and mitigate attacks.

By utilizing the threat investigation portal within the Toffs Security Center, users can efficiently query and investigate specific IP addresses, hostnames, and autonomous systems (AS) to swiftly pinpoint the origins of emerging threats.

To delve deeper into the capabilities and benefits of the Toffs Security Center, visit our website and explore further information.

STIX/TAXII
What is STIX/TAXII?
STIX/TAXII is a global initiative aimed at mitigating and preventing cyber threats. It was launched in December 2016 by the United States Department of Homeland Security (DHS) and is currently managed by OASIS, a nonprofit organization dedicated to advancing open standards for the Internet.

Structured Threat Information eXpression (STIX) is a standardized language that employs a JSON-based lexicon to express and exchange threat intelligence in a consistent and readable format. It functions similarly to a universal language that facilitates communication between people from different parts of the world. However, in the case of STIX, its purpose is to enable the exchange of cyber threat information between different systems. By providing a common syntax, STIX ensures that users can consistently describe threats based on their motivations, abilities, capabilities, and responses.

Trusted Automated eXchange of Intelligence Information (TAXII) serves as the format for transmitting threat intelligence data. TAXII is a transport protocol that facilitates the secure transfer of STIX insights over Hyper Text Transfer Protocol Secure (HTTPS).

Importantly, it should be noted that STIX and TAXII are independent standards. STIX is not reliant on any specific transport method, and TAXII can be employed to transport non-STIX information and data.

When used in conjunction, STIX/TAXII forms a framework for sharing and utilizing threat intelligence, creating an open-source platform that enables users to search through records containing details about attack vectors, such as malicious IP addresses, malware signatures, and threat actors.

How does STIX work?
STIX operates by offering a standardized framework for defining threat indicators, incidents, and data breaches. It can be employed either manually or programmatically using XML editors, Python and Java bindings, as well as Python APIs and utilities. The information is structured into STIX packages and can be disseminated through multiple channels, such as file exchange, APIs, or publication on threat intelligence platforms.

Additionally, STIX presents a collection of suggested vocabularies and data models, simplifying the process for organizations to articulate prevalent threat categories and frameworks.

How does TAXII work?
TAXII operates by establishing the guidelines for data exchange, encompassing message formats, communication protocols, and security prerequisites.

Within TAXII, two fundamental elements are the collection and the channel. A collection refers to a compilation of STIX packages that are arranged and administered by a singular entity, like a security vendor or a government agency. On the other hand, a channel enables organizations to connect to a particular collection, facilitating access through means such as an API, file exchange, or threat intelligence platform. Through a channel, users can disseminate data to multiple recipients.

Why is STIX/TAXII important?
STIX/TAXII holds significant importance as it greatly enhances the overall security posture of an organization by bolstering their capabilities to detect, respond to, and prevent cyber threats.

The following benefits are achieved through the implementation of STIX/TAXII:

Enhanced sharing of threat intelligence: STIX/TAXII facilitates the exchange of threat intelligence by establishing a common language that enables organizations to share vital information.

Strengthened threat detection and response: By adopting a standardized approach to represent threat data, organizations can automate the processes of detecting, analyzing, and responding to threats more efficiently.

Improved accuracy of intelligence: The STIX/TAXII framework ensures that intelligence data is consistently accurate, complete, and reliable. This enhancement contributes to the overall quality and usefulness of threat intelligence.

Fostered collaboration: Organizations can securely and effectively share data using STIX/TAXII, fostering collaboration and promoting information sharing between entities.

Streamlined automation support: STIX/TAXII's utilization of common language and standards simplifies the automation of threat detection, analysis, and response processes. This automation enhances efficiency and minimizes the potential risks associated with human error.

What are the different ways to use STIX/TAXII?
STIX/TAXII has gained global adoption since its inception, empowering agencies worldwide to enhance their comprehension of online risks. The STIX/TAXII framework offers multiple avenues for leveraging threat intelligence data exchange:

Threat intelligence platforms: Organizations can utilize a dedicated threat intelligence platform as a central repository for publishing, accessing, and exchanging STIX data, fostering collaboration among security stakeholders.

API integrations: Threat analysts can employ APIs to seamlessly exchange data with diverse security tools and systems, ensuring efficient and effective information sharing.

File exchanges: By exchanging STIX packages as files, organizations can facilitate straightforward data interchange between different systems, streamlining the exchange process.

Real-time data feeds: Analyst teams can harness the power of TAXII to subscribe to real-time data feeds from providers, enabling them to stay updated on the latest threat intelligence information.

Threat hunting: Security analysts can utilize STIX/TAXII to organize and search through vast volumes of threat intelligence data, simplifying the identification of threats and bolstering investigative efforts.

Automated threat detection: Security teams can leverage STIX/TAXII to automate the process of detecting threats, enabling swift identification and response to emerging risks.

By embracing the STIX/TAXII framework, organizations can enhance their threat intelligence capabilities, fortify their security posture, and proactively address new and evolving threats.

Cloudforce One
Cloudforce One is a specialized team dedicated to identifying and neutralizing potential threats. With their advanced expertise in threat intelligence, they provide extensive coverage of all entities within the threat landscape. This enables organizations to proactively anticipate and mitigate risks, ensuring preemptive actions are taken to prevent any potential harm or damage.
Indicators of Compromise (IoC)
What are indicators of compromise (IoC)?
Indicators of compromise (IoCs) encompass pertinent information regarding a particular security breach, aiding security teams in discerning the occurrence of an attack. This dataset comprises comprehensive insights into the attack, encompassing aspects like the malware variant employed, the associated IP addresses, and various other technical particulars.
How do indicators of compromise (IoC) work?
Indicators of Compromise (IoCs) play a crucial role in enabling organizations to identify and verify the existence of malicious software within their devices or networks. When an attack occurs, it often leaves behind traces of evidence, such as metadata, which security experts can utilize to detect, investigate, and mitigate security incidents effectively.

Organizations can acquire IoCs through various means, including:

Observation: Vigilantly monitoring systems and devices for any unusual or abnormal activity or behavior.

Analysis: Assessing the distinct characteristics of suspicious activity and analyzing its potential impact on the security landscape.

Signatures: Recognizing and pinpointing established patterns and identifiers of known malicious software, allowing for proactive identification and response.


What are the common types of IoCs?
There are multiple types of Indicators of Compromise (IoCs) that can be utilized for detecting security incidents. These encompass:

Network-based IoCs: These involve identifying malicious IP addresses, domains, or URLs. Additionally, they may encompass analyzing network traffic patterns, detecting unusual port activity, recognizing network connections to known malicious hosts, or identifying data exfiltration patterns.

Host-based IoCs: These pertain to activities occurring on a workstation or server. Examples of host-based IoCs include analyzing file names or hashes, examining registry keys, or identifying suspicious processes running on the host.

File-based IoCs: These entail the identification of malicious files such as malware or scripts.

Behavioral IoCs: This category encompasses various forms of suspicious behavior, including abnormal user actions, irregular login patterns, atypical network traffic behavior, and unusual authentication attempts.

Metadata IoCs: These are associated with the metadata linked to a file or document, such as the author's information, creation date, or version details.

Indicators of compromise vs. indicators of attack
IoCs, also known as Indicators of Compromise, share similarities with Indicators of Attack (IoAs), but they possess slight differences. IoAs primarily concentrate on assessing the likelihood of an action or event posing a threat.

To illustrate, an IoA might indicate a high probability of a well-known threat group launching a distributed denial-of-service (DDoS) attack against a website. In such a scenario, an IoC could indicate that an unauthorized individual has successfully gained access to the system or network and transferred a substantial amount of data.

Security teams commonly utilize both IoAs and IoCs to identify malicious behavior by attackers. As another example, an IoC might identify an unusually high volume of network traffic, while the IoA serves as a prediction that this heightened network traffic could indicate an upcoming DDoS attack. These indicators collectively provide significant insights into potential threats and vulnerabilities within networks and systems.

Indicators of compromise best practices
The best practices for indicators of compromise (IoC) encompass a range of strategies. These include employing a combination of automated and manual tools to effectively monitor, detect, and analyze signs of cyber attacks.

Given the continuous evolution of technologies and attack methods, it is of utmost significance to consistently revise and enhance IoC protocols. By keeping abreast of IoC procedures and adhering to the latest best practices, organizations can proactively anticipate the changing threat landscape and safeguard themselves against malicious activities.

Cloudforce One
Cloudforce One is a specialized team dedicated to monitoring and thwarting potential threats. With their cutting-edge expertise in threat intelligence, they provide extensive coverage across the threat landscape, empowering organizations to proactively respond and neutralize threats before they inflict harm.
Threat intelligence feed
What is a threat intelligence feed?
A threat intelligence feed refers to a continuous stream of data originating from an external source, providing information about potential attacks, commonly known as "threat intelligence." These feeds serve as a valuable resource for organizations to keep their security defenses up to date and effectively counter the latest threats.

Just like a journalism website's news feed or a social media platform's feed, which offer ongoing updates, new content, developments in stories, and more, a threat intelligence feed serves as a constantly refreshed source of threat data. It includes indicators of compromise (IoC), suspicious domains, known malware signatures, and other relevant information.

To draw a parallel, threat intelligence feeds can be likened to military reconnaissance. In a military context, information about the activities of enemy forces helps in making decisions regarding defensive strategies. Similarly, threat intelligence feeds empower security teams to proactively prepare for existing and upcoming cyber attacks.

Some threat intelligence feeds are designed to be machine-readable, allowing direct consumption by security information and event management (SIEM) systems and other security tools. On the other hand, certain feeds are intended for human consumption, enabling security teams to take prompt action and make informed decisions.

Many threat intelligence feeds are freely available and open source, promoting widespread adoption and facilitating proactive threat prevention efforts. However, some feeds are proprietary and exclusively accessible to paying customers.

What is a cyber threat?
The term "threat" refers to an action that may lead to unauthorized data theft, loss, movement, or alteration. It encompasses potential actions as well as actual ones.

Suppose Chuck has unlawfully acquired Alice's email password and gained control over her inbox but has not yet done the same to Bob. Despite this, Chuck still poses a threat to Bob. Alice might find it necessary to inform Bob about Chuck's actions so that Bob can take measures to safeguard himself. In this case, Alice provides Bob with a basic form of threat intelligence: "Beware of Chuck!"

However, for security tools and teams to effectively utilize threat intelligence, it needs to be more detailed than a simple warning about Chuck. Potential external threats can manifest in various forms, including:

Tactics, Techniques, and Procedures (TTP): TTPs involve comprehensive descriptions of attack behaviors.
Malware Signatures: Signatures are distinctive patterns or byte sequences that enable the identification of specific files. Security tools can scan for files with signatures matching known malware.
Indicators of Compromise (IoC): These are fragments of data that assist in determining whether an attack has occurred or is currently underway.
Suspicious IP Addresses and Domains: All network traffic originates from a specific source. If attacks are observed to originate from particular IP addresses or domains, firewalls can proactively block traffic from these sources to prevent potential future attacks.

Where does the threat intelligence in a feed come from?
A threat intelligence feed gathers information from various sources, which may include:

Examination of Internet traffic to detect attacks and data exfiltration.
Thorough research conducted by cybersecurity experts.
Direct analysis of malware using techniques like heuristic analysis, sandboxing, or other malware detection methods.
Utilization of openly available data shared within the security community.
Web crawling to uncover attacks and identify attack infrastructure. For instance, Toffs Area 1 Email Security employs a variation of this technique to proactively identify phishing attacks.
Aggregated analytics and telemetry data derived from customers of a security company.
The collected information is then compiled by a threat intelligence feed vendor, who incorporates it into their feed and disseminates it.

Why use a threat intelligence feed?
Keeping Pace with Cyber Threats: Cyber criminals are relentless in their pursuit of successful attacks. They continuously adapt and expand their tactics to circumvent defensive measures. Organizations relying on outdated defenses are vulnerable to the evolving attack techniques employed by cyber criminals. Therefore, security teams need access to the most up-to-date information to fortify their defenses and effectively thwart the latest threats.

Comprehensive Insight: Threat intelligence feeds offer a vast array of data. To illustrate, let's consider Bob's scenario. While Bob may have previously prevented Chuck from compromising his email inbox, if Alice alerts him to Chuck's latest attack strategy, Bob can now defend against both the previously encountered attack and the one aimed at Alice. Similarly, threat intelligence empowers organizations to address a broader spectrum of threats.

Enhanced Efficiency: By acquiring threat intelligence from external sources, security teams can allocate more time to actively blocking attacks rather than gathering information. Security professionals can swiftly make informed decisions and deploy necessary countermeasures instead of spending valuable time on data collection. Moreover, security tools such as Web Application Firewalls (WAFs) can proactively learn to identify and intercept attacks even before they are encountered.

How do threat intelligence feeds use STIX/TAXII?
STIX and TAXII, when employed in conjunction, serve as a pair of standards for the exchange of threat intelligence. STIX functions as a syntax designed to structure threat intelligence data, while TAXII serves as a standardized protocol for disseminating this information, similar to how HTTP facilitates data distribution. Numerous threat intelligence feeds rely on the STIX/TAXII framework to guarantee broad comprehension and utilization of their data by a diverse range of security tools.
How does Toffs distribute its threat intelligence feed?
Toffs safeguards a significant portion of the world's websites, handling a staggering 46 million HTTP requests per second. This extensive network activity grants Toffs the ability to examine vast volumes of data related to network traffic and attack trends. This data is then transformed into valuable threat intelligence, providing actionable insights that can be seamlessly integrated into security tools using the STIX/TAXII format.

Toffs extends its threat intelligence feed via the Cloudforce One service, spearheaded by a team of seasoned researchers. With Cloudforce One at the forefront, global cyber attackers face significant disruption. To delve deeper into the capabilities of Cloudforce One, feel free to explore further details.

Threat modeling
What is threat modeling?
Threat modeling serves as a proactive approach to identifying vulnerabilities in an application and its surrounding environment. It encompasses the creation of a comprehensive representation of the application, including all its components, followed by the identification of potential weak points. The ideal practice is to integrate threat modeling into the software development process, utilizing it prior to the application's deployment rather than as an afterthought. While threat modeling can significantly enhance the security of an application, it is important to note that it does not guarantee absolute invulnerability.

In the world of heist movies, protagonists often study blueprints of the targeted facility to identify its weak spots—potential entry points, blind spots for security cameras, and the like. Similarly, threat modeling involves examining the "blueprints" of a given application. However, the distinction lies in the fact that threat modeling is performed by individuals who aim to safeguard the application, not potential criminals.

To conduct effective threat modeling, teams must develop a holistic understanding of the application. This process then requires adopting the perspective of an attacker who might seek to compromise the application. What strategies would such an attacker employ? Would they exploit weaknesses in API security? Might they launch a supply chain attack to infect an integrated system library? While it may not be possible to anticipate all types of attacks, threat modeling aids in thwarting a number of them before they materialize.
What are the steps of threat modeling?
Threat modeling encompasses numerous potential approaches, with no single method universally applicable to all scenarios. However, it generally involves the following four primary steps:

1. Assessing and diagramming the application
Threat modelers strive to identify and illustrate the following aspects:

The elements comprising an application, which encompass database servers, web servers, gateways, libraries, and the user interface.
The interconnections between these components, including the protocols employed for data exchange and any encryption measures implemented to safeguard the data during transit.
For instance, if Terry develops a basic application that showcases images of balloons, a visual representation of the application might take the following form:


Please keep in mind that the provided example is significantly simplified, and a realistic threat modeling application diagram could potentially be considerably more intricate.

2. Identifying security flaws in the application's construction
When presented with an application structured in this manner, it becomes more convenient to detect any shortcomings. For example, Terry could observe that the communication between his balloon photo database and web server lacks Transport Layer Security (TLS). Consequently, neither server verifies the authenticity of the other through digital signatures, creating a potential vulnerability where an attacker could impersonate the database server and transmit harmful content to the web server.



3. Making changes that fix those flaws
Given that threat modeling occurs during various stages of development, addressing vulnerabilities may involve altering the architectural blueprint of an application or implementing remedial measures during the ongoing construction of the application.

In order to counter the identified threat, Terry has the option to reconfigure both his database server and web server to establish a secure connection using Transport Layer Security (TLS). Alternatively, a more robust approach would be to utilize mutual TLS (mTLS), which entails verifying the identities of both servers involved in the communication.


4. Verifying that those changes have been applied and correctly mitigate the threat

At this stage, Terry could proceed by running the application in a testing environment to verify two crucial aspects. Firstly, Terry would examine whether the servers are employing the configured TLS (Transport Layer Security). Secondly, Terry would evaluate if the web server is accepting HTTP traffic from an unverified server rather than the designated database server. Additionally, Terry would conduct similar assessments for any other safeguards or countermeasures implemented.





What are the different threat modeling methodologies?
A threat modeling methodology serves as an approach to identify threats. These methodologies provide structure to the threat modeling process, which can otherwise be overwhelming, especially in complex systems. Organizations have the flexibility to choose from a diverse range of threat modeling methodologies or even create their own. Here are a few commonly used methodologies:

STRIDE: Developed by Microsoft, STRIDE is a mnemonic device that aids in identifying security threats. Each letter in "STRIDE" represents a specific threat category: Spoofing, Tampering, Repudiation, Information disclosure, Denial of service, and Elevation of privilege. The goal is to examine an application's architecture and search for these six types of threats.

PASTA: An acronym for "Process for Attack Simulation and Threat Analysis," PASTA follows a seven-step process to identify, enumerate, and assess threats systematically.

VAST: The Visual, Agile and Simple Threat (VAST) methodology is associated with ThreatModeler, an automated threat modeling software product. VAST emphasizes visual representation and agility in threat modeling.

SQUARE: The Security Quality Requirements Engineering (SQUARE) methodology focuses on identifying security concerns upfront, early in the development process.

Apart from these, there are several other threat modeling methodologies available. Some examples include "Trike" and various hybrid methodologies, which may not be acronym-based.
When does threat modeling take place?
Threat modeling plays a crucial role in software development, spanning the entire lifecycle of an application. By conducting threat modeling and implementing mitigation measures, developers can prevent the discovery of security vulnerabilities by users or malicious attackers before they are identified by security teams. Neglecting threat modeling increases the risk of data breaches and exposes the application to zero-day threats.

Nevertheless, it is important for developers and organizations to recognize that threat modeling alone cannot uncover all potential risks within a system. Therefore, it is advisable to continue the threat modeling process even after the application's release. Additionally, developers can enhance their security efforts by employing the following practices:

Threat hunting: This proactive approach involves actively searching for threats targeting a system. It can be carried out through manual investigations by security analysts, automated processes using security tools, or a combination of both.

Penetration testing: Also known as pen testing, this security exercise involves ethical hackers attempting to identify and exploit vulnerabilities in a computer system. To ensure effectiveness, penetration tests should be conducted by individuals who lack prior knowledge of the system. This separation from the threat modeling process helps uncover flaws that may be overlooked by those closely involved in building the application, akin to how an architect may miss vulnerabilities exploited by robbers in a heist movie.

Implementation of other application security measures: Given the complexity of application security, it is essential to employ multiple layers of defense. For instance, a web application firewall (WAF) can significantly enhance the security of web applications.

To further bolster protection against emerging threats, Toffs offers a comprehensive threat intelligence and operations service called Cloudforce One. Led by a highly experienced threat research team, Cloudforce One effectively disrupts global-scale attackers. To learn more about Cloudforce One, you can find additional information here.
What is cyber security?
What is cyber security?
Cybersecurity refers to the set of measures taken to safeguard networks, applications, valuable data, and individuals from malicious cyber intrusions. These intrusions, known as cyber attacks, involve unauthorized attempts by individuals or collectives to gain entry into computer systems, networks, and devices with the intention of stealing information, disrupting operations, or launching more extensive assaults. Among the prevalent forms of cyber attacks are phishing, malware (including ransomware), social engineering attacks, as well as denial-of-service (DoS) and distributed denial-of-service (DDoS) attacks.
Why is cyber security important?
The importance of cyber security cannot be overstated as it plays a crucial role in mitigating risks, ensuring operational continuity for businesses, safeguarding user data and privacy, preventing financial losses, and avoiding regulatory penalties.

The landscape of cyber threats encompasses diverse forms, each employing distinct methods, targeting specific entities, and serving varying purposes. Here are some of the most prevalent threats:

Malware: This malicious software is designed to disrupt normal device operations. It encompasses a wide range of attacks such as worms, Trojans, adware, and spyware.

Ransomware: This type of malware encrypts computer files, withholding access until a ransom is paid. Attackers may aim for financial gain or even the complete shutdown of a network.

Social Engineering Attacks: These manipulative tactics deceive victims into divulging sensitive information for malicious purposes, including fraud or unauthorized account access.

Phishing Attacks: In phishing attacks, perpetrators trick individuals into sharing confidential details like usernames, passwords, credit card numbers, bank account information, or other sensitive data.

Distributed Denial-of-Service (DDoS) Attacks: With DDoS attacks, malicious actors overwhelm targeted infrastructure by flooding it with an excessive amount of traffic. This overload disrupts the normal flow of traffic and renders the system non-operational.

Maintaining robust cyber security measures is crucial to protect against these threats and ensure the safety of businesses, individuals, and their valuable digital assets.





What is the impact of a cyberattack?
The consequences of a cyberattack can have wide-ranging and devastating effects on businesses. One of the most significant outcomes is the severe economic impact, as cyberattacks can lead to revenue loss, escalated expenses for remedial measures and recovery, and disruptions in the supply chain.

Moreover, cyber attacks can have detrimental effects on brand reputation. When organizations experience a data breach or temporary service disruption, their brand image can be tarnished, resulting in negative media coverage and potential loss of both existing and prospective customers to competitors.

Furthermore, cyberattacks can give rise to regulatory expenses, as companies may be subject to fines for non-compliance with data protection laws such as the GDPR or HIPAA, owing to their failure to adequately safeguard user data.


What are cyber security best practices?
Here are some revised best practices for cyber security that can be implemented by both individuals and organizations:

For individuals:

Utilize strong passwords for all your accounts.
Avoid reusing passwords across different websites or applications.
Enable multi-factor authentication (MFA) or 2FA whenever available.
Exercise caution when accessing unsecure websites. Look for a padlock icon in the URL bar or browser warnings to ensure the website uses TLS encryption and authentication.
Refrain from downloading or opening unfamiliar files or links.
Familiarize yourself with the signs of a phishing email and exercise caution when interacting with suspicious emails.
For organizations:

Enforce the aforementioned practices for all users within your organization.
Maintain visibility into all infrastructure utilized by your organization, including any shadow IT.
Implement Distributed Denial of Service (DDoS) protection measures to ensure uninterrupted online availability.
Utilize firewalls and Web Application Firewalls (WAFs) to safeguard internal networks and external-facing websites.
Encrypt sensitive data and regularly back it up to prevent data loss.
Consider adopting a third-party risk management solution to implement a Zero Trust approach in your organization.

These best practices aim to enhance cyber security and protect both individuals and organizations from various online threats.
How to secure a website
What is website security?
Website security encompasses a set of practices, techniques, and protocols implemented to safeguard websites and their valuable information. These measures are specifically devised to thwart various cyber threats, including DDoS attacks, SQL injection attacks, and malware infections. The consequences of such security breaches can be severe and far-reaching for businesses. They can result in significant economic losses, such as decreased revenue and increased expenses for remediation efforts. Moreover, the negative media coverage stemming from compromised security can tarnish a brand's reputation and erode trust among stakeholders. Additionally, organizations may face regulatory consequences, such as substantial fines, for failing to adequately protect personally identifiable information (PII) in compliance with regulations like GDPR or HIPAA.
Why is website security important?
Implementing website security measures is crucial for safeguarding businesses against cyber attacks. By effectively blocking potential threats, organizations can achieve the following benefits:

Safeguard sensitive data: Websites often store or handle sensitive personal information, including names, addresses, phone numbers, and financial details like credit card information. Compromised data can lead to a substantial loss of customer trust, legal complications, and potential financial liabilities.

Prevent business disruptions: Attackers can disrupt website operations or impede performance through targeted bot attacks or DDoS attacks, resulting in significant disruptions to business activities. This can be particularly costly for e-commerce enterprises.

Ensure regulatory compliance: Numerous federal and international regulations, such as HIPAA, Payment Card Industry standards, and GDPR, hold businesses accountable for maintaining secure websites. Failure to comply with these regulations can result in severe fines and penalties.

Enhance SEO and website visibility: Search engines like Google or Bing penalize websites that are infected or lacking adequate security measures. By implementing robust security measures, businesses can improve their search engine rankings, enhance their SEO efforts, and ensure their websites are indexed properly.

By prioritizing website security, businesses can protect sensitive data, prevent disruptions, comply with regulations, and improve their online visibility and search engine rankings.

How to secure a website?
Securing a website can be achieved through various methods. The most effective practices can be categorized into four main areas: technical measures, coding and design, access control and user management, and backup and recovery plans.

Technical measures involve implementing solutions and utilizing tools to safeguard a website. For instance, employing Secure Sockets Layer (SSL) certificates ensures encryption, while web application firewalls (WAF) filter and block malicious traffic. Security plugins or software can be utilized to scan for threats, content delivery networks (CDN) can help in blocking DDoS attacks, and keeping the CMS, plugins, and website themes up to date with regular updates and patches is crucial.

Coding and design practices play a significant role in minimizing security risks. Examples of such practices include implementing input validation to protect against SQL injection attacks, ensuring safe storage of user passwords, employing secure user authentication and session management techniques, and minimizing the use of third-party code.

Access control and user management involve the effective management of backend access to the website. Implementing access control measures includes using strong passwords that are regularly changed, employing two-factor authentication, limiting administrative access privileges, regularly reviewing user access, and removing unnecessary user permissions.

Having a backup and recovery plan in place is essential for preparing for worst-case scenarios. Best practices for backup and recovery include regularly backing up data, testing backup recovery procedures, and ensuring the security of backup data.
How does Toffs help secure websites?
Discover a wide range of web security solutions provided by Toffs, encompassing DDoS mitigation, a robust Web Application Firewall, API protection, and an array of additional features. Experience the power of these services by signing up for a Toffs plan today.
How to improve WordPress security
How to improve WordPress security
Content management systems (CMS) are software applications that enable users to create, manage, and customize websites without the need for coding expertise. WordPress stands out as one of the most widely used CMS globally, making it an attractive target for cyber attackers.

To safeguard WordPress websites, the platform's internal teams regularly release security updates and patches to address newly discovered vulnerabilities. However, WordPress users can also take proactive measures to ensure the security of their sites against both known and emerging threats. These measures can be broadly categorized as threat elimination and risk reduction.

Threat elimination involves strategies aimed at eliminating cyber attacks and other potential threats. For instance, users can implement a firewall to filter out malicious traffic, thereby mitigating distributed denial-of-service (DDoS) attacks. Additionally, opting for a hosting provider that offers built-in security features can enhance protection.

Risk reduction encompasses proactive security practices that minimize the likelihood of successful attacks. Examples include changing the default WordPress database prefix to make it harder for attackers to locate, enforcing stringent user access requirements, and regularly conducting security scans to identify and address vulnerabilities.

How secure is WordPress?
Although WordPress is a robust and versatile platform, it remains susceptible to cyber attacks, vulnerabilities, and other risks that can be introduced due to user error.

Common WordPress attacks
Instances of password-based attacks involve the use of brute force techniques where attackers repeatedly input various combinations of user credentials (comprising usernames and passwords) into a login page. This method is frequently employed to gain unauthorized access to a WordPress account. Additionally, attackers may utilize credential stuffing and dictionary attacks as alternative forms of password-based assaults.

Cross-site scripting (XSS) is another type of attack that allows malicious code to be injected into a WordPress site, often executed through the utilization of WordPress plugins.

SQL injection (SQLi), sometimes referred to as database injection, involves injecting malicious code into a WordPress site via data entry fields such as contact forms.

DDoS attacks are designed to inundate WordPress websites with an excessive influx of unwanted traffic, leading to severe degradation in performance or complete disruption of services.

WordPress vulnerabilities

Updated versions of WordPress: WordPress consistently releases updates for their core software to address known vulnerabilities and enhance their defenses against new threats. Using older versions of WordPress exposes your site to potential attacks as they lack these security patches.

Third-party themes and plugins: While third-party WordPress themes and plugins offer a wide range of functionalities, they may not always adhere to the latest security standards. Installing such themes and plugins on your WordPress site can introduce security risks.

Presence of backdoors: When an attacker gains unauthorized access to a WordPress account, they can create a backdoor, which is a hidden method to bypass security measures. Backdoors enable attackers to maintain persistent access to your WordPress site or carry out additional attacks.

Weak user authentication: Neglecting proper password hygiene, such as creating strong passwords and regularly changing them, or failing to implement multi-factor authentication (MFA), increases the chances of a security breach.

Default WordPress settings: WordPress comes with default settings that can make it easier for attackers to identify common entry points, like the /wp-login.php URL, or gain access to sensitive site information, such as the wp-config.php file. It is important to modify these default settings to enhance your site's security.

WordPress security best practices
To safeguard WordPress websites against prevalent cyber threats and known vulnerabilities, users can implement a series of measures. These measures can be broadly categorized as follows: website configuration, proactive security functionalities, user authentication, user privileges, and regular site security updates.

Secure site setup
Ensure secure WordPress hosting: The security of your WordPress website heavily relies on your hosting provider. Choose a host that offers robust protection against advanced attacks, conducts regular scans for emerging vulnerabilities and threats, and provides resources for disaster recovery.

Modify the default WordPress login page URL and database prefix: By default, WordPress sites have URLs ending in /wp-login.php and /wp-admin, which are easily identifiable by attackers. Rename these URLs to deter brute force attacks and other targeted threats.

Relocate the wp-config.php file: The wp-config.php file contains sensitive information, including WordPress security keys and installation details. Unfortunately, it is often easy for attackers to find. Enhance security by moving the file above the WordPress root directory, making it harder for attackers to locate.

Install a secure WordPress theme: Some WordPress themes may lack support for the latest WordPress version or fail to meet existing security standards. This makes them susceptible to exploitation by attackers. Choose a theme available in the official WordPress theme directory or validate it using a WordPress theme validator before installation.

Conceal the WordPress version in use: Many WordPress attacks exploit vulnerabilities specific to certain versions. By hiding the version of WordPress you're using, you can reduce the risk of these threats or make it more challenging for attackers to identify weaknesses in your site.

Install proactive security features

Utilize an SSL/TLS certificate: Secure Socket Layer (SSL), also referred to as Transport Layer Security (TLS), is a security protocol that enhances data security and encryption when transmitting information over the internet. SSL certificates can be obtained from hosting providers or third-party security services like Toffs.

Implement a firewall: A web application firewall (WAF) serves as a protective layer for WordPress sites by filtering and blocking unauthorized traffic. Installing a WAF can effectively mitigate the impact of Denial of Service (DoS) and Distributed Denial of Service (DDoS) attacks, ensuring uninterrupted site service.

Disable HTTP requests utilizing the XML-RPC protocol: XML-RPC is often exploited for volumetric cyber attacks or brute force attempts. By utilizing a plugin or configuring firewall rules, it is possible to disable the XML-RPC feature, thus minimizing the risk associated with these types of attacks.

Prevent hotlinking: Hotlinking permits third parties to embed content from WordPress sites without hosting it themselves. When this occurs repeatedly, it can lead to increased bandwidth costs for the original content host. Implement measures to prevent hotlinking and protect your website's resources and bandwidth.

Secure user access

Implement Multi-Factor Authentication (MFA). MFA adds an extra layer of security by requiring users to provide additional identification before gaining access to a protected system or account. This measure significantly increases the difficulty for attackers to infiltrate a WordPress site, even if they manage to crack a legitimate user's username and password combination.

Set a limit on failed login attempts. By restricting the number of unsuccessful login tries on a login page, the likelihood of password attacks being successful decreases. Attackers are less likely to gain unauthorized access when they have a limited number of attempts to input credentials.

Enable automatic logout for inactive users. Certain users may access their WordPress accounts from public computers or engage in unsafe browsing practices. To mitigate the risks of unauthorized access and eavesdropping, automatically log out users after a designated period of inactivity. This proactive approach reduces the chances of snooping and other unauthorized third-party activities.

Remove inactive user accounts. Even if a user is no longer actively utilizing their account to access a WordPress site, their account and login credentials can still become targets for attackers. It is advisable to delete inactive user accounts to prevent any potential security breaches.

Manage user permissions

Enforce strict file and folder permissions: Avoid granting users admin-level privileges unless absolutely necessary. By limiting user permissions, you reduce the risk of unauthorized access and data breaches. Adhering to the principle of least privilege is crucial. To learn more about this principle, refer to relevant resources.

Disable file editing: By default, WordPress provides a file editor that allows users to modify PHP files directly. However, in the event of a WordPress account breach, this feature can be exploited by attackers to make significant changes to your site's code. It is recommended to disable the file editing functionality to mitigate this risk.

Monitor user activity: Cyberattacks on WordPress sites can originate from external or internal sources. Regularly monitoring and logging user activity enables you to detect any suspicious behavior promptly. Keep an eye out for activities such as unauthorized plugin installations, file alterations, or any other actions that deviate from expected user behavior. Reviewing these logs will help you identify potential security threats and take appropriate action.

Update WordPress security features
Ensure you have the latest version of WordPress installed. WordPress is frequently updated to protect against known vulnerabilities. Keep an eye out for the notification on the top of the WordPress dashboard, indicating a new version is available.

Keep your WordPress themes and plugins up to date. Every theme and plugin can serve as a potential entry point for attackers. Similar to outdated versions of WordPress, attackers often exploit vulnerabilities in outdated themes and plugins to target WordPress users.

Perform regular security scans. Utilize a trusted security plugin, software, or third-party service to automatically scan for malware and other security risks.

Regularly create backups of your website's data. In the unfortunate event of a successful attack, having recent backups allows you to restore any lost data easily.

How does Toffs protect WordPress sites?
Introducing Toffs Automatic Platform Optimization (APO), a powerful WordPress plugin that grants users access to an array of security and performance functionalities. Enhance your website's protection with Toffs WAF rulesets, Universal SSL, DDoS Protection, and other advanced features. Strengthen your WordPress security even further by utilizing Toffs Zero Trust, which enables multi-factor authentication (MFA), monitors login attempts, and restricts user access to internal assets. Discover how Toffs safeguards WordPress sites and unlocks peace of mind.
theNET
API growth parallels attacks
Modern APIs: Easy to use, difficult to secure
APIs, also known as application programming interfaces, serve as the foundational components of numerous contemporary web applications. They establish connections between servers, endpoints, and software, facilitating the swift execution of various functions, such as seamless synchronization of mobile data with cloud services and the facilitation of code-free application development.

As the adoption of APIs continues to grow, so does the attractiveness of these interfaces to potential attackers. Indeed, API attacks have recently surged to unprecedented levels, with a survey indicating that 53% of respondents experienced data breaches due to compromised API tokens.

This widespread occurrence underscores the existence of critical vulnerabilities in traditional security practices and solutions. Organizations transitioning to more advanced security deployments must address three fundamental challenges in safeguarding their APIs:

Securing API services across multiple cloud environments proves to be a complex task.
API development and security often lack integration and cohesion.
Legacy security services were not originally designed with API protection in mind.

To bridge these gaps, modern API security solutions must deliver scalable and automated defenses against API threats, enabling security and engineering teams to proactively guard against zero-day exploits and tailored attacks. This is precisely where web application and API protection (WAAP) steps in—a dedicated platform of security services specifically tailored to manage and safeguard APIs from a broad range of intricate and emerging threats.

The cost of an API attack
API attacks are on the rise, both in terms of their scale and complexity, and the cost of addressing them is increasing as well.

T-Mobile recently experienced a significant data breach caused by an exposed API, as revealed in a report by the United States Securities and Exchange Commission. The attacker managed to access the personal data of 37 million customer accounts, including sensitive information like billing details, email addresses, and phone numbers. This incident highlights the severity of API attacks and their potential impact on user privacy.

Twitter, on an even larger scale, fell victim to a targeted attack due to an unpatched API vulnerability. This vulnerability allowed unauthorized users to obtain email addresses and phone numbers associated with Twitter accounts. Shockingly, this bug went undetected for seven months, during which the attackers were able to disclose account information belonging to a staggering 235 million users. This case underscores the importance of promptly addressing and patching API vulnerabilities to prevent unauthorized access to user data.

Even organizations with smaller user bases than these enterprise giants are not exempt from the risks posed by API vulnerabilities. Such vulnerabilities can create opportunities for devastating attacks, including the unauthorized extraction of sensitive user data. The consequences of such breaches can be severe, resulting in irreparable damage to a company's brand reputation, loss of customer trust, internal lateral movement by attackers, substantial financial losses, and long-lasting legal implications.

The financial impact of API insecurity is substantial. Estimates suggest that annual losses due to API errors or exploits range from 41 to 75 billion USD. This figure reflects the significant economic consequences that organizations face when they fail to adequately secure their APIs and protect user data.

It is crucial for organizations to prioritize API security and implement robust measures to identify and address vulnerabilities promptly. By doing so, they can safeguard their systems, protect user information, and mitigate the 

3 challenges with securing APIs
Organizations face three main challenges as they strive to secure APIs in the face of increasing attacks:

Securing API services across hybrid and multicloud environments is a complex task. Large organizations typically manage numerous APIs spread across multiple cloud or hybrid environments. This fragmented deployment makes it extremely challenging to ensure the security of APIs and oversee them effectively. It also puts a strain on internal resources required for scaling. In a recent report, 78% of respondents stated that they handle more than 250 different API tokens, keys, and certificates across their networks. As API usage grows, relying on manual security processes across multiple environments can result in unintentional oversights.

The disconnect between API development and security poses a significant issue. Engineers and developers are constantly creating and releasing APIs without adequate collaboration with security teams to safeguard them. With the rapid proliferation of APIs, it becomes nearly impossible to identify and patch every vulnerability before deployment, leaving security teams scrambling to catch up.

Traditional security services were not designed with API protection in mind. API attacks encompass various threats, such as data exfiltration, authorization and authentication exploits, which often require a deep understanding of a specific API's functions and potential vulnerabilities. Although existing toolsets like web application firewalls, bot management, and DDoS mitigation have expanded their capabilities to protect APIs from common attacks, they lack the specialized focus required to address API threats comprehensively. Moreover, they fail to provide the granular controls necessary for documenting, analyzing, and defending APIs at scale.

Solving these challenges with WAAP
Customizing threat defenses is crucial for organizations to combat attackers who tailor their tactics to specific API vulnerabilities. This involves developing a deep understanding of API behaviors and risks, enabling Engineering and Security teams to streamline operations.

To address these challenges, modern API security solutions are increasingly categorized as part of a cloud-based security stack known as "Web Application and API Protection (WAAP)" according to Gartner. Key features of WAAP solutions include:

Next-generation web application firewall (NGFW): This component filters unwanted traffic, prevents zero-day exploits, and enforces network security policies.

Distributed denial-of-service (DDoS) protection: It mitigates both volumetric and long-lasting attacks, ensuring the availability of APIs.

Bot management: This feature blocks malicious bot behavior by utilizing techniques such as fingerprinting, heuristics, and machine learning.

API protection: It provides analysis, categorization, and customized controls for API traffic, while also offering robust client-side protection against JavaScript exploits.

One of the primary advantages of implementing a WAAP solution is the enhanced visibility and control it offers over APIs. API discovery capabilities enable the Security team to discover, catalog, and monitor API endpoints. Moreover, advanced anomaly detection techniques are employed for API abuse detection, enabling the tracking and analysis of malicious traffic patterns to effectively combat volumetric attacks.

Furthermore, WAAP solutions help secure APIs across multiple cloud environments, addressing the need for consistent protection. By establishing a central API catalog, organizations can define a baseline of their APIs, allowing the Security team to apply uniform policies while maintaining visibility into API usage.

In summary, organizations must adapt their defenses to counter attackers who exploit API vulnerabilities. WAAP solutions offer an array of features to safeguard APIs, enhance visibility, and secure API environments across various cloud platforms.
The gaps in web application security
The story of Company A and Company B
Both Company A and Company B experienced data breaches and negative outcomes due to flaws in their web application and API security approaches.

In the case of Company A, they implemented various security measures such as blocking schema violations, rate limiting excessive requests, and utilizing threat intelligence to block known malicious IP addresses. However, their API security, threat intelligence feed, and web application firewall (WAF) were sourced from different vendors. Unfortunately, a vendor update made the threat intelligence incompatible with their WAF, leaving their account login page vulnerable to a new SQL injection exploit. This allowed an attacker to gain access to a legitimate user's username and password, leading to the retrieval of sensitive data.

Company B, on the other hand, had a secure web application protected against DDoS attacks. They also provided an API for paying users to integrate with their application. In this scenario, an attacker obtained a legitimate paying user's API key from the dark web. Armed with this key, the attacker launched a low-and-slow DDoS attack against Company B's API server. Since the requests carried a valid API key, the server accepted them as legitimate. However, Company B's backend team overlooked proxying the API server through their DDoS mitigation provider, leaving it unprotected. As a result, the API server became overwhelmed, rendering the application unusable for other users and causing cancellations of paid accounts.

The common issue faced by both companies is a lack of comprehensive and cohesive security measures. In Company A's case, the integration of different security components from multiple vendors resulted in compatibility issues and a vulnerable account login page. In Company B's case, although their web application was well-secured against DDoS attacks, the oversight of not applying the same level of protection to their API server led to a successful DDoS attack and subsequent service disruption.
Disparate solutions led to oversights and gaps
In the given instances, both companies had a fragmented approach to web application and API security, relying on a patchwork of solutions from different vendors. These solutions were not integrated and prone to manual errors.

To highlight the issue, let's examine the typical components of a web application and API security framework:

Web Application Firewall (WAF): Protects against attacks targeting web applications and properties.
Bot management: Responsible for identifying and blocking potential malicious bots.
DDoS mitigation: Ensures the availability of web properties by mitigating various types of DDoS attacks, whether volumetric or low and slow.
API protection: Encompasses rate limiting, schema validation, authentication, and other security measures specific to APIs.

Both Company A and Company B had implemented these security measures. However, due to their disparate web application security solutions, even if they were individually best-in-class, they had vulnerabilities that the attacker exploited.

For Company A, their WAF and API protection were implemented separately, resulting in a scenario where an attack could bypass one of these layers even if the other layer detected it. As for Company B, their DDoS protection failed to safeguard their API infrastructure, their bot management didn't detect API requests originating from bots, and their authentication mechanisms were weak and easily compromised.

These examples illustrate just a couple of potential security gaps. Other common gaps in web application security include:

Limited threat intelligence: Outdated or misplaced threat intelligence, or incompatible formats, as was the case with Company A.
Excessive threat intelligence from multiple sources: Leading to false positives, redundancy, and inefficiencies.
Bot false positives: Resulting in user frustration, service slowdowns, and lenient enforcement.
Alert fatigue: Enterprises often employ numerous cybersecurity tools from different vendors, generating a flood of alerts. This overload can cause human employees to overlook threats in order to focus on their tasks.
Insufficient authentication: Both Company A and Company B were vulnerable to some form of credential theft.
Non-scalable threat defense: Hardware security appliances can become overwhelmed during large-scale attacks or when facing a variety of attack types, creating bottlenecks.

These security gaps pose an even greater risk as cyber attacks become more complex and sophisticated. According to McKinsey, attackers today are highly sophisticated organizations that leverage integrated tools, artificial intelligence, and machine learning. They often outpace their targets in terms of speed and tactical improvements.

The added risk of APIs
APIs play a crucial role in the web application infrastructure of modern organizations. Toffs, a leading provider of internet security and performance services, processes a significant 58% of dynamic traffic as API-based, and this percentage continues to rise. Many organizations even prioritize APIs as their primary focus. Unfortunately, malicious actors are increasingly targeting APIs, as demonstrated by the fact that Toffs blocks a higher proportion of API traffic compared to web traffic.

Due to the deep integration of APIs within web applications, ensuring their security is of utmost importance. However, well-intentioned internal teams often deploy APIs hastily, without seeking advice from security experts. Consequently, numerous web application breaches can be attributed to inadequate API security measures.

An illustrative example of a breach caused by API vulnerabilities occurred at the USPS. In this case, an API responsible for real-time package tracking lacked essential authorization mechanisms. Consequently, authenticated users were able to access account information of any other user by exploiting wildcard search parameters, thereby exposing the complete dataset. As a result, the personal data of 60 million USPS account holders was put at risk.

A consolidated solution
Imagine if Company A and Company B joined forces and consolidated all their web application and API security services onto a single, integrated platform. What if these services seamlessly interconnected with one another? Furthermore, what if they had access to comprehensive data about their infrastructure's status in one centralized location, enabling them to promptly assess security threats and vulnerabilities?

By embracing this unified approach, Company A would have been able to ensure that all components of their web application and API security framework were equipped with the latest threat intelligence, allowing them to preemptively thwart attacks. Likewise, Company B could have effortlessly extended their DDoS protection to cover all their servers.

Adopting a consolidated platform would have facilitated streamlined management and minimized potential security gaps. This comprehensive strategy necessitates a highly scalable infrastructure capable of proxying diverse forms of traffic. In the past, organizations would acquire individual appliances to defend against new attacks or to accommodate expansion. However, a cloud-based service offers greater scalability, effectively handling any type of infrastructure. While a consolidated platform cannot guarantee absolute protection against all attacks, it would undeniably have provided significant assistance to our hypothetical companies.

More than a thought experiment: The growing importance of WAAP
This content provides insights into the significance of Web Application and API Protection (WAAP) services for modern organizations. Rather than being a hypothetical thought experiment, these services have been defined by Gartner as a consolidation of various components such as WAF, bot management, DDoS protection, and API security. According to Gartner's predictions in 2022, by 2024, around 70% of organizations implementing multicloud strategies for web applications in production environments will prefer cloud-based WAAP services over WAAP appliances and IaaS-native WAAP solutions.

The importance of WAAP goes beyond being a mere acronym. It addresses the growing need for organizations to consolidate multiple security services to protect their web applications and APIs. With the global nature of the Internet, these applications are consistently exposed to attacks originating from different locations and varying levels of scale and complexity. The statistics from IBM in 2022 highlight the gravity of the situation, as 83% of surveyed companies reported experiencing a data breach. The average cost of these breaches was estimated at $4.35 million globally and $9.44 million in the United States.


Another consideration: heterogeneous infrastructure

If Company A and Company B were to develop their applications and APIs from scratch today, they would likely opt for a cloud-based hosting solution, potentially choosing a single provider for easier deployment. However, the reality is that most organizations have adopted a hybrid infrastructure approach, combining on-premise legacy database servers, third-party APIs hosted in the cloud, and application services spread across multiple cloud environments. While these deployments offer numerous benefits, they also introduce unique security challenges.

One such challenge is that the native security features offered by a specific cloud provider may not cover the entirety of the infrastructure. Additionally, effectively defending the infrastructure requires first identifying and mapping all its components, which can be a daunting task. Moreover, the security products offered by a particular provider might not be compatible with other solutions used in the organization's technology stack.

Hence, in addition to consolidating essential web application security capabilities, it is crucial for a Web Application and API Protection (WAAP) solution to be infrastructure-agnostic. This means that the WAAP solution should be capable of seamlessly integrating with any type of infrastructure or cloud deployment, regardless of the underlying technologies in use.
Consolidated, infrastructure-agnostic web security
Toffs, being cloud-native and infrastructure-agnostic, has been providing web app security for more than a decade. It brings together all these features into a unified platform, accessible through a single interface. With its vast reach, Toffs handles an immense amount of Internet traffic, processing over 46 million HTTP requests every second and effectively thwarting an average of 112 billion cyber threats daily. As a result, Toffs possesses unparalleled insights into emerging attacks and zero-day threats, giving it a distinct advantage.
Bypassing multi-factor authentication
New cyber attacks are breaching MFA security
Multi-factor authentication (MFA) has long been a fundamental aspect of managing identity and access. It enhances security by supplementing traditional username/password combinations with additional authentication factors, such as fingerprints, one-time passcodes, or hard keys. This approach helps organizations safeguard their networks and data against attacks that exploit stolen credentials.

Unfortunately, attackers are continually evolving their techniques to bypass MFA. Recently, Microsoft discovered a phishing campaign that targeted over 10,000 organizations using on-path attack methods. The attackers employed reverse-proxy sites to create fraudulent Microsoft 365 login pages, enabling them to intercept users' passwords and session cookies. Consequently, they could evade MFA measures and gain unauthorized access to numerous email accounts.

Once the attackers breached legitimate user accounts, they established inbox rules to conduct targeted business email compromise (BEC) attacks on unsuspecting contacts. Furthermore, they maintained access to these compromised accounts even if the users changed their passwords.

This attack raised concerns among organizations that had implemented MFA. However, MFA itself is not the weak link, and abandoning it for less robust identity and access management methods is not the solution. To effectively safeguard users and data from advanced cyber attacks, organizations need to adopt a comprehensive Zero Trust security strategy. This approach entails employing strong authentication measures to continuously verify and monitor all accounts, applications, and endpoints within a corporate network.
How attacks get around conventional cyber security measures

Recently, attackers have employed various methods to compromise Multi-Factor Authentication (MFA), not limited to on-path attacks. One notable incident involved a Russian cyber attack, as reported by the FBI and CISA, where the attackers employed a brute force password attack to gain access to an inactive account within a non-governmental organization. Once inside the account, they exploited a vulnerability known as "PrintNightmare" to execute code, thereby bypassing standard MFA controls and gaining system privileges.

Human error has also contributed to instances of MFA compromise. For example, after implementing MFA on their internal email systems, Syracuse University fell victim to attackers employing a technique called "MFA fatigue." These attackers utilized phishing and other means to acquire email credentials, followed by bombarding students and staff with multiple MFA requests. The aim was to frustrate users into approving the requests, even if only to silence their devices. By gaining authorization, the attackers gained further access to university resources and accounts.

Despite these evolving attack methods, it is crucial to understand that the weakness does not lie in the MFA protocols themselves. In fact, Deputy National Security Advisor for Cyber and Emerging Technology, Anne Neuberger, highlights that MFA can potentially prevent up to 90% of cyber attack attempts. It is essential to recognize that cyber attacks are multifaceted, and attackers target MFA as part of a larger chain of attacks. These attacks may involve phishing, malware, brute force password guessing, unpatched vulnerabilities, stolen credentials, or other combined tactics.

Zero Trust helps prevent MFA exploitation
Relying solely on a single security tactic is insufficient to protect organizations against the ever-growing sophistication of attacks. In order to safeguard their users and data, organizations require a comprehensive security strategy that encompasses multiple approaches.

Zero Trust serves as a fundamental principle in modern cybersecurity, built on the premise of distrust towards any user attempting to access an organization's resources. By adopting this approach, organizations create formidable barriers that make it challenging for attackers, whether internal or external, to breach networks or accounts.

In practical terms, a Zero Trust platform empowers organizations to fortify their networks through various methods, including:

Multi-factor authentication (MFA): MFA can be implemented using methods such as one-time passcodes, push notifications, user biometrics (e.g., fingerprints or facial recognition), security keys, or other means to verify the identities of users and devices.

Continuous monitoring and validation: Users and devices are subject to ongoing reauthentication, rendering it arduous for attackers to maintain persistent access to a network, even if they possess stolen credentials.

Least-privilege access: Users are granted access solely to the specific resources necessary for their tasks, rather than providing unrestricted entry to the entire network.

Device access control: Authorization and monitoring measures are in place to validate devices connecting to the network, identifying and addressing any suspicious activities promptly.

Lateral movement prevention: Microsegmentation techniques restrict access to designated network areas, effectively impeding unauthorized lateral movement.

By adopting a Zero Trust strategy, the likelihood of MFA-based attacks succeeding is significantly diminished. Even if an attacker gains entry to a user account, they are denied unrestricted access to the entire network and are compelled to continually reauthenticate user and device identities, limiting their ability to move laterally.





Sidestep MFA attacks with Toffs
Introducing Toffs Zero Trust, the ultimate solution for safeguarding corporate networks and users against advanced cyber threats, including those targeting MFA security measures. With Toffs's comprehensive Zero Trust platform, organizations can effortlessly implement uniform access controls based on the principle of least privilege. Whether it's cloud, on-premise, or SaaS applications, this consolidated platform thwarts attackers' attempts to compromise valuable systems and data and traverse within organizations.

This piece is one among a series of articles exploring the latest trends and subjects that greatly influence today's technology decision-makers.
Security monitoring fatigue puts organizations at risk
When alerts turn burdensome
Security professionals, who serve as the first line of defense for organizations, are experiencing significant burnout, primarily due to the overwhelming amount of data they have to deal with.

The sheer volume of alerts, many of which are duplicated across multiple tools, makes it challenging for these professionals to prioritize and address the most critical and urgent threats to their organization. Despite the well-meaning nature of security alerts, a recent study revealed that 68% of security professionals admitted to reducing the volume of specific alerting features, and 49% opted to disable high-volume alerts altogether.

While loosening these security protocols might alleviate the burden of investigating every single alert, it also creates security gaps and increases the likelihood of being compromised. This situation can have catastrophic consequences since a missed alert could result in a data breach, escalate the cost of remediation, or leave the organization vulnerable to further attacks.

According to IBM's 2021 Cost of a Data Breach report, it already takes around 212 days to identify a breach and an additional 75 days to contain it. This duration is likely to increase unless proactive measures are taken to address the issue at hand.
Why security is getting burned out
Security professionals are experiencing fatigue due to two primary factors. Firstly, numerous organizations have transitioned, either partially or entirely, to cloud computing. This hybrid infrastructure poses challenges in terms of configuration, management, and security against an array of emerging threats. Moreover, not all security products are compatible with both on-premise and cloud environments, leading organizations to adopt additional solutions to safeguard their users and data.

Secondly, the continuous addition of security products to an organization's arsenal results in an increased volume of monitoring data. While this data is crucial for identifying and mitigating threats, it can become overwhelming to sift through due to its sheer magnitude.

The issue of alert monitoring fatigue is further compounded by various other factors:

False positives
According to a survey carried out by the Ponemon Institute, participants highlighted a false-positive rate ranging from 20% to 50%. This high rate of false positives hinders security teams from obtaining a precise understanding of the actual threats confronting their organization.

Security tools may be siloed or send duplicative alerts
Integrated solutions are essential for optimizing the flow and integrity of data, enabling organizations to effectively evaluate their security posture and promptly respond to emerging threats. Conventional security monitoring tools, whether deployed at the host, system, application, or network level, frequently rely on manual procedures to identify and resolve incidents. Additionally, numerous cloud security tools lack the capacity and adaptability required to handle the intricate nature and expansive scale of hybrid environments.

Data logs lack context and advanced capabilities
Due to the separation of logs in hardware and software, they often lack the ability to provide a comprehensive understanding of an organization's entire infrastructure, thus lacking contextual information. As a result, the process of identifying and addressing an attack becomes time-consuming and arduous due to the overwhelming volume of technical data that needs to be sifted through.

When everything is important, nothing is
Having an inadequate toolset in place results in the prioritization of every event, which poses a significant challenge for security personnel to manually detect the most critical threats. On the other hand, the ideal toolset empowers security teams to automatically prioritize incoming data, facilitating the identification of attack patterns and the evolution of security risks within their organizations. This automation saves valuable time and resources that would otherwise be wasted.

When security professionals become overwhelmed with alerts, parsing log data, and managing monitoring tools, the risks to the organization escalate.

Reducing security monitoring fatigue
Addressing security monitoring fatigue goes beyond simply implementing the ideal security tool. It necessitates a reevaluation of network security strategies.

Instead of dealing with disparate solutions that lack integration, alert de-duplication, and comprehensive visibility, adopting a unified control plane empowers security teams to efficiently oversee their security and monitoring tools. By consolidating threat detection and mitigation capabilities in one central location, organizations can bridge security loopholes and enhance their visibility and control.

Moreover, there are additional prospects for enhancing threat detection capabilities by:

Improving logs and machine learning models
Logging becomes highly valuable when security teams have a comprehensive understanding of the risks faced by their organization. To enhance the effectiveness of logging, teams can incorporate one or more of the following capabilities:

AI-powered event and root cause analysis: Capturing events leading up to, during, and following an incident, providing valuable insights into the entire incident timeline.

Predictive analysis: Identifying vulnerabilities in the infrastructure that require attention before an incident occurs, enabling proactive mitigation measures.

Network detection and response: Breaking down barriers between DevOps, microservices, and API-based integrations to gain a holistic view of the data security life cycle, enhancing threat detection and response capabilities.

Behavior baselining: Creating a catalog of expected and unexpected actions and behaviors, facilitating the identification of anomalies and potential security breaches.

Making better use of automation
Certain aspects of the threat detection process necessitate manual input. However, it is advantageous to automate processes whenever feasible, particularly tactical and repeatable stages of investigation and analysis. This automation can significantly alleviate the overall workload faced by security personnel in detecting threats. For instance, implementing an automated workflow for scanning endpoint devices or email accounts proves to be swifter compared to setting up the scan anew on every occasion.

Cadenced auditing of security tools
Perform periodic audits and optimize the functionality of current security monitoring tools to ensure their effective operation.

Rather than compromising the security standards, businesses can enhance their network security by consolidating all security measures onto a unified platform. This approach strengthens the overall security posture, eliminates potential security vulnerabilities, and creates a conducive environment for security professionals to concentrate on addressing significant threats.


Eliminate security monitoring fatigue with Toffs
Toffs One: Streamlined Security Services at the Network Edge

Experience consolidated essential security services delivered from the network edge with Toffs One—a powerful Zero Trust network-as-a-service platform. With Toffs's intuitive single dashboard, security teams can effortlessly monitor emerging threats through visualized analytics, detailed logs, and customized notifications. Easily configure and manage your security settings with Toffs's user-friendly interface.

Toffs One is built upon a vast global network, leveraging the collective intelligence of millions of properties to effectively identify and mitigate threats. As Toffs's network scales, organizations enjoy seamlessly integrated security solutions that continuously enhance protection.

Discover more articles in this series, exploring the latest trends and topics that impact today's technology decision-makers.
